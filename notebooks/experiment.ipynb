{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "Prepare train/val/test splits for coconut tree detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kshitijrajsharma/dl4cv-object-detection-on-aerial-imagery/blob/master/notebooks/experiment.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dl4cv_oda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from dl4cv_oda import (clean_osm_data, clip_labels_to_tiles, convert_to_yolo_format,\n",
    "                       create_train_val_split, create_yolo_config, download_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../data\")\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "CHIPS_DIR = DATA_DIR / \"chips\"\n",
    "LABELS_DIR = DATA_DIR / \"labels\"\n",
    "YOLO_DIR = DATA_DIR / \"yolo\"\n",
    "\n",
    "OSM_FILE = RAW_DIR / \"kolovai-trees.geojson\"\n",
    "CLEANED_FILE = RAW_DIR / \"cleaned.geojson\"\n",
    "TREES_BOX_FILE = DATA_DIR / \"trees_box.geojson\"\n",
    "TILES_FILE = DATA_DIR / \"tiles.geojson\"\n",
    "\n",
    "if not OSM_FILE.exists():\n",
    "    OSM_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    OSM_FILE.write_bytes(requests.get(\"https://github.com/kshitijrajsharma/dl4cv-oda/blob/master/data/raw/kolovai-trees.geojson?raw=true\", allow_redirects=True).content)\n",
    "    print(f\"Downloaded OSM data\")\n",
    "\n",
    "if not CLEANED_FILE.exists():\n",
    "    count = clean_osm_data(str(OSM_FILE), str(CLEANED_FILE), str(TREES_BOX_FILE))\n",
    "    print(f\"Cleaned {count} trees\")\n",
    "\n",
    "if not TILES_FILE.exists():\n",
    "    data = gpd.read_file(TREES_BOX_FILE)\n",
    "    data.to_crs(epsg=4326, inplace=True)\n",
    "    bbox = list(data.total_bounds)\n",
    "    await download_tiles(bbox, 19, \"https://tiles.openaerialmap.org/5a28639331eff4000c380690/0/5b1b6fb2-5024-4681-a175-9b667174f48c/{z}/{x}/{y}.png\", DATA_DIR, 'OAM')\n",
    "    print(\"Downloaded tiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation complete\n"
     ]
    }
   ],
   "source": [
    "if not (YOLO_DIR / \"train\").exists():\n",
    "    stats = clip_labels_to_tiles(str(TREES_BOX_FILE), str(TILES_FILE), str(LABELS_DIR))\n",
    "    print(f\"Clipped {stats['total_trees']} trees to {stats['processed']} tiles\")\n",
    "    \n",
    "    class_mapping = convert_to_yolo_format(str(TREES_BOX_FILE), str(CHIPS_DIR), str(LABELS_DIR), str(YOLO_DIR), target_species=\"Coconut\")\n",
    "    print(f\"Converted to YOLO format\")\n",
    "    \n",
    "    train_count, val_count, test_count = create_train_val_split(str(LABELS_DIR), str(CHIPS_DIR), str(YOLO_DIR), train_ratio=0.7, val_ratio=0.2, test_ratio=0.1, seed=42)\n",
    "    print(f\"Split: train={train_count}, val={val_count}, test={test_count}\")\n",
    "    \n",
    "    config_file = create_yolo_config(str(YOLO_DIR), {\"Coconut\": 0})\n",
    "    print(f\"Config: {config_file}\")\n",
    "\n",
    "print(\"Data preparation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO, RTDETR\n",
    "import torch\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: 20260111_172635\n",
      "Models: ['yolov8l', 'yolo12l', 'rtdetr-l']\n"
     ]
    }
   ],
   "source": [
    "RESULTS_DIR = Path(\"results\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "# for training\n",
    "SEED = 64\n",
    "IMG_SIZE = 256\n",
    "EPOCHS = 200 \n",
    "PATIENCE = 15\n",
    "BATCH = 16\n",
    "\n",
    "# for hyper param tuning\n",
    "TUNE_MODELS = True\n",
    "TUNE_ITERATIONS = 10\n",
    "TUNE_EPOCHS = 20\n",
    "\n",
    "MODELS = [\n",
    "    {\"name\": \"yolov8l\", \"weights\": \"yolov8l.pt\"},\n",
    "    {\"name\": \"yolo12l\", \"weights\": \"yolo12l.pt\"},\n",
    "    {\"name\": \"rtdetr-l\", \"weights\": \"rtdetr-l.pt\"},\n",
    "]\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "exp_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(f\"Experiment: {exp_id}\")\n",
    "print(f\"Models: {[m['name'] for m in MODELS]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning & Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning yolov8l for 10 iterations\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mInitialized Tuner instance with 'tune_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune'\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mğŸ’¡ Learn about tuning at https://docs.ultralytics.com/guides/hyperparameter-tuning\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 1/10 with hyperparameters: {'lr0': 0.01, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'box': 7.5, 'cls': 0.5, 'dfl': 1.5, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 10}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5583571  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "Model summary: 209 layers, 43,630,611 parameters, 43,630,595 gradients, 165.4 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5315.0Â±1296.9 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 14.7Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3933.4Â±2374.8 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.9Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.25G       3.82      2.649      1.801        496        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 12.1it/s 1.7s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.306      0.394      0.231     0.0618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20      2.53G      2.385      1.372      1.148        790        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.9it/s 0.2s.2s\n",
      "                   all         93       2846    0.00344     0.0337    0.00178   0.000663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20      2.53G      2.214      1.249      1.097        570        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 17.6it/s 0.2s.2s\n",
      "                   all         93       2846    0.00182    0.00597   0.000602   0.000187\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20      2.53G      2.246      1.212      1.111        514        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.4it/s 1.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 20.9it/s 0.1s.2s\n",
      "                   all         93       2846     0.0365     0.0116     0.0187    0.00413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20      2.53G      2.214      1.192      1.082        531        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 17.4it/s 0.2s.2s\n",
      "                   all         93       2846     0.0945      0.118     0.0386     0.0126\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20      2.53G      2.161      1.185      1.064        529        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 19.0it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.2it/s 0.2s.2s\n",
      "                   all         93       2846      0.311      0.316      0.151      0.033\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20      2.53G      2.165      1.192      1.077        433        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.1it/s 0.2s.2s\n",
      "                   all         93       2846     0.0236     0.0706    0.00895    0.00172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20      2.53G      2.086      1.211       1.05        532        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.6it/s 0.2s.2s\n",
      "                   all         93       2846     0.0381     0.0548    0.00925    0.00154\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20      2.53G      2.101      1.182      1.053        410        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.309      0.357      0.168     0.0296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20      2.53G      2.071      1.172      1.034        420        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.524       0.48      0.349     0.0722\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20      2.53G      2.011      1.228      1.044        416        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.3it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.179      0.132     0.0581     0.0103\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20      2.53G      1.941      1.176      1.035        355        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.443      0.402      0.274     0.0532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20      2.53G      1.857      1.166      1.016        251        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 19.0it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.518      0.417      0.332     0.0723\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20      2.53G      1.903       1.16      1.031        219        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.632      0.591      0.507      0.187\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20      2.53G      1.818      1.122      1.011        283        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 19.0it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.669      0.587      0.531      0.165\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20      2.53G      1.864      1.143      1.011        270        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.693      0.639      0.581      0.204\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20      2.53G      1.792       1.14      1.001        467        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 19.1it/s 1.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.2it/s 0.2s.2s\n",
      "                   all         93       2846      0.721      0.629       0.59       0.21\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20      2.53G       1.78      1.127     0.9959        275        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 19.0it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.9it/s 0.2s.2s\n",
      "                   all         93       2846      0.693      0.625      0.555      0.158\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20      2.53G      1.769      1.096     0.9894        369        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 19.0it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.9it/s 0.2s.2s\n",
      "                   all         93       2846      0.739      0.653      0.607      0.241\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20      2.53G      1.751      1.074     0.9931        315        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 19.1it/s 1.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.731      0.644      0.591      0.204\n",
      "\n",
      "20 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 87.6MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m1/10 iterations complete âœ… (34.45s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.20369 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.73122, 'metrics/recall(B)': 0.64371, 'metrics/mAP50(B)': 0.59099, 'metrics/mAP50-95(B)': 0.20369, 'val/box_loss': 2.28538, 'val/cls_loss': 1.17102, 'val/dfl_loss': 1.04056, 'fitness': 0.20369}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 2/10 with hyperparameters: {'lr0': 0.01, 'lrf': 0.01, 'momentum': 0.96035, 'weight_decay': 0.00054, 'warmup_epochs': 3.0, 'warmup_momentum': 0.74885, 'box': 7.5, 'cls': 0.5, 'dfl': 1.5, 'hsv_h': 0.01707, 'hsv_s': 0.7, 'hsv_v': 0.3216, 'degrees': 0.0, 'translate': 0.07683, 'scale': 0.44248, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.51123, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 9}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=9, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.51123, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01707, hsv_s=0.7, hsv_v=0.3216, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.96035, mosaic=1.0, multi_scale=False, name=train43, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train43, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.44248, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.07683, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.74885, weight_decay=0.00054, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5583571  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "Model summary: 209 layers, 43,630,611 parameters, 43,630,595 gradients, 165.4 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5052.8Â±1260.9 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 12.9Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3909.7Â±2542.6 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.8Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.96035' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.00054), 103 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train43\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.26G      3.876      2.685      1.805        474        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 12.3it/s 1.6s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.326      0.358      0.186     0.0641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20      2.54G      2.316      1.335      1.133        764        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 21.4it/s 0.1s.2s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20      2.54G      2.179      1.238      1.095        564        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.1it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.0it/s 0.2s.2s\n",
      "                   all         93       2846   0.000571    0.00492   0.000287   3.49e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20      2.54G      2.186      1.199      1.102        499        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 19.1it/s 0.2s.2s\n",
      "                   all         93       2846    0.00336     0.0112    0.00146   0.000176\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20      2.54G      2.166      1.197      1.079        518        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.5it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 19.7it/s 0.2s.2s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20      2.54G       2.14      1.174      1.072        505        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 18.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.103     0.0427     0.0246    0.00525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20      2.54G       2.11      1.193      1.071        427        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 19.1it/s 1.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 17.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.073     0.0548     0.0252    0.00437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20      2.54G      2.077      1.196      1.052        509        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.6it/s 0.2s.2s\n",
      "                   all         93       2846       0.24      0.381      0.131     0.0284\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20      2.54G      2.045      1.162      1.045        403        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.277      0.331      0.149     0.0244\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20      2.54G      2.021       1.14      1.034        417        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.2it/s 0.2s.2s\n",
      "                   all         93       2846     0.0359      0.338     0.0244    0.00483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20      2.54G      1.949      1.126      1.021        636        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.8it/s 0.2s.2s\n",
      "                   all         93       2846     0.0988      0.123     0.0365    0.00549\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20      2.54G      1.949      1.179      1.031        386        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.4it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.665      0.608      0.559      0.232\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20      2.54G      1.899      1.122      1.028        273        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846        0.2      0.196     0.0979     0.0159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20      2.54G      1.858      1.129      1.013        218        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.639      0.598      0.521      0.141\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20      2.54G      1.808      1.101      1.011        284        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.658      0.616      0.541      0.162\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20      2.54G      1.837      1.113      1.003        263        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.607      0.586      0.494      0.126\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20      2.54G      1.789      1.112     0.9927        458        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.719      0.644      0.605      0.237\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20      2.54G       1.78      1.091     0.9945        273        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.9it/s 0.2s.2s\n",
      "                   all         93       2846       0.65      0.579      0.505      0.129\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20      2.54G       1.74      1.077     0.9966        352        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 19.0it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.2it/s 0.2s.2s\n",
      "                   all         93       2846       0.71      0.645      0.592      0.207\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20      2.54G      1.712      1.053     0.9826        300        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.708      0.638      0.581      0.178\n",
      "\n",
      "20 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train43/weights/last.pt, 87.6MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m2/10 iterations complete âœ… (68.44s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.20369 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.73122, 'metrics/recall(B)': 0.64371, 'metrics/mAP50(B)': 0.59099, 'metrics/mAP50-95(B)': 0.20369, 'val/box_loss': 2.28538, 'val/cls_loss': 1.17102, 'val/dfl_loss': 1.04056, 'fitness': 0.20369}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 3/10 with hyperparameters: {'lr0': 0.01001, 'lrf': 0.00713, 'momentum': 0.937, 'weight_decay': 0.00045, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'box': 7.5, 'cls': 0.53808, 'dfl': 1.5, 'hsv_h': 0.01248, 'hsv_s': 0.61091, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.09398, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 10}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.53808, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01248, hsv_s=0.61091, hsv_v=0.4, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01001, lrf=0.00713, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.09398, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.00045, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5583571  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "Model summary: 209 layers, 43,630,611 parameters, 43,630,595 gradients, 165.4 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5172.0Â±1373.8 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 12.2Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 4192.1Â±2225.1 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.7Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.00045), 103 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.25G      3.956       3.04      1.857        496        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 12.2it/s 1.6s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.0it/s 0.2s.3s\n",
      "                   all         93       2846     0.0518      0.251     0.0304    0.00793\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20      2.53G      2.449      1.504       1.16        794        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.5it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.5it/s 0.2s.2s\n",
      "                   all         93       2846     0.0456      0.114     0.0157    0.00283\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20      2.53G      2.319      1.402      1.122        570        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.108      0.365     0.0694     0.0184\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20      2.53G      2.283      1.344      1.116        516        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 23.9it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20      2.53G      2.276      1.332      1.097        531        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.4it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.144      0.137     0.0523     0.0161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20      2.53G      2.191      1.311      1.074        529        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.6it/s 0.2s.2s\n",
      "                   all         93       2846     0.0701     0.0875     0.0154    0.00301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20      2.53G      2.142      1.292      1.079        433        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.492      0.579      0.419      0.143\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20      2.53G      2.123       1.31      1.061        532        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.1it/s 0.2s.2s\n",
      "                   all         93       2846     0.0328     0.0358    0.00447    0.00158\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20      2.53G      2.099      1.278      1.057        409        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.2it/s 0.2s.2s\n",
      "                   all         93       2846    0.00668     0.0397    0.00287   0.000974\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20      2.53G      2.108       1.28      1.046        416        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.4it/s 0.2s.2s\n",
      "                   all         93       2846     0.0709     0.0587     0.0184    0.00423\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20      2.53G      2.012      1.314      1.052        416        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.3it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.589      0.485      0.427      0.114\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20      2.53G      1.971      1.298       1.04        354        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.236      0.235      0.104     0.0165\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20      2.53G      1.905      1.232      1.027        251        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.665      0.532      0.516      0.146\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20      2.53G      1.928      1.239      1.039        219        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.738      0.639      0.621      0.267\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20      2.53G      1.874      1.217      1.023        283        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.2it/s 0.2s.2s\n",
      "                   all         93       2846      0.583      0.499      0.423     0.0904\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20      2.53G      1.875      1.217      1.013        270        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 19.3it/s 1.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.675      0.609      0.549      0.145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20      2.53G      1.846      1.199      1.016        467        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 19.0it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.682      0.597      0.553      0.164\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20      2.53G      1.805      1.235      1.004        277        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846        0.6      0.529      0.436     0.0839\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20      2.53G      1.791      1.172     0.9951        370        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.717       0.64      0.588      0.198\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20      2.53G      1.799      1.166      1.002        314        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.719      0.632      0.589       0.19\n",
      "\n",
      "20 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 87.6MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m3/10 iterations complete âœ… (102.46s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.20369 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.73122, 'metrics/recall(B)': 0.64371, 'metrics/mAP50(B)': 0.59099, 'metrics/mAP50-95(B)': 0.20369, 'val/box_loss': 2.28538, 'val/cls_loss': 1.17102, 'val/dfl_loss': 1.04056, 'fitness': 0.20369}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 4/10 with hyperparameters: {'lr0': 0.01021, 'lrf': 0.01, 'momentum': 0.98, 'weight_decay': 0.00046, 'warmup_epochs': 3.07752, 'warmup_momentum': 0.8, 'box': 7.5, 'cls': 0.5, 'dfl': 1.76026, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.24211, 'degrees': 0.0, 'translate': 0.08067, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.35187, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 10}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.76026, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.35187, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.24211, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01021, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.98, mosaic=1.0, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.08067, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.07752, warmup_momentum=0.8, weight_decay=0.00046, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5583571  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "Model summary: 209 layers, 43,630,611 parameters, 43,630,595 gradients, 165.4 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 4986.2Â±1263.4 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 14.3Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2386.1Â±883.0 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.1Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01021' and 'momentum=0.98' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.00046), 103 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.25G      3.812      2.645      2.112        488        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 12.2it/s 1.6s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.283      0.525      0.205      0.073\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20      2.53G       2.39      1.378       1.35        796        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.5it/s 0.2s.2s\n",
      "                   all         93       2846    0.00147     0.0137   0.000733   0.000215\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20      2.53G      2.246      1.259      1.286        573        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.0it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 18.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.008     0.0274    0.00411    0.00084\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20      2.53G      2.203      1.199      1.286        518        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.9it/s 0.2s.2s\n",
      "                   all         93       2846    0.00613     0.0548    0.00323   0.000871\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20      2.53G      2.152      1.181       1.25        528        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.4it/s 0.2s.2s\n",
      "                   all         93       2846     0.0038     0.0372    0.00197   0.000574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20      2.53G       2.14      1.181      1.245        528        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 17.4it/s 0.2s.2s\n",
      "                   all         93       2846     0.0719     0.0274    0.00956    0.00214\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20      2.53G      2.156      1.196      1.255        438        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.2it/s 0.2s.2s\n",
      "                   all         93       2846      0.171      0.547      0.123     0.0348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20      2.53G      2.098      1.179      1.228        532        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 19.0it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.672      0.477      0.499      0.169\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20      2.53G      2.045      1.156      1.222        403        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.301      0.364      0.179     0.0362\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20      2.53G        2.1      1.162      1.226        419        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.371      0.338      0.212     0.0473\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20      2.53G      2.016       1.24      1.227        416        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.1it/s 0.2s.2s\n",
      "                   all         93       2846     0.0349     0.0148    0.00418     0.0019\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20      2.53G      1.919      1.188      1.203        360        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.2it/s 0.2s.2s\n",
      "                   all         93       2846      0.502      0.428      0.309     0.0565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20      2.53G      1.893      1.162      1.202        253        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.436      0.291      0.226     0.0578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20      2.53G      1.886      1.141      1.203        216        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.646      0.618      0.524      0.157\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20      2.53G      1.819      1.111      1.186        281        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.2it/s 0.2s.2s\n",
      "                   all         93       2846      0.511      0.442      0.335     0.0673\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20      2.53G      1.834      1.115      1.174        270        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.704      0.642      0.586      0.211\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20      2.53G      1.811      1.121      1.184        470        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.727      0.636      0.593      0.208\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20      2.53G      1.775      1.125      1.168        274        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.2it/s 0.2s.2s\n",
      "                   all         93       2846       0.68      0.596      0.533      0.135\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20      2.53G      1.764      1.081      1.158        370        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.721      0.652      0.599       0.21\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20      2.53G      1.747      1.072      1.164        313        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.2it/s 0.2s.2s\n",
      "                   all         93       2846       0.72      0.654      0.599      0.202\n",
      "\n",
      "20 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 87.6MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m4/10 iterations complete âœ… (136.53s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.20369 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.73122, 'metrics/recall(B)': 0.64371, 'metrics/mAP50(B)': 0.59099, 'metrics/mAP50-95(B)': 0.20369, 'val/box_loss': 2.28538, 'val/cls_loss': 1.17102, 'val/dfl_loss': 1.04056, 'fitness': 0.20369}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 5/10 with hyperparameters: {'lr0': 0.00758, 'lrf': 0.00689, 'momentum': 0.96336, 'weight_decay': 0.00046, 'warmup_epochs': 3.04375, 'warmup_momentum': 0.95, 'box': 5.97796, 'cls': 0.41059, 'dfl': 1.67616, 'hsv_h': 0.01335, 'hsv_s': 0.61798, 'hsv_v': 0.34149, 'degrees': 0.0, 'translate': 0.11046, 'scale': 0.4154, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.38294, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 10}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=5.97796, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.41059, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.67616, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.38294, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01335, hsv_s=0.61798, hsv_v=0.34149, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00758, lrf=0.00689, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.96336, mosaic=1.0, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.4154, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.11046, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.04375, warmup_momentum=0.95, weight_decay=0.00046, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5583571  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "Model summary: 209 layers, 43,630,611 parameters, 43,630,595 gradients, 165.4 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5435.3Â±1407.9 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 12.9Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2905.0Â±1783.8 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.6Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.00758' and 'momentum=0.96336' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.00046), 103 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.26G      3.043      2.176      2.014        469        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 12.0it/s 1.7s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.216       0.53      0.169     0.0475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20      2.54G      1.832      1.069      1.263        741        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846     0.0499      0.354     0.0325     0.0117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20      2.54G      1.713      1.012      1.208        545        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 22.0it/s 0.1s\n",
      "                   all         93       2846     0.0616    0.00632     0.0312    0.00917\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20      2.54G      1.727     0.9956      1.221        492        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 18.0it/s 0.2s.2s\n",
      "                   all         93       2846    0.00211     0.0155    0.00107   0.000231\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20      2.54G      1.657     0.9817      1.176        522        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.3it/s 0.2s.2s\n",
      "                   all         93       2846     0.0395      0.214      0.019    0.00592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20      2.54G      1.627     0.9372      1.164        507        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.305      0.464      0.255       0.07\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20      2.54G      1.643     0.9676      1.178        422        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.425      0.576      0.328     0.0869\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20      2.54G       1.68     0.9551      1.173        504        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.473      0.549      0.427      0.135\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20      2.54G      1.591     0.9518      1.146        403        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.4it/s 0.2s.2s\n",
      "                   all         93       2846     0.0578     0.0337    0.00513     0.0015\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20      2.54G      1.597     0.9408      1.142        399        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.6it/s 0.2s.2s\n",
      "                   all         93       2846     0.0485     0.0471    0.00764    0.00198\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20      2.54G      1.547     0.9753      1.135        429        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.276      0.272      0.126     0.0201\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20      2.54G      1.518     0.9443      1.131        368        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.132      0.153       0.05    0.00688\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20      2.54G      1.457     0.9351      1.117        252        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 19.0it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.423      0.329      0.245     0.0435\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20      2.54G      1.477     0.9401       1.12        220        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.239      0.238     0.0975     0.0132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20      2.54G      1.412      0.912      1.108        288        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.447      0.385      0.259     0.0374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20      2.54G      1.442     0.9067      1.108        270        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.624      0.582       0.49      0.129\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20      2.54G      1.427      0.917      1.105        470        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 19.0it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.738      0.646      0.612      0.235\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20      2.54G      1.418     0.9093      1.101        280        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.705      0.636      0.585      0.189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20      2.54G      1.394     0.8813      1.092        369        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.716      0.648      0.598      0.209\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20      2.54G      1.383     0.8705      1.097        320        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.726       0.66      0.604      0.225\n",
      "\n",
      "20 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 87.6MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m5/10 iterations complete âœ… (170.81s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.225 observed at iteration 5\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.72553, 'metrics/recall(B)': 0.65952, 'metrics/mAP50(B)': 0.60438, 'metrics/mAP50-95(B)': 0.225, 'val/box_loss': 1.71893, 'val/cls_loss': 0.9517, 'val/dfl_loss': 1.13558, 'fitness': 0.225}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00758\n",
      "lrf: 0.00689\n",
      "momentum: 0.96336\n",
      "weight_decay: 0.00046\n",
      "warmup_epochs: 3.04375\n",
      "warmup_momentum: 0.95\n",
      "box: 5.97796\n",
      "cls: 0.41059\n",
      "dfl: 1.67616\n",
      "hsv_h: 0.01335\n",
      "hsv_s: 0.61798\n",
      "hsv_v: 0.34149\n",
      "degrees: 0.0\n",
      "translate: 0.11046\n",
      "scale: 0.4154\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.38294\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 6/10 with hyperparameters: {'lr0': 0.01038, 'lrf': 0.00805, 'momentum': 0.95173, 'weight_decay': 0.00049, 'warmup_epochs': 3.06359, 'warmup_momentum': 0.92308, 'box': 5.87563, 'cls': 0.59646, 'dfl': 1.68058, 'hsv_h': 0.01318, 'hsv_s': 0.73884, 'hsv_v': 0.36175, 'degrees': 0.0, 'translate': 0.10204, 'scale': 0.49026, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.38815, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 10}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=5.87563, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.59646, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.68058, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.38815, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01318, hsv_s=0.73884, hsv_v=0.36175, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01038, lrf=0.00805, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.95173, mosaic=1.0, multi_scale=False, name=train44, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train44, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.49026, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.10204, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.06359, warmup_momentum=0.92308, weight_decay=0.00049, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5583571  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "Model summary: 209 layers, 43,630,611 parameters, 43,630,595 gradients, 165.4 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5252.1Â±1336.2 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 13.7Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 4126.6Â±2235.9 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.8Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01038' and 'momentum=0.95173' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.00049), 103 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train44\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.26G      3.025      3.367      2.016        490        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 12.0it/s 1.7s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.9it/s 0.2s.3s\n",
      "                   all         93       2846      0.237      0.384      0.144     0.0505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20      2.54G      1.914      1.677      1.294        784        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846    0.00849     0.0833    0.00478   0.000591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20      2.54G       1.75       1.48      1.231        569        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 23.9it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20      2.54G      1.757      1.436      1.241        516        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 20.0it/s 0.1s.2s\n",
      "                   all         93       2846     0.0552     0.0162     0.0196    0.00979\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20      2.54G       1.74       1.44      1.208        527        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 18.9it/s 0.2s.2s\n",
      "                   all         93       2846    0.00317     0.0141     0.0041    0.00122\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20      2.54G      1.694      1.418      1.192        528        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.2it/s 0.2s.2s\n",
      "                   all         93       2846     0.0305     0.0527    0.00889    0.00214\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20      2.54G       1.67      1.415      1.193        433        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.3it/s 0.2s.2s\n",
      "                   all         93       2846     0.0706     0.0734     0.0173    0.00357\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20      2.54G      1.629      1.413      1.168        528        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.5it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.655      0.615      0.559      0.217\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20      2.54G      1.556      1.385      1.149        407        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.238      0.394       0.15     0.0331\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20      2.54G      1.707      1.399      1.185        414        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.2it/s 0.2s.2s\n",
      "                   all         93       2846       0.11      0.136     0.0477    0.00906\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20      2.54G      1.611      1.467      1.177        420        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846     0.0238     0.0372    0.00484     0.0012\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20      2.54G      1.508      1.408      1.145        358        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.156      0.265     0.0716     0.0117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20      2.54G      1.475      1.364      1.136        252        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.161      0.264     0.0665     0.0112\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20      2.54G      1.491      1.348      1.147        220        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.556       0.53      0.433      0.125\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20      2.54G      1.421       1.32      1.125        283        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.486      0.371      0.284     0.0519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20      2.54G      1.437      1.307      1.121        270        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.669      0.619      0.548      0.172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20      2.54G      1.428      1.321      1.122        467        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.655      0.608      0.532      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20      2.54G      1.405      1.333      1.114        277        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.681      0.611      0.545      0.152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20      2.54G      1.395      1.278      1.109        369        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.735      0.665      0.609      0.249\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20      2.54G      1.387      1.276      1.112        317        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.696      0.635      0.562      0.166\n",
      "\n",
      "20 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train44/weights/last.pt, 87.6MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m6/10 iterations complete âœ… (204.87s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.225 observed at iteration 5\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.72553, 'metrics/recall(B)': 0.65952, 'metrics/mAP50(B)': 0.60438, 'metrics/mAP50-95(B)': 0.225, 'val/box_loss': 1.71893, 'val/cls_loss': 0.9517, 'val/dfl_loss': 1.13558, 'fitness': 0.225}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00758\n",
      "lrf: 0.00689\n",
      "momentum: 0.96336\n",
      "weight_decay: 0.00046\n",
      "warmup_epochs: 3.04375\n",
      "warmup_momentum: 0.95\n",
      "box: 5.97796\n",
      "cls: 0.41059\n",
      "dfl: 1.67616\n",
      "hsv_h: 0.01335\n",
      "hsv_s: 0.61798\n",
      "hsv_v: 0.34149\n",
      "degrees: 0.0\n",
      "translate: 0.11046\n",
      "scale: 0.4154\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.38294\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 7/10 with hyperparameters: {'lr0': 0.01088, 'lrf': 0.01275, 'momentum': 0.87408, 'weight_decay': 0.00047, 'warmup_epochs': 3.03393, 'warmup_momentum': 0.76737, 'box': 5.35954, 'cls': 0.47204, 'dfl': 1.75337, 'hsv_h': 0.01445, 'hsv_s': 0.67261, 'hsv_v': 0.40741, 'degrees': 0.0, 'translate': 0.1085, 'scale': 0.47352, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.40575, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 10}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=5.35954, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.47204, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.75337, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.40575, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01445, hsv_s=0.67261, hsv_v=0.40741, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01088, lrf=0.01275, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.87408, mosaic=1.0, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.47352, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1085, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.03393, warmup_momentum=0.76737, weight_decay=0.00047, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5583571  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "Model summary: 209 layers, 43,630,611 parameters, 43,630,595 gradients, 165.4 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5454.8Â±1382.8 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 16.4Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2444.7Â±1213.4 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.7Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01088' and 'momentum=0.87408' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.00047), 103 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.27G      2.732       2.48        2.1        481        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 11.9it/s 1.7s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.107      0.433     0.0774     0.0196\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20      2.55G      1.705      1.284      1.339        770        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 23.4it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20      2.55G      1.625      1.203      1.294        567        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 20.2it/s 0.1s.2s\n",
      "                   all         93       2846    0.00214    0.00176   0.000975   0.000312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20      2.55G      1.606      1.134      1.301        508        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 23.8it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20      2.55G      1.559      1.138      1.254        527        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.5it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 17.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.227     0.0387      0.024    0.00829\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20      2.55G      1.545      1.114      1.251        524        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 18.8it/s 0.2s.2s\n",
      "                   all         93       2846     0.0215    0.00878    0.00525    0.00181\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20      2.55G      1.497      1.132       1.24        424        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.9it/s 0.2s.2s\n",
      "                   all         93       2846      0.291      0.305      0.164     0.0286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20      2.55G      1.477      1.118      1.221        519        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.399      0.342      0.231     0.0438\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20      2.55G      1.437      1.091      1.209        406        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.5it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.9it/s 0.2s.2s\n",
      "                   all         93       2846      0.381      0.432      0.244     0.0588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20      2.55G      1.563      1.123      1.243        407        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.3it/s 0.2s.2s\n",
      "                   all         93       2846     0.0227     0.0274    0.00408   0.000711\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20      2.55G      1.456      1.149      1.229        420        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.5it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.326      0.332      0.205     0.0442\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20      2.55G      1.368      1.111      1.197        360        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.258      0.278      0.153     0.0292\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20      2.55G      1.352      1.084        1.2        249        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.572       0.46      0.376      0.092\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20      2.55G      1.339       1.07      1.193        219        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.735      0.651       0.62      0.248\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20      2.55G      1.296      1.042       1.18        284        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.679      0.579      0.528      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20      2.55G      1.309      1.043      1.174        269        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.721      0.644      0.594      0.207\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20      2.55G      1.279      1.041      1.171        469        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.714      0.622      0.589      0.205\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20      2.55G      1.273      1.057      1.163        278        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.698      0.627      0.568      0.158\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20      2.55G      1.255      1.008      1.156        367        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.9it/s 0.2s.2s\n",
      "                   all         93       2846      0.727      0.659      0.599      0.204\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20      2.55G       1.26      1.008      1.158        317        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.9it/s 0.2s.2s\n",
      "                   all         93       2846      0.732      0.649      0.599      0.212\n",
      "\n",
      "20 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 87.6MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m7/10 iterations complete âœ… (238.91s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.225 observed at iteration 5\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.72553, 'metrics/recall(B)': 0.65952, 'metrics/mAP50(B)': 0.60438, 'metrics/mAP50-95(B)': 0.225, 'val/box_loss': 1.71893, 'val/cls_loss': 0.9517, 'val/dfl_loss': 1.13558, 'fitness': 0.225}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00758\n",
      "lrf: 0.00689\n",
      "momentum: 0.96336\n",
      "weight_decay: 0.00046\n",
      "warmup_epochs: 3.04375\n",
      "warmup_momentum: 0.95\n",
      "box: 5.97796\n",
      "cls: 0.41059\n",
      "dfl: 1.67616\n",
      "hsv_h: 0.01335\n",
      "hsv_s: 0.61798\n",
      "hsv_v: 0.34149\n",
      "degrees: 0.0\n",
      "translate: 0.11046\n",
      "scale: 0.4154\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.38294\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 8/10 with hyperparameters: {'lr0': 0.00879, 'lrf': 0.00876, 'momentum': 0.88463, 'weight_decay': 0.0005, 'warmup_epochs': 2.54879, 'warmup_momentum': 0.76442, 'box': 5.42445, 'cls': 0.43362, 'dfl': 1.68601, 'hsv_h': 0.01451, 'hsv_s': 0.60385, 'hsv_v': 0.29994, 'degrees': 0.0, 'translate': 0.0913, 'scale': 0.48704, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.59837, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 7}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=5.42445, cache=False, cfg=None, classes=None, close_mosaic=7, cls=0.43362, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.68601, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.59837, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01451, hsv_s=0.60385, hsv_v=0.29994, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00879, lrf=0.00876, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.88463, mosaic=1.0, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.48704, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.0913, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=2.54879, warmup_momentum=0.76442, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5583571  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "Model summary: 209 layers, 43,630,611 parameters, 43,630,595 gradients, 165.4 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5090.3Â±1320.5 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 14.1Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2550.0Â±1156.1 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.1Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.00879' and 'momentum=0.88463' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.27G      2.791      2.324      2.029        491        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 12.2it/s 1.6s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.9it/s 0.2s.3s\n",
      "                   all         93       2846      0.131     0.0703     0.0331    0.00547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20      2.55G      1.699      1.154      1.271        787        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.4it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.4it/s 0.2s.2s\n",
      "                   all         93       2846   3.81e-05   0.000351    1.9e-05   9.52e-06\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20      2.55G       1.62      1.075      1.229        570        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.9it/s 0.2s.2s\n",
      "                   all         93       2846    0.00592     0.0548    0.00306    0.00124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20      2.55G      1.581      1.054      1.222        517        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 20.3it/s 0.1s.2s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20      2.55G      1.547      1.042      1.187        525        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.3it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.2it/s 0.2s.2s\n",
      "                   all         93       2846     0.0148      0.145    0.00846    0.00149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20      2.55G      1.532      1.027      1.181        523        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.5it/s 0.2s.2s\n",
      "                   all         93       2846     0.0843      0.178     0.0406    0.00697\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20      2.55G       1.53      1.032       1.19        432        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.241       0.35      0.149     0.0323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20      2.55G      1.482          1      1.166        526        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.4it/s 0.2s.2s\n",
      "                   all         93       2846     0.0608     0.0439     0.0106    0.00319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20      2.55G      1.434      1.003      1.147        406        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.319      0.402      0.285     0.0787\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20      2.55G      1.508     0.9996      1.163        413        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.3it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.571      0.527      0.457      0.148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20      2.55G      1.411     0.9889      1.137        664        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.652      0.568      0.511      0.145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20      2.55G      1.466     0.9871      1.168        493        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.2it/s 0.2s.2s\n",
      "                   all         93       2846      0.635      0.627      0.551      0.204\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20      2.55G      1.418     0.9982      1.142        514        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.246      0.258     0.0985     0.0167\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20      2.55G      1.385      1.019      1.145        224        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.2it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.461      0.409      0.293      0.052\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20      2.55G       1.36     0.9644      1.142        271        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.238      0.216     0.0907     0.0158\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20      2.55G      1.302     0.9631       1.13        229        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846       0.67      0.621      0.549      0.173\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20      2.55G      1.303     0.9753      1.112        467        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.712      0.617       0.58      0.188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20      2.55G      1.294     0.9483      1.118        283        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.2it/s 0.2s.2s\n",
      "                   all         93       2846      0.517      0.436      0.317     0.0628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20      2.55G      1.265     0.9336      1.096        353        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.9it/s 0.2s.2s\n",
      "                   all         93       2846      0.668      0.605      0.529      0.141\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20      2.55G      1.259     0.9155      1.111        309        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.717      0.647      0.595      0.213\n",
      "\n",
      "20 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 87.6MB\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/best.pt, 87.6MB\n",
      "\n",
      "Validating /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/best.pt...\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "Model summary (fused): 112 layers, 43,607,379 parameters, 0 gradients, 164.8 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 17.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.718      0.646      0.595      0.213\n",
      "Speed: 0.0ms preprocess, 0.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m8/10 iterations complete âœ… (274.15s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.225 observed at iteration 5\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.72553, 'metrics/recall(B)': 0.65952, 'metrics/mAP50(B)': 0.60438, 'metrics/mAP50-95(B)': 0.225, 'val/box_loss': 1.71893, 'val/cls_loss': 0.9517, 'val/dfl_loss': 1.13558, 'fitness': 0.225}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00758\n",
      "lrf: 0.00689\n",
      "momentum: 0.96336\n",
      "weight_decay: 0.00046\n",
      "warmup_epochs: 3.04375\n",
      "warmup_momentum: 0.95\n",
      "box: 5.97796\n",
      "cls: 0.41059\n",
      "dfl: 1.67616\n",
      "hsv_h: 0.01335\n",
      "hsv_s: 0.61798\n",
      "hsv_v: 0.34149\n",
      "degrees: 0.0\n",
      "translate: 0.11046\n",
      "scale: 0.4154\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.38294\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 9/10 with hyperparameters: {'lr0': 0.00835, 'lrf': 0.00764, 'momentum': 0.98, 'weight_decay': 0.00046, 'warmup_epochs': 2.91982, 'warmup_momentum': 0.77321, 'box': 10.19167, 'cls': 0.39733, 'dfl': 1.77361, 'hsv_h': 0.0154, 'hsv_s': 0.65005, 'hsv_v': 0.44494, 'degrees': 0.0, 'translate': 0.08669, 'scale': 0.48062, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.3608, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 7}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=10.19167, cache=False, cfg=None, classes=None, close_mosaic=7, cls=0.39733, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.77361, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.3608, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.0154, hsv_s=0.65005, hsv_v=0.44494, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00835, lrf=0.00764, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.98, mosaic=1.0, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.48062, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.08669, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=2.91982, warmup_momentum=0.77321, weight_decay=0.00046, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5583571  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "Model summary: 209 layers, 43,630,611 parameters, 43,630,595 gradients, 165.4 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 4983.1Â±1230.4 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 14.1Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2293.0Â±1051.6 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.2Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.00835' and 'momentum=0.98' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.00046), 103 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.27G      5.177      2.105      2.124        483        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 12.0it/s 1.7s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.163      0.484      0.155     0.0346\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20      2.55G      3.244      1.105      1.359        786        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 24.1it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20      2.55G      3.002     0.9937      1.299        569        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 19.4it/s 0.2s.2s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20      2.55G      3.068     0.9641      1.322        515        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 24.1it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20      2.55G      2.908     0.9617      1.261        522        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.3it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.5it/s 0.2s.2s\n",
      "                   all         93       2846    0.00383     0.0246    0.00178   0.000329\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20      2.55G      2.876      0.941      1.254        524        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.9it/s 0.2s.2s\n",
      "                   all         93       2846    0.00326     0.0112    0.00101   0.000234\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20      2.55G      2.899     0.9463      1.263        432        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.8it/s 0.2s.2s\n",
      "                   all         93       2846     0.0532     0.0759     0.0148    0.00287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20      2.55G      2.832     0.9423      1.243        520        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.142      0.157     0.0476    0.00751\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20      2.55G      2.723     0.9386       1.23        405        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.141      0.183     0.0633     0.0108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20      2.55G      2.827     0.9273      1.235        413        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.4it/s 0.2s.2s\n",
      "                   all         93       2846       0.16      0.107     0.0628     0.0189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20      2.55G      2.745      0.919      1.226        662        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.165      0.204     0.0949     0.0188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20      2.55G      2.794     0.9277      1.245        488        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.537      0.498      0.419      0.118\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20      2.55G      2.727     0.9502      1.224        512        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.106     0.0562     0.0296    0.00692\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20      2.55G      2.629     0.9553      1.217        224        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.5it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.2it/s 0.2s.2s\n",
      "                   all         93       2846      0.109      0.161     0.0561     0.0116\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20      2.55G      2.582     0.9008      1.214        272        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.588      0.499      0.421     0.0988\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20      2.55G      2.532     0.8858      1.213        231        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.673      0.575      0.522      0.149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20      2.55G      2.501     0.9174      1.187        467        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.724      0.652       0.61      0.216\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20      2.55G      2.462     0.8913      1.188        283        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.433      0.378       0.26     0.0427\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20      2.55G      2.426     0.8755      1.171        355        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.655      0.595      0.526      0.139\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20      2.55G      2.432     0.8472      1.188        309        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.704      0.631      0.576      0.183\n",
      "\n",
      "20 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 87.6MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m9/10 iterations complete âœ… (308.67s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.225 observed at iteration 5\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.72553, 'metrics/recall(B)': 0.65952, 'metrics/mAP50(B)': 0.60438, 'metrics/mAP50-95(B)': 0.225, 'val/box_loss': 1.71893, 'val/cls_loss': 0.9517, 'val/dfl_loss': 1.13558, 'fitness': 0.225}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00758\n",
      "lrf: 0.00689\n",
      "momentum: 0.96336\n",
      "weight_decay: 0.00046\n",
      "warmup_epochs: 3.04375\n",
      "warmup_momentum: 0.95\n",
      "box: 5.97796\n",
      "cls: 0.41059\n",
      "dfl: 1.67616\n",
      "hsv_h: 0.01335\n",
      "hsv_s: 0.61798\n",
      "hsv_v: 0.34149\n",
      "degrees: 0.0\n",
      "translate: 0.11046\n",
      "scale: 0.4154\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.38294\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 10/10 with hyperparameters: {'lr0': 0.00878, 'lrf': 0.00661, 'momentum': 0.94084, 'weight_decay': 0.00035, 'warmup_epochs': 2.76384, 'warmup_momentum': 0.64476, 'box': 9.32408, 'cls': 0.41988, 'dfl': 1.89486, 'hsv_h': 0.02141, 'hsv_s': 0.54735, 'hsv_v': 0.28373, 'degrees': 0.0, 'translate': 0.10931, 'scale': 0.57152, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.47921, 'bgr': 0.0, 'mosaic': 0.8809, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 10}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=9.32408, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.41988, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.89486, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.47921, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.02141, hsv_s=0.54735, hsv_v=0.28373, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00878, lrf=0.00661, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.94084, mosaic=0.8809, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.57152, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.10931, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=2.76384, warmup_momentum=0.64476, weight_decay=0.00035, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5583571  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "Model summary: 209 layers, 43,630,611 parameters, 43,630,595 gradients, 165.4 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5061.8Â±1123.4 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 15.4Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 4069.0Â±2333.9 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.9Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.00878' and 'momentum=0.94084' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.00035), 103 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.33G      4.845      2.242      2.242        518        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 12.1it/s 1.6s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846     0.0774      0.359     0.0529     0.0143\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20      2.61G      2.995      1.134      1.461        633        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 22.1it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20      2.61G      2.881      1.059      1.409        524        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.5it/s 0.2s.2s\n",
      "                   all         93       2846    0.00476      0.046    0.00247    0.00101\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20      2.61G      2.761      1.078      1.371        454        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.5it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 17.6it/s 0.2s.2s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20      2.61G      2.707       1.07      1.349        644        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.8it/s 0.2s.2s\n",
      "                   all         93       2846     0.0156      0.152    0.00908    0.00155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20      2.61G      2.848      1.083      1.377        445        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.338      0.586      0.256      0.105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20      2.61G      2.683      1.055      1.328        645        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.023     0.0183    0.00258   0.000489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20      2.61G      2.626      1.018      1.327        574        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.4it/s 0.2s.2s\n",
      "                   all         93       2846     0.0812     0.0302     0.0162    0.00655\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20      2.61G      2.634      1.034      1.312        636        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.9it/s 0.2s.2s\n",
      "                   all         93       2846      0.463      0.489      0.334     0.0916\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20      2.61G      2.594      1.041      1.296        605        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846    0.00278     0.0134    0.00111   0.000239\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20      2.61G       2.49      1.054      1.331        406        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.1it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.4it/s 0.2s.2s\n",
      "                   all         93       2846    0.00386     0.0193    0.00165   0.000286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20      2.61G       2.42     0.9985      1.309        347        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.2it/s 0.2s.2s\n",
      "                   all         93       2846      0.158      0.132     0.0529    0.00767\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20      2.61G      2.431      0.973      1.316        247        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.465      0.544      0.336      0.121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20      2.61G      2.413     0.9977      1.327        212        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.148      0.171     0.0479    0.00832\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20      2.61G       2.31     0.9564      1.295        277        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.508      0.426      0.321      0.063\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20      2.61G      2.301     0.9603      1.281        265        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.587      0.565      0.466      0.121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20      2.61G       2.27     0.9558       1.28        463        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.732      0.639        0.6      0.234\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20      2.61G      2.277     0.9721      1.278        267        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.2it/s 0.2s.2s\n",
      "                   all         93       2846      0.701      0.601       0.55       0.15\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20      2.61G      2.209     0.9261      1.258        361        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.9it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.719      0.633      0.582      0.191\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20      2.61G      2.242     0.9214      1.269        308        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.9it/s 0.2s.2s\n",
      "                   all         93       2846      0.723      0.627      0.582      0.194\n",
      "\n",
      "20 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 87.6MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m10/10 iterations complete âœ… (343.30s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.225 observed at iteration 5\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.72553, 'metrics/recall(B)': 0.65952, 'metrics/mAP50(B)': 0.60438, 'metrics/mAP50-95(B)': 0.225, 'val/box_loss': 1.71893, 'val/cls_loss': 0.9517, 'val/dfl_loss': 1.13558, 'fitness': 0.225}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolov8l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00758\n",
      "lrf: 0.00689\n",
      "momentum: 0.96336\n",
      "weight_decay: 0.00046\n",
      "warmup_epochs: 3.04375\n",
      "warmup_momentum: 0.95\n",
      "box: 5.97796\n",
      "cls: 0.41059\n",
      "dfl: 1.67616\n",
      "hsv_h: 0.01335\n",
      "hsv_s: 0.61798\n",
      "hsv_v: 0.34149\n",
      "degrees: 0.0\n",
      "translate: 0.11046\n",
      "scale: 0.4154\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.38294\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "yolov8l tuning complete. Best hyperparameters saved to runs/detect/20260111_172635_yolov8l_tune/best_hyperparameters.yaml\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=5.97796, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.41059, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.67616, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=200, erasing=0.4, exist_ok=False, fliplr=0.38294, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01335, hsv_s=0.61798, hsv_v=0.34149, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00758, lrf=0.00689, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.96336, mosaic=1.0, multi_scale=False, name=20260111_172635_yolov8l, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/20260111_172635_yolov8l, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.4154, seed=64, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.11046, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.04375, warmup_momentum=0.95, weight_decay=0.00046, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5583571  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "Model summary: 209 layers, 43,630,611 parameters, 43,630,595 gradients, 165.4 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5364.4Â±761.8 MB/s, size: 152.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 746.9Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1357.1Â±898.3 MB/s, size: 142.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 212.8Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.00758' and 'momentum=0.96336' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.00046), 103 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/20260111_172635_yolov8l\u001b[0m\n",
      "Starting training for 200 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/200      2.29G      3.115       2.48      2.047        469        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.2it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.0it/s 0.2s.2s\n",
      "                   all         93       2846       0.25      0.434      0.173     0.0641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/200      2.61G      1.879      1.114      1.279        741        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.2it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 24.1it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/200      2.61G      1.716      1.004      1.207        545        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 24.0it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/200      2.61G      1.756     0.9883      1.232        492        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.5it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 23.9it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/200      2.73G      1.729     0.9796      1.202        522        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.3it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.2it/s 0.2s.2s\n",
      "                   all         93       2846   0.000932    0.00914   0.000483      7e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/200      2.84G      1.718     0.9799      1.195        507        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.8it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 17.9it/s 0.2s.2s\n",
      "                   all         93       2846       0.22      0.144      0.078     0.0148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/200      2.89G      1.678     0.9877      1.195        422        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.7it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.231      0.338       0.14     0.0223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/200      2.89G       1.64     0.9686      1.164        504        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.3it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846     0.0503      0.128     0.0153    0.00213\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/200      2.89G      1.628     0.9645      1.165        403        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.4it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.024     0.0724     0.0101     0.0015\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/200      2.89G      1.738     0.9977       1.19        399        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.3it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.4it/s 0.2s.2s\n",
      "                   all         93       2846     0.0294    0.00773     0.0059    0.00124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/200      2.89G      1.618     0.9553      1.162        611        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.4it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846     0.0755     0.0999     0.0305    0.00646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/200      2.89G      1.673      1.008      1.181        462        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.5it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.9it/s 0.2s.3s\n",
      "                   all         93       2846     0.0314     0.0531    0.00722    0.00147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/200      2.89G      1.637     0.9867      1.168        484        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.4it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.9it/s 0.2s.2s\n",
      "                   all         93       2846      0.105      0.112     0.0306    0.00581\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/200      2.89G      1.622     0.9832      1.151        513        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.5it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.359      0.328      0.196     0.0318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/200      2.89G      1.616     0.9832      1.151        579        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.4it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846        0.3      0.255      0.133     0.0213\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/200      2.89G      1.621     0.9873      1.152        383        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.3it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.599      0.554       0.46      0.107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/200      2.89G      1.629     0.9585      1.149        459        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.4it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.289      0.279      0.128     0.0195\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/200      2.89G      1.597     0.9626      1.138        411        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.5it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.304      0.265      0.161     0.0282\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/200      2.89G      1.536     0.9561      1.127        410        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.4it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.384      0.384      0.239     0.0404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/200      2.89G      1.521     0.9623      1.117        564        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.2it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.202      0.188     0.0808     0.0121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/200      2.89G      1.505     0.9527      1.115        460        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846     0.0595     0.0615      0.018    0.00305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/200      2.89G      1.501     0.9185      1.112        580        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.582      0.573      0.433     0.0933\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/200      2.89G      1.464     0.9206      1.104        356        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.4it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.9it/s 0.2s.2s\n",
      "                   all         93       2846       0.69      0.641      0.563      0.177\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/200      2.89G      1.519     0.9302      1.108        567        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846     0.0349     0.0534     0.0107     0.0018\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/200      2.89G      1.513     0.9176      1.108        536        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.5it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 18.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.186     0.0706      0.047      0.012\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/200      2.89G      1.498     0.9128      1.103        452        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.5it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.149      0.154     0.0557    0.00877\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     27/200      2.89G      1.607      0.952      1.132        470        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846       0.57      0.548       0.43      0.101\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     28/200      2.89G      1.493     0.9292      1.122        510        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.3it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.726      0.641      0.596      0.229\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     29/200      2.89G      1.546     0.9308      1.116        570        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.4it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846       0.27      0.301      0.131     0.0199\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     30/200      2.89G      1.492     0.9238        1.1        454        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.5it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.687      0.586      0.532      0.156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     31/200      2.89G      1.456     0.9094      1.092        534        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.3it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.373      0.351       0.21     0.0385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     32/200      2.89G      1.462     0.9045      1.092        555        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.2it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.184      0.162     0.0746     0.0131\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     33/200      2.89G      1.451     0.8805      1.087        514        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.4it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.667      0.615      0.531      0.133\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     34/200      2.89G      1.431     0.9013      1.085        378        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.5it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.9it/s 0.2s.2s\n",
      "                   all         93       2846      0.335      0.313      0.172      0.027\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     35/200      2.89G      1.416     0.8927      1.086        545        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.3it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.693      0.646      0.577      0.199\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     36/200      2.89G      1.438     0.8882      1.092        556        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.6it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.6it/s 0.2s.7s\n",
      "                   all         93       2846      0.541      0.481      0.365     0.0611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     37/200      2.89G       1.44     0.8914      1.088        427        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.4it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.536      0.468      0.388      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     38/200      2.89G      1.511     0.9107      1.102        630        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.4it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.514      0.432      0.334     0.0753\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     39/200      2.89G      1.515     0.9238      1.112        415        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.5it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.506      0.463      0.346     0.0693\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     40/200      2.89G       1.44     0.9047      1.076        508        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.4it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.649      0.558      0.503      0.131\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     41/200      2.89G      1.466     0.9047      1.093        591        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.3it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.648      0.581      0.505      0.121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     42/200      2.89G       1.43     0.8634      1.082        525        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.5it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.718      0.618      0.582        0.2\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     43/200      2.89G      1.414     0.8738      1.072        581        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 18.3it/s 1.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.461       0.44        0.3     0.0706\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 15 epochs. Best results observed at epoch 28, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=15) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "43 epochs completed in 0.021 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/20260111_172635_yolov8l/weights/last.pt, 87.6MB\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/20260111_172635_yolov8l/weights/best.pt, 87.6MB\n",
      "\n",
      "Validating /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/20260111_172635_yolov8l/weights/best.pt...\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "Model summary (fused): 112 layers, 43,607,379 parameters, 0 gradients, 164.8 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.725      0.642      0.596      0.229\n",
      "Speed: 0.0ms preprocess, 0.8ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "Model summary (fused): 112 layers, 43,607,379 parameters, 0 gradients, 164.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3802.0Â±1544.8 MB/s, size: 153.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 446.8Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 6/6 3.9it/s 1.5s0.8s\n",
      "                   all         93       2846      0.724      0.641      0.596      0.229\n",
      "Speed: 0.2ms preprocess, 10.2ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/val33\u001b[0m\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 4292.2Â±1284.6 MB/s, size: 131.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/test.cache... 45 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 223.1Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.3it/s 0.9s0.9s\n",
      "                   all         45       1150      0.764      0.687      0.649      0.241\n",
      "Speed: 0.5ms preprocess, 12.6ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/val34\u001b[0m\n",
      "yolov8l: val_f1=0.6802, test_f1=0.7236, test_map50=0.6487\n",
      "\n",
      "Tuning yolo12l for 10 iterations\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mInitialized Tuner instance with 'tune_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune'\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mğŸ’¡ Learn about tuning at https://docs.ultralytics.com/guides/hyperparameter-tuning\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 1/10 with hyperparameters: {'lr0': 0.01, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'box': 7.5, 'cls': 0.5, 'dfl': 1.5, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 10}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo12l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 4, True, 1.2]\n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 1, True, 1.2]\n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  2   2102784  ultralytics.nn.modules.block.A2C2f           [1024, 512, 2, False, -1, True, 1.2]\n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  2    592640  ultralytics.nn.modules.block.A2C2f           [1024, 256, 2, False, -1, True, 1.2]\n",
      " 15                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  2   2037248  ultralytics.nn.modules.block.A2C2f           [768, 512, 2, False, -1, True, 1.2]\n",
      " 18                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 21        [14, 17, 20]  1   1411795  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "YOLOv12l summary: 488 layers, 26,389,875 parameters, 26,389,859 gradients, 89.4 GFLOPs\n",
      "\n",
      "Transferred 1239/1245 items from pretrained weights\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3758.2Â±1525.6 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 16.2Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3393.8Â±2112.6 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.7Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 205 weight(decay=0.0), 214 weight(decay=0.0005), 211 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.42G      3.919      2.507      1.824        496        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.6it/s 4.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.7it/s 1.8s5.9s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20       2.8G      2.414      1.314      1.166        790        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.7it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 22.5it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20       2.8G      2.364      1.308      1.147        570        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 22.5it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20       2.8G      2.281      1.247      1.127        514        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.124      0.533     0.0956     0.0318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20       2.8G      2.235      1.239      1.095        531        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.6it/s 0.2s.2s\n",
      "                   all         93       2846     0.0413      0.013    0.00349   0.000611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20       2.8G      2.268      1.219      1.095        529        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 21.7it/s 0.1s\n",
      "                   all         93       2846     0.0522    0.00422    0.00809    0.00246\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20       2.8G      2.216      1.232      1.097        433        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.176      0.201     0.0845     0.0149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20       2.8G       2.17      1.232      1.072        532        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.1it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.167      0.183     0.0615     0.0104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20       2.8G      2.081      1.184       1.06        410        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.6it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.381      0.478      0.312     0.0808\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20       2.8G       2.27      1.226      1.084        420        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.1it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846     0.0333     0.0158    0.00457     0.0012\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20       2.8G      2.117      1.268      1.078        416        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.1it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.035      0.033     0.0106    0.00308\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20       2.8G      1.965      1.223      1.038        355        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.1it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.431      0.422      0.291     0.0574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20       2.8G      1.897       1.17      1.036        251        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.6it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.0it/s 0.2s.2s\n",
      "                   all         93       2846     0.0471     0.0597     0.0095    0.00153\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20       2.8G      1.942      1.199      1.045        219        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.6it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.8it/s 0.2s.3s\n",
      "                   all         93       2846       0.68      0.621      0.559      0.185\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20       2.8G      1.862      1.134      1.026        283        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.0it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.191      0.153     0.0569    0.00793\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20       2.8G      1.858      1.146      1.019        270        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.9it/s 0.2s.2s\n",
      "                   all         93       2846      0.699      0.654      0.588      0.205\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20       2.8G      1.842      1.139       1.02        467        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.1it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.719      0.605      0.574      0.175\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20       2.8G      1.827      1.161      1.014        275        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.1it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846       0.69      0.579      0.538      0.142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20       2.8G      1.766      1.107     0.9983        369        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.8it/s 0.2s.3s\n",
      "                   all         93       2846       0.74      0.649      0.607      0.232\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20       2.8G      1.797        1.1      1.009        315        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.0it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846       0.74      0.644      0.603      0.216\n",
      "\n",
      "20 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 53.5MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m1/10 iterations complete âœ… (42.54s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.21559 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.73975, 'metrics/recall(B)': 0.64418, 'metrics/mAP50(B)': 0.60341, 'metrics/mAP50-95(B)': 0.21559, 'val/box_loss': 2.21944, 'val/cls_loss': 1.19396, 'val/dfl_loss': 1.04535, 'fitness': 0.21559}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 2/10 with hyperparameters: {'lr0': 0.00979, 'lrf': 0.01, 'momentum': 0.98, 'weight_decay': 0.00048, 'warmup_epochs': 3.0, 'warmup_momentum': 0.73752, 'box': 7.5, 'cls': 0.5, 'dfl': 2.31385, 'hsv_h': 0.015, 'hsv_s': 0.4697, 'hsv_v': 0.37203, 'degrees': 0.0, 'translate': 0.12275, 'scale': 0.45164, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.39258, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 9}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=9, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=2.31385, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.39258, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.4697, hsv_v=0.37203, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00979, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo12l.pt, momentum=0.98, mosaic=1.0, multi_scale=False, name=train45, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train45, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.45164, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.12275, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.73752, weight_decay=0.00048, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 4, True, 1.2]\n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 1, True, 1.2]\n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  2   2102784  ultralytics.nn.modules.block.A2C2f           [1024, 512, 2, False, -1, True, 1.2]\n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  2    592640  ultralytics.nn.modules.block.A2C2f           [1024, 256, 2, False, -1, True, 1.2]\n",
      " 15                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  2   2037248  ultralytics.nn.modules.block.A2C2f           [768, 512, 2, False, -1, True, 1.2]\n",
      " 18                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 21        [14, 17, 20]  1   1411795  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "YOLOv12l summary: 488 layers, 26,389,875 parameters, 26,389,859 gradients, 89.4 GFLOPs\n",
      "\n",
      "Transferred 1239/1245 items from pretrained weights\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 4872.3Â±1241.7 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 14.9Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3729.6Â±2225.5 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.8Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.00979' and 'momentum=0.98' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 205 weight(decay=0.0), 214 weight(decay=0.00048), 211 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train45\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.42G      3.911      2.523      2.789        478        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.6it/s 4.4s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.7it/s 1.8s6.0s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20       2.8G       2.35      1.292      1.771        758        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.6it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 22.5it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20       2.8G      2.229      1.215      1.706        559        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.8it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 22.6it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20       2.8G      2.273      1.208      1.736        498        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 22.4it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20       2.8G      2.206      1.224      1.679        527        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.6it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 21.2it/s 0.1s\n",
      "                   all         93       2846     0.0489     0.0148     0.0125    0.00373\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20       2.8G      2.141      1.168      1.644        517        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.2it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 22.1it/s 0.1s\n",
      "                   all         93       2846      0.163     0.0112     0.0474     0.0124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20       2.8G      2.108      1.197      1.644        425        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.0it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846     0.0481     0.0892     0.0189    0.00306\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20       2.8G      2.108      1.197      1.632        517        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.1it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.212      0.262     0.0995     0.0171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20       2.8G      2.023      1.167      1.605        401        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.0it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.413      0.514      0.386      0.122\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20       2.8G      2.078      1.155      1.607        400        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.1it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846     0.0365     0.0453    0.00785    0.00207\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20       2.8G      1.972      1.137      1.581        629        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.423      0.439      0.307     0.0567\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20       2.8G      1.921      1.195      1.572        380        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.2it/s 0.2s.2s\n",
      "                   all         93       2846      0.696      0.627      0.578      0.226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20       2.8G      1.938      1.152      1.597        275        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.1it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.503      0.482       0.33     0.0603\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20       2.8G       1.87      1.171      1.566        215        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.0it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.251      0.264      0.111     0.0169\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20       2.8G      1.797       1.15      1.552        282        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.2it/s 0.2s.2s\n",
      "                   all         93       2846      0.727      0.653      0.597       0.23\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20       2.8G      1.857      1.121      1.548        262        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.5it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.534      0.494      0.352     0.0621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20       2.8G       1.81      1.135      1.529        452        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.744      0.646      0.604      0.226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20       2.8G      1.777      1.122      1.526        273        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.0it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.678      0.615      0.542      0.135\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20       2.8G       1.76      1.092      1.534        343        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.6it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.744      0.665      0.616       0.23\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20       2.8G       1.72      1.062      1.521        297        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.2it/s 0.2s.2s\n",
      "                   all         93       2846      0.736      0.654      0.603      0.204\n",
      "\n",
      "20 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train45/weights/last.pt, 53.5MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m2/10 iterations complete âœ… (85.11s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.21559 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.73975, 'metrics/recall(B)': 0.64418, 'metrics/mAP50(B)': 0.60341, 'metrics/mAP50-95(B)': 0.21559, 'val/box_loss': 2.21944, 'val/cls_loss': 1.19396, 'val/dfl_loss': 1.04535, 'fitness': 0.21559}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 3/10 with hyperparameters: {'lr0': 0.01, 'lrf': 0.00779, 'momentum': 0.98, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.68894, 'box': 7.5, 'cls': 0.42094, 'dfl': 1.5, 'hsv_h': 0.01726, 'hsv_s': 0.87655, 'hsv_v': 0.38956, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 7}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=7, cls=0.42094, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01726, hsv_s=0.87655, hsv_v=0.38956, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.00779, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo12l.pt, momentum=0.98, mosaic=1.0, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.68894, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 4, True, 1.2]\n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 1, True, 1.2]\n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  2   2102784  ultralytics.nn.modules.block.A2C2f           [1024, 512, 2, False, -1, True, 1.2]\n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  2    592640  ultralytics.nn.modules.block.A2C2f           [1024, 256, 2, False, -1, True, 1.2]\n",
      " 15                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  2   2037248  ultralytics.nn.modules.block.A2C2f           [768, 512, 2, False, -1, True, 1.2]\n",
      " 18                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 21        [14, 17, 20]  1   1411795  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "YOLOv12l summary: 488 layers, 26,389,875 parameters, 26,389,859 gradients, 89.4 GFLOPs\n",
      "\n",
      "Transferred 1239/1245 items from pretrained weights\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5073.0Â±1461.8 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 16.0Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2196.6Â±1259.3 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.2Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.98' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 205 weight(decay=0.0), 214 weight(decay=0.0005), 211 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.42G      3.972      2.155      1.843        496        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.6it/s 4.4s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.7it/s 1.8s5.9s\n",
      "                   all         93       2846      0.186     0.0555     0.0486     0.0172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20       2.8G      2.444      1.151       1.17        790        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.7it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 22.6it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20       2.8G      2.312      1.132      1.134        570        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 22.0it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20       2.8G      2.257      1.054      1.128        514        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 22.4it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20       2.8G      2.277      1.067       1.11        531        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.6it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 21.3it/s 0.1s\n",
      "                   all         93       2846     0.0466    0.00316    0.00664    0.00333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20       2.8G       2.23      1.022      1.099        529        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846     0.0189     0.0207     0.0029   0.000815\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20       2.8G      2.219      1.023      1.105        433        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.1it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.477      0.442      0.353     0.0948\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20       2.8G      2.215      1.048      1.095        532        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.309      0.384      0.215      0.066\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20       2.8G       2.14      1.007       1.08        410        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.6it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.8it/s 0.2s.3s\n",
      "                   all         93       2846      0.043     0.0278    0.00693    0.00142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20       2.8G      2.184      1.011      1.079        420        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.015     0.0271    0.00271   0.000583\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20       2.8G      2.047     0.9844      1.057        670        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.0it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.314       0.29      0.157     0.0354\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20       2.8G      2.091      1.001      1.077        495        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846       0.51      0.527      0.383     0.0978\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20       2.8G      2.045      1.007      1.062        515        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.5it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.562      0.497      0.394     0.0952\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20       2.8G      2.002      1.027      1.069        223        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.0it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.6it/s 0.2s.2s\n",
      "                   all         93       2846     0.0715      0.112     0.0216    0.00351\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20       2.8G      1.979      1.017      1.063        272        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.707      0.606       0.56      0.175\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20       2.8G      1.904     0.9655      1.056        224        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.9it/s 0.2s.3s\n",
      "                   all         93       2846      0.711      0.601      0.558      0.174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20       2.8G       1.87     0.9623      1.032        467        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.6it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.752      0.637      0.604      0.238\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20       2.8G      1.848     0.9539      1.032        282        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.0it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.648      0.548      0.483      0.105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20       2.8G      1.819     0.9499      1.014        349        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.699      0.609      0.558      0.167\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20       2.8G      1.784     0.9128      1.024        307        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.669        0.6       0.53      0.131\n",
      "\n",
      "20 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 53.5MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m3/10 iterations complete âœ… (128.07s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.21559 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.73975, 'metrics/recall(B)': 0.64418, 'metrics/mAP50(B)': 0.60341, 'metrics/mAP50-95(B)': 0.21559, 'val/box_loss': 2.21944, 'val/cls_loss': 1.19396, 'val/dfl_loss': 1.04535, 'fitness': 0.21559}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 4/10 with hyperparameters: {'lr0': 0.01, 'lrf': 0.00774, 'momentum': 0.98, 'weight_decay': 0.00052, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'box': 8.9572, 'cls': 0.5, 'dfl': 1.60577, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.35261, 'degrees': 0.0, 'translate': 0.07688, 'scale': 0.619, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.46672, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 7}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=8.9572, cache=False, cfg=None, classes=None, close_mosaic=7, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.60577, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.46672, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.35261, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.00774, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo12l.pt, momentum=0.98, mosaic=1.0, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.619, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.07688, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.00052, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 4, True, 1.2]\n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 1, True, 1.2]\n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  2   2102784  ultralytics.nn.modules.block.A2C2f           [1024, 512, 2, False, -1, True, 1.2]\n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  2    592640  ultralytics.nn.modules.block.A2C2f           [1024, 256, 2, False, -1, True, 1.2]\n",
      " 15                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  2   2037248  ultralytics.nn.modules.block.A2C2f           [768, 512, 2, False, -1, True, 1.2]\n",
      " 18                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 21        [14, 17, 20]  1   1411795  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "YOLOv12l summary: 488 layers, 26,389,875 parameters, 26,389,859 gradients, 89.4 GFLOPs\n",
      "\n",
      "Transferred 1239/1245 items from pretrained weights\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 4970.8Â±1316.7 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 13.6Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2406.8Â±1118.7 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.1Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.98' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 205 weight(decay=0.0), 214 weight(decay=0.00052), 211 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.42G      4.685       2.59      1.974        547        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.4it/s 4.5s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.6it/s 1.8s5.9s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20      2.81G       3.03      1.433      1.272        848        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.5it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 22.5it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20      2.81G      2.889      1.284      1.234        608        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.8it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.4it/s 0.2s.2s\n",
      "                   all         93       2846     0.0191      0.113     0.0107     0.0032\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20      2.81G      2.772      1.293      1.229        570        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 22.1it/s 0.1s\n",
      "                   all         93       2846     0.0137   0.000351     0.0118    0.00353\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20      2.81G      2.786      1.295      1.189        556        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.6it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 17.2it/s 0.2s.2s\n",
      "                   all         93       2846     0.0278      0.108     0.0206    0.00652\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20      2.81G       2.78      1.256      1.193        565        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846     0.0462       0.02    0.00492    0.00112\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20      2.81G       2.83      1.303      1.217        467        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.0it/s 0.2s.3s\n",
      "                   all         93       2846     0.0284     0.0692     0.0142    0.00251\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20      2.81G      2.772      1.301      1.184        555        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.6it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.255      0.318      0.138     0.0287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20      2.81G      2.662      1.253      1.171        411        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.0it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.138      0.192     0.0556    0.00989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20      2.81G      2.765      1.255      1.178        430        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.116      0.111     0.0252     0.0046\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20      2.81G      2.645      1.221       1.16        744        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.183       0.16     0.0577      0.012\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20      2.81G      2.652      1.226      1.181        537        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.443       0.55      0.324     0.0816\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20      2.81G      2.531      1.221      1.147        570        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.2it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.9it/s 0.2s.2s\n",
      "                   all         93       2846      0.646      0.548       0.46      0.125\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20      2.81G      2.442      1.252      1.163        214        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.0it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.334      0.298      0.166     0.0319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20      2.81G      2.427      1.196      1.157        262        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.725      0.627      0.577      0.217\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20      2.81G      2.292      1.156      1.141        216        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.713      0.619      0.565      0.202\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20      2.81G      2.267       1.16      1.116        459        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846       0.71      0.629      0.564      0.176\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20      2.81G       2.22      1.138      1.111        273        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.2it/s 0.2s.2s\n",
      "                   all         93       2846       0.58      0.506      0.412     0.0819\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20      2.81G      2.212      1.146      1.098        346        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.691      0.605       0.55      0.153\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20      2.81G       2.17        1.1      1.111        301        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.698      0.612       0.56      0.159\n",
      "\n",
      "20 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 53.5MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m4/10 iterations complete âœ… (170.87s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.21559 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.73975, 'metrics/recall(B)': 0.64418, 'metrics/mAP50(B)': 0.60341, 'metrics/mAP50-95(B)': 0.21559, 'val/box_loss': 2.21944, 'val/cls_loss': 1.19396, 'val/dfl_loss': 1.04535, 'fitness': 0.21559}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 5/10 with hyperparameters: {'lr0': 0.00983, 'lrf': 0.01, 'momentum': 0.96323, 'weight_decay': 0.00046, 'warmup_epochs': 3.0, 'warmup_momentum': 0.72696, 'box': 6.14734, 'cls': 0.5, 'dfl': 2.1216, 'hsv_h': 0.01495, 'hsv_s': 0.51709, 'hsv_v': 0.40094, 'degrees': 0.0, 'translate': 0.11804, 'scale': 0.59307, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.4261, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 9}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=6.14734, cache=False, cfg=None, classes=None, close_mosaic=9, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=2.1216, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.4261, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01495, hsv_s=0.51709, hsv_v=0.40094, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00983, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo12l.pt, momentum=0.96323, mosaic=1.0, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.59307, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.11804, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.72696, weight_decay=0.00046, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 4, True, 1.2]\n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 1, True, 1.2]\n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  2   2102784  ultralytics.nn.modules.block.A2C2f           [1024, 512, 2, False, -1, True, 1.2]\n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  2    592640  ultralytics.nn.modules.block.A2C2f           [1024, 256, 2, False, -1, True, 1.2]\n",
      " 15                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  2   2037248  ultralytics.nn.modules.block.A2C2f           [768, 512, 2, False, -1, True, 1.2]\n",
      " 18                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 21        [14, 17, 20]  1   1411795  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "YOLOv12l summary: 488 layers, 26,389,875 parameters, 26,389,859 gradients, 89.4 GFLOPs\n",
      "\n",
      "Transferred 1239/1245 items from pretrained weights\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3754.3Â±1684.5 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 14.6Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3262.2Â±1757.2 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.7Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.00983' and 'momentum=0.96323' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 205 weight(decay=0.0), 214 weight(decay=0.00046), 211 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.42G      3.147      2.455      2.539        527        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.6it/s 4.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.7it/s 1.8s6.0s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20      2.81G      2.053      1.441      1.643        846        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.5it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 22.6it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20      2.81G      1.953      1.274      1.601        588        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.1it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 22.4it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20      2.81G      1.852      1.249      1.584        554        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.5it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 18.2it/s 0.2s.2s\n",
      "                   all         93       2846    0.00502     0.0116    0.00174   0.000592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20      2.81G      1.892      1.265      1.547        556        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846     0.0158     0.0141    0.00142   0.000257\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20      2.81G      1.924      1.248      1.559        566        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.5it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846    0.00155    0.00351   0.000371   8.46e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20      2.81G      1.877      1.281      1.547        457        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.1it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.3it/s 0.2s.2s\n",
      "                   all         93       2846     0.0168     0.0109    0.00348   0.000631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20      2.81G       1.83      1.264      1.514        543        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.224      0.213     0.0879     0.0199\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20      2.81G      1.758      1.221      1.495        409        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.3it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.382      0.506      0.324     0.0912\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20      2.81G      1.846      1.224      1.514        419        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.2it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.539      0.593      0.467      0.143\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20      2.81G      1.702      1.192       1.47        720        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.9it/s 0.2s.2s\n",
      "                   all         93       2846      0.269      0.212      0.109     0.0198\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20      2.81G      1.652      1.235      1.488        367        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.2it/s 0.2s.2s\n",
      "                   all         93       2846      0.621       0.54      0.476      0.161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20      2.81G      1.599      1.197       1.47        265        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.2it/s 0.2s.2s\n",
      "                   all         93       2846       0.67      0.614       0.55      0.197\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20      2.81G      1.576      1.197      1.461        213        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.6it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846        0.7      0.593      0.546      0.164\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20      2.81G      1.536      1.145      1.455        273        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.1it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.636       0.56       0.49      0.113\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20      2.81G      1.586      1.179      1.453        249        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.1it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846       0.66      0.589      0.515      0.124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20      2.81G      1.532      1.172      1.429        441        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.3it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.709      0.634       0.58      0.204\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20      2.81G      1.531      1.151      1.433        260        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.721      0.626      0.572      0.172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20      2.81G      1.496      1.113      1.449        332        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.736      0.657      0.609      0.234\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20      2.81G      1.456       1.08      1.428        281        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.1it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.713      0.631      0.572      0.168\n",
      "\n",
      "20 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 53.5MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m5/10 iterations complete âœ… (213.51s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.21559 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.73975, 'metrics/recall(B)': 0.64418, 'metrics/mAP50(B)': 0.60341, 'metrics/mAP50-95(B)': 0.21559, 'val/box_loss': 2.21944, 'val/cls_loss': 1.19396, 'val/dfl_loss': 1.04535, 'fitness': 0.21559}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 6/10 with hyperparameters: {'lr0': 0.00979, 'lrf': 0.01056, 'momentum': 0.94757, 'weight_decay': 0.00048, 'warmup_epochs': 3.6816, 'warmup_momentum': 0.72262, 'box': 5.10441, 'cls': 0.50678, 'dfl': 2.27993, 'hsv_h': 0.01501, 'hsv_s': 0.60217, 'hsv_v': 0.38285, 'degrees': 0.0, 'translate': 0.10988, 'scale': 0.4847, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.44237, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 7}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=5.10441, cache=False, cfg=None, classes=None, close_mosaic=7, cls=0.50678, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=2.27993, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.44237, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01501, hsv_s=0.60217, hsv_v=0.38285, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00979, lrf=0.01056, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo12l.pt, momentum=0.94757, mosaic=1.0, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.4847, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.10988, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.6816, warmup_momentum=0.72262, weight_decay=0.00048, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 4, True, 1.2]\n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 1, True, 1.2]\n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  2   2102784  ultralytics.nn.modules.block.A2C2f           [1024, 512, 2, False, -1, True, 1.2]\n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  2    592640  ultralytics.nn.modules.block.A2C2f           [1024, 256, 2, False, -1, True, 1.2]\n",
      " 15                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  2   2037248  ultralytics.nn.modules.block.A2C2f           [768, 512, 2, False, -1, True, 1.2]\n",
      " 18                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 21        [14, 17, 20]  1   1411795  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "YOLOv12l summary: 488 layers, 26,389,875 parameters, 26,389,859 gradients, 89.4 GFLOPs\n",
      "\n",
      "Transferred 1239/1245 items from pretrained weights\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5319.5Â±1456.3 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 14.4Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 4031.8Â±2012.9 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.7Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.00979' and 'momentum=0.94757' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 205 weight(decay=0.0), 214 weight(decay=0.00048), 211 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.42G      2.634      2.489      2.713        486        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.6it/s 4.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.7it/s 1.8s5.9s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20       2.8G      1.643      1.367      1.751        777        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 22.5it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20       2.8G      1.568      1.291      1.705        567        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.2it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 22.5it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20       2.8G      1.579      1.269      1.717        516        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.0it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 21.9it/s 0.1s\n",
      "                   all         93       2846    0.00167   0.000351   0.000428   0.000128\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20       2.8G       1.54      1.243      1.665        529        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 22.4it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20       2.8G      1.536      1.234      1.654        529        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.0it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 17.5it/s 0.2s.2s\n",
      "                   all         93       2846     0.0125    0.00527    0.00139   0.000438\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20       2.8G      1.458       1.21      1.636        427        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.1it/s 0.2s.2s\n",
      "                   all         93       2846     0.0449     0.0372     0.0118    0.00259\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20       2.8G      1.435      1.236      1.605        522        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.2it/s 0.2s.2s\n",
      "                   all         93       2846     0.0569     0.0351     0.0108    0.00181\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20       2.8G      1.397       1.19      1.587        406        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.2it/s 0.2s.2s\n",
      "                   all         93       2846      0.307      0.442      0.261     0.0652\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20       2.8G      1.543      1.206      1.651        410        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.6it/s 0.2s.2s\n",
      "                   all         93       2846     0.0192     0.0119    0.00164   0.000472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20       2.8G       1.41      1.176       1.59        655        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.449      0.397      0.268     0.0469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20       2.8G      1.442      1.214      1.612        491        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846     0.0781      0.123     0.0262    0.00415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20       2.8G       1.39      1.237      1.578        512        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846     0.0533     0.0492    0.00997    0.00177\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20       2.8G      1.348      1.221      1.583        223        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.3it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.9it/s 0.2s.3s\n",
      "                   all         93       2846      0.286      0.262      0.177     0.0315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20       2.8G      1.351      1.178       1.59        272        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.8it/s 0.2s.3s\n",
      "                   all         93       2846      0.758      0.617      0.606      0.264\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20       2.8G       1.28      1.151      1.558        223        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.5it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.567      0.497      0.421     0.0993\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20       2.8G      1.254      1.152      1.519        466        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.2it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846       0.66      0.611      0.531      0.144\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20       2.8G       1.25      1.151      1.528        282        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.2it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.678      0.591      0.522      0.135\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20       2.8G      1.216      1.126        1.5        348        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.0it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.641      0.557      0.476     0.0991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20       2.8G      1.206      1.087      1.517        307        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.0it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.2it/s 0.2s.2s\n",
      "                   all         93       2846      0.706      0.622      0.572      0.166\n",
      "\n",
      "20 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 53.5MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m6/10 iterations complete âœ… (255.87s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.21559 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.73975, 'metrics/recall(B)': 0.64418, 'metrics/mAP50(B)': 0.60341, 'metrics/mAP50-95(B)': 0.21559, 'val/box_loss': 2.21944, 'val/cls_loss': 1.19396, 'val/dfl_loss': 1.04535, 'fitness': 0.21559}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 7/10 with hyperparameters: {'lr0': 0.00994, 'lrf': 0.00867, 'momentum': 0.9648, 'weight_decay': 0.00049, 'warmup_epochs': 2.60678, 'warmup_momentum': 0.70293, 'box': 7.5, 'cls': 0.5, 'dfl': 1.85556, 'hsv_h': 0.015, 'hsv_s': 0.52939, 'hsv_v': 0.39121, 'degrees': 0.0, 'translate': 0.12242, 'scale': 0.47354, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.46065, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 9}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=9, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.85556, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.46065, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.52939, hsv_v=0.39121, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00994, lrf=0.00867, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo12l.pt, momentum=0.9648, mosaic=1.0, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.47354, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.12242, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=2.60678, warmup_momentum=0.70293, weight_decay=0.00049, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 4, True, 1.2]\n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 1, True, 1.2]\n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  2   2102784  ultralytics.nn.modules.block.A2C2f           [1024, 512, 2, False, -1, True, 1.2]\n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  2    592640  ultralytics.nn.modules.block.A2C2f           [1024, 256, 2, False, -1, True, 1.2]\n",
      " 15                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  2   2037248  ultralytics.nn.modules.block.A2C2f           [768, 512, 2, False, -1, True, 1.2]\n",
      " 18                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 21        [14, 17, 20]  1   1411795  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "YOLOv12l summary: 488 layers, 26,389,875 parameters, 26,389,859 gradients, 89.4 GFLOPs\n",
      "\n",
      "Transferred 1239/1245 items from pretrained weights\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 4099.3Â±2008.2 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 16.0Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3951.2Â±2145.2 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.7Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.00994' and 'momentum=0.9648' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 205 weight(decay=0.0), 214 weight(decay=0.00049), 211 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.42G      3.847       2.47      2.206        481        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.6it/s 4.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.7it/s 1.8s6.0s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20       2.8G      2.392       1.37      1.428        767        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.6it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 22.0it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20       2.8G      2.296      1.289      1.385        563        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.1it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 21.9it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20       2.8G      2.345      1.265      1.409        508        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.6it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 22.5it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20       2.8G      2.247      1.245      1.358        537        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.6it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 21.5it/s 0.1s\n",
      "                   all         93       2846     0.0127    0.00141    0.00177   0.000222\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20       2.8G      2.209      1.204      1.339        530        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.0it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.019     0.0235    0.00369   0.000854\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20       2.8G      2.139      1.212      1.323        427        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.1it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846     0.0982        0.2     0.0435    0.00673\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20       2.8G      2.086      1.193      1.304        519        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.182      0.222     0.0921     0.0163\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20       2.8G      1.984      1.166      1.277        405        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.7it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.9it/s 0.2s.3s\n",
      "                   all         93       2846     0.0677      0.104      0.034     0.0082\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20       2.8G      2.134      1.178      1.304        404        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846     0.0632     0.0632     0.0143    0.00273\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20       2.8G      2.032      1.178      1.286        639        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.0it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.384      0.365      0.216     0.0359\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20       2.8G      1.957      1.208      1.271        379        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.1it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.672      0.604      0.554      0.213\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20       2.8G      1.885      1.159       1.26        275        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846       0.36      0.357      0.183     0.0303\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20       2.8G      1.876      1.161      1.263        215        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.424      0.385      0.249     0.0418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20       2.8G      1.803      1.104      1.252        282        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.1it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.9it/s 0.2s.2s\n",
      "                   all         93       2846      0.652      0.568       0.49      0.108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20       2.8G      1.868      1.132      1.252        261        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846        0.7      0.625      0.572      0.181\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20       2.8G      1.799      1.132      1.227        451        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.0it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.745      0.648      0.609      0.234\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20       2.8G      1.785      1.114       1.23        274        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.716      0.637       0.58      0.172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20       2.8G      1.776      1.092      1.237        341        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.744      0.663      0.616      0.248\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20       2.8G      1.727      1.067      1.222        293        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.734      0.641      0.597      0.205\n",
      "\n",
      "20 epochs completed in 0.010 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 53.5MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m7/10 iterations complete âœ… (298.29s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.21559 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.73975, 'metrics/recall(B)': 0.64418, 'metrics/mAP50(B)': 0.60341, 'metrics/mAP50-95(B)': 0.21559, 'val/box_loss': 2.21944, 'val/cls_loss': 1.19396, 'val/dfl_loss': 1.04535, 'fitness': 0.21559}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 8/10 with hyperparameters: {'lr0': 0.0098, 'lrf': 0.01036, 'momentum': 0.96344, 'weight_decay': 0.00047, 'warmup_epochs': 3.83468, 'warmup_momentum': 0.80511, 'box': 7.12554, 'cls': 0.50612, 'dfl': 2.36027, 'hsv_h': 0.02068, 'hsv_s': 0.6182, 'hsv_v': 0.37453, 'degrees': 0.0, 'translate': 0.0958, 'scale': 0.49527, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.44264, 'bgr': 0.0, 'mosaic': 0.9146, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 7}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.12554, cache=False, cfg=None, classes=None, close_mosaic=7, cls=0.50612, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=2.36027, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.44264, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.02068, hsv_s=0.6182, hsv_v=0.37453, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0098, lrf=0.01036, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo12l.pt, momentum=0.96344, mosaic=0.9146, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.49527, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.0958, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.83468, warmup_momentum=0.80511, weight_decay=0.00047, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 4, True, 1.2]\n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 1, True, 1.2]\n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  2   2102784  ultralytics.nn.modules.block.A2C2f           [1024, 512, 2, False, -1, True, 1.2]\n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  2    592640  ultralytics.nn.modules.block.A2C2f           [1024, 256, 2, False, -1, True, 1.2]\n",
      " 15                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  2   2037248  ultralytics.nn.modules.block.A2C2f           [768, 512, 2, False, -1, True, 1.2]\n",
      " 18                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 21        [14, 17, 20]  1   1411795  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "YOLOv12l summary: 488 layers, 26,389,875 parameters, 26,389,859 gradients, 89.4 GFLOPs\n",
      "\n",
      "Transferred 1239/1245 items from pretrained weights\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 4755.4Â±1134.1 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 14.1Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3847.4Â±2352.7 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.8Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.0098' and 'momentum=0.96344' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 205 weight(decay=0.0), 214 weight(decay=0.00047), 211 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.44G      3.775      2.599      2.851        479        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.7it/s 4.3s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.7it/s 1.8s5.8s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20      2.83G      2.276      1.357      1.826        749        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 23.9it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20      2.83G      2.194      1.296      1.792        330        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 23.9it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20      2.83G      2.196      1.273      1.767        554        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.8it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 23.2it/s 0.1s\n",
      "                   all         93       2846    0.00448   0.000351   0.000702    0.00021\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20      2.83G      2.081      1.272      1.697        381        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.6it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.9it/s 0.2s.2s\n",
      "                   all         93       2846      0.143      0.213     0.0525    0.00941\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20      2.83G      2.048      1.245      1.697        502        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.3it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.5it/s 0.2s.2s\n",
      "                   all         93       2846     0.0134     0.0545    0.00445   0.000689\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20      2.83G      2.103      1.252      1.699        459        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.0it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.3it/s 0.2s.2s\n",
      "                   all         93       2846     0.0358      0.044    0.00875    0.00175\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20      2.83G      2.021      1.223      1.661        544        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.5it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.263      0.309      0.141     0.0317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20      2.83G      2.019       1.22      1.666        364        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.0it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.2it/s 0.2s.2s\n",
      "                   all         93       2846     0.0546     0.0661     0.0161    0.00505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20      2.83G      1.999      1.205      1.656        580        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.4it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.423       0.45      0.298     0.0667\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20      2.83G      1.946      1.184      1.618        439        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.9it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.204      0.219     0.0854     0.0157\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20      2.83G      1.869      1.158      1.588        463        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.603      0.571      0.468       0.12\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20      2.83G      1.869      1.164      1.608        730        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.9it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.114      0.171     0.0388     0.0067\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20      2.83G      1.787      1.201        1.6        224        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.2it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.292      0.259      0.144     0.0244\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20      2.83G      1.797      1.141      1.612        271        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.8it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.2it/s 0.2s.2s\n",
      "                   all         93       2846      0.713      0.628      0.592      0.206\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20      2.83G      1.735      1.133      1.598        227        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.9it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.718      0.639      0.598      0.239\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20      2.83G      1.731      1.159       1.57        467        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.8it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.4it/s 0.2s.2s\n",
      "                   all         93       2846       0.64      0.578       0.48      0.113\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20      2.83G      1.712      1.136      1.573        284        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.9it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.6it/s 0.2s.2s\n",
      "                   all         93       2846       0.53      0.456      0.342     0.0667\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20      2.83G      1.671      1.115      1.543        352        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.8it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.663      0.608      0.532       0.13\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20      2.83G      1.664      1.088      1.564        307        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.8it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.679      0.619      0.548      0.149\n",
      "\n",
      "20 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 53.5MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m8/10 iterations complete âœ… (339.00s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.21559 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.73975, 'metrics/recall(B)': 0.64418, 'metrics/mAP50(B)': 0.60341, 'metrics/mAP50-95(B)': 0.21559, 'val/box_loss': 2.21944, 'val/cls_loss': 1.19396, 'val/dfl_loss': 1.04535, 'fitness': 0.21559}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 9/10 with hyperparameters: {'lr0': 0.00874, 'lrf': 0.00798, 'momentum': 0.97378, 'weight_decay': 0.00051, 'warmup_epochs': 3.49708, 'warmup_momentum': 0.6871, 'box': 9.00772, 'cls': 0.5008, 'dfl': 2.05195, 'hsv_h': 0.01501, 'hsv_s': 0.84848, 'hsv_v': 0.34353, 'degrees': 0.0, 'translate': 0.0787, 'scale': 0.42381, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.40764, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 8}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=9.00772, cache=False, cfg=None, classes=None, close_mosaic=8, cls=0.5008, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=2.05195, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.40764, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01501, hsv_s=0.84848, hsv_v=0.34353, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00874, lrf=0.00798, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo12l.pt, momentum=0.97378, mosaic=1.0, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.42381, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.0787, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.49708, warmup_momentum=0.6871, weight_decay=0.00051, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 4, True, 1.2]\n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 1, True, 1.2]\n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  2   2102784  ultralytics.nn.modules.block.A2C2f           [1024, 512, 2, False, -1, True, 1.2]\n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  2    592640  ultralytics.nn.modules.block.A2C2f           [1024, 256, 2, False, -1, True, 1.2]\n",
      " 15                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  2   2037248  ultralytics.nn.modules.block.A2C2f           [768, 512, 2, False, -1, True, 1.2]\n",
      " 18                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 21        [14, 17, 20]  1   1411795  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "YOLOv12l summary: 488 layers, 26,389,875 parameters, 26,389,859 gradients, 89.4 GFLOPs\n",
      "\n",
      "Transferred 1239/1245 items from pretrained weights\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5555.2Â±1387.2 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 15.4Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3828.3Â±1843.5 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.5Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.00874' and 'momentum=0.97378' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 205 weight(decay=0.0), 214 weight(decay=0.00051), 211 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.42G      4.696      2.493      2.498        470        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.7it/s 4.3s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.7it/s 1.8s5.8s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20       2.8G      2.811      1.309      1.576        744        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.6it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 24.0it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20       2.8G      2.682      1.251      1.532        558        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.241       0.31      0.136     0.0434\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20       2.8G      2.693      1.208      1.536        493        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.9it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.109      0.246     0.0481    0.00892\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20       2.8G      2.674      1.212      1.503        519        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.5it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.7it/s 0.2s.2s\n",
      "                   all         93       2846     0.0185     0.0246      0.003   0.000857\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20       2.8G      2.589      1.201      1.483        505        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.4it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.019     0.0474    0.00401   0.000902\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20       2.8G      2.543      1.182      1.477        426        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.0it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.9it/s 0.2s.2s\n",
      "                   all         93       2846      0.253      0.278       0.15      0.026\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20       2.8G      2.513      1.195      1.455        501        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.7it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.129     0.0768     0.0272    0.00323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20       2.8G       2.43      1.173      1.438        403        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.7it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.1it/s 0.2s.2s\n",
      "                   all         93       2846     0.0492     0.0689     0.0141    0.00194\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20       2.8G      2.448       1.15      1.441        409        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.9it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.6it/s 0.2s.2s\n",
      "                   all         93       2846     0.0547     0.0467    0.00801    0.00236\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20       2.8G      2.375      1.143      1.421        619        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.6it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.6it/s 0.2s.2s\n",
      "                   all         93       2846     0.0452     0.0696       0.01    0.00181\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20       2.8G      2.448      1.157      1.448        464        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.3it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.6it/s 0.2s.2s\n",
      "                   all         93       2846     0.0544     0.0439    0.00733    0.00196\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20       2.8G       2.31      1.157      1.447        272        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.6it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.588      0.524      0.434     0.0897\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20       2.8G      2.312       1.17      1.429        236        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.2it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.0it/s 0.2s.2s\n",
      "                   all         93       2846       0.18      0.189     0.0685    0.00997\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20       2.8G      2.323      1.135      1.433        242        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.9it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.6it/s 0.2s.2s\n",
      "                   all         93       2846        0.5      0.441      0.319     0.0511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20       2.8G      2.228      1.131      1.398        223        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.0it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.672      0.606      0.534      0.148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20       2.8G      2.147       1.11       1.39        441        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.7it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.725      0.644      0.594      0.206\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20       2.8G      2.147      1.135      1.373        270        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.7it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.2it/s 0.2s.2s\n",
      "                   all         93       2846      0.734      0.645      0.597      0.207\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20       2.8G       2.12        1.1      1.386        363        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.8it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.2it/s 0.2s.2s\n",
      "                   all         93       2846      0.749      0.648      0.607      0.224\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20       2.8G      2.108      1.061      1.381        332        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.9it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.4it/s 0.2s.2s\n",
      "                   all         93       2846       0.75      0.651       0.61      0.219\n",
      "\n",
      "20 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 53.5MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m9/10 iterations complete âœ… (379.74s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.21895 observed at iteration 9\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.75015, 'metrics/recall(B)': 0.65109, 'metrics/mAP50(B)': 0.6098, 'metrics/mAP50-95(B)': 0.21895, 'val/box_loss': 2.75804, 'val/cls_loss': 1.15991, 'val/dfl_loss': 1.48879, 'fitness': 0.21895}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00874\n",
      "lrf: 0.00798\n",
      "momentum: 0.97378\n",
      "weight_decay: 0.00051\n",
      "warmup_epochs: 3.49708\n",
      "warmup_momentum: 0.6871\n",
      "box: 9.00772\n",
      "cls: 0.5008\n",
      "dfl: 2.05195\n",
      "hsv_h: 0.01501\n",
      "hsv_s: 0.84848\n",
      "hsv_v: 0.34353\n",
      "degrees: 0.0\n",
      "translate: 0.0787\n",
      "scale: 0.42381\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.40764\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 8.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 10/10 with hyperparameters: {'lr0': 0.01007, 'lrf': 0.01083, 'momentum': 0.9155, 'weight_decay': 0.00054, 'warmup_epochs': 3.04299, 'warmup_momentum': 0.68262, 'box': 8.39357, 'cls': 0.46091, 'dfl': 1.73011, 'hsv_h': 0.02157, 'hsv_s': 0.59593, 'hsv_v': 0.39413, 'degrees': 0.0, 'translate': 0.1226, 'scale': 0.48589, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.39998, 'bgr': 0.0, 'mosaic': 0.78239, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 7}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=8.39357, cache=False, cfg=None, classes=None, close_mosaic=7, cls=0.46091, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.73011, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.39998, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.02157, hsv_s=0.59593, hsv_v=0.39413, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01007, lrf=0.01083, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo12l.pt, momentum=0.9155, mosaic=0.78239, multi_scale=False, name=train46, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train46, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.48589, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1226, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.04299, warmup_momentum=0.68262, weight_decay=0.00054, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 4, True, 1.2]\n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 1, True, 1.2]\n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  2   2102784  ultralytics.nn.modules.block.A2C2f           [1024, 512, 2, False, -1, True, 1.2]\n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  2    592640  ultralytics.nn.modules.block.A2C2f           [1024, 256, 2, False, -1, True, 1.2]\n",
      " 15                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  2   2037248  ultralytics.nn.modules.block.A2C2f           [768, 512, 2, False, -1, True, 1.2]\n",
      " 18                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 21        [14, 17, 20]  1   1411795  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "YOLOv12l summary: 488 layers, 26,389,875 parameters, 26,389,859 gradients, 89.4 GFLOPs\n",
      "\n",
      "Transferred 1239/1245 items from pretrained weights\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3971.9Â±1809.4 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 14.4Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 4181.1Â±2490.8 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 2.0Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01007' and 'momentum=0.9155' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 205 weight(decay=0.0), 214 weight(decay=0.00054), 211 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train46\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/20      2.39G      4.293      2.368      2.084        400        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.7it/s 4.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.6it/s 1.8s6.1s\n",
      "                   all         93       2846      0.162      0.465      0.125     0.0401\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/20      2.78G      2.687      1.161      1.354        591        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.4it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 24.0it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/20      2.78G      2.546       1.19      1.322        357        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.4it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 23.8it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/20      2.78G      2.531      1.221      1.299        485        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.4it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 23.5it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/20      2.78G      2.484      1.135      1.268        580        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.7it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.5it/s 0.2s.2s\n",
      "                   all         93       2846    0.00296    0.00246   0.000497   6.09e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/20      2.78G      2.416      1.148      1.239        365        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.8it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.6it/s 0.2s.2s\n",
      "                   all         93       2846     0.0598     0.0678     0.0144    0.00199\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/20      2.78G      2.439      1.119      1.248        484        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.3it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 20.2it/s 0.1s.2s\n",
      "                   all         93       2846     0.0706     0.0183     0.0113    0.00236\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/20      2.78G      2.332      1.123      1.232        423        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.5it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.142      0.117     0.0437    0.00661\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/20      2.78G      2.351      1.093      1.217        465        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.5it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.7it/s 0.2s.2s\n",
      "                   all         93       2846     0.0332      0.046    0.00807    0.00146\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/20      2.78G      2.285      1.049      1.213        558        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.8it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.163      0.225     0.0665     0.0111\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/20      2.78G      2.166      1.053      1.182        528        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.7it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.603      0.579      0.493      0.176\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/20      2.78G      2.241      1.073      1.198        543        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.7it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.112      0.144      0.035    0.00908\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/20      2.78G      2.258      1.044      1.191        394        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.7it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.586      0.541      0.436      0.131\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/20      2.78G      2.169      1.105      1.191        222        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.3it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.212      0.183      0.079     0.0112\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/20      2.78G      2.125      1.072      1.185        269        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 17.1it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.133     0.0984     0.0402    0.00896\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/20      2.78G      2.049      1.037      1.173        223        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.8it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.496      0.426      0.329     0.0612\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/20      2.78G      2.046       1.04      1.159        466        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.8it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.647      0.549      0.488      0.113\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/20      2.78G      2.017      1.052      1.159        281        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.7it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.609      0.511      0.432     0.0886\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/20      2.78G      1.975      1.028       1.14        344        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.7it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.687      0.633      0.563      0.171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/20      2.78G      1.966     0.9976      1.156        307        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 16.5it/s 1.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.706      0.628      0.571      0.169\n",
      "\n",
      "20 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train46/weights/last.pt, 53.5MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m10/10 iterations complete âœ… (420.47s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.21895 observed at iteration 9\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.75015, 'metrics/recall(B)': 0.65109, 'metrics/mAP50(B)': 0.6098, 'metrics/mAP50-95(B)': 0.21895, 'val/box_loss': 2.75804, 'val/cls_loss': 1.15991, 'val/dfl_loss': 1.48879, 'fitness': 0.21895}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_yolo12l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00874\n",
      "lrf: 0.00798\n",
      "momentum: 0.97378\n",
      "weight_decay: 0.00051\n",
      "warmup_epochs: 3.49708\n",
      "warmup_momentum: 0.6871\n",
      "box: 9.00772\n",
      "cls: 0.5008\n",
      "dfl: 2.05195\n",
      "hsv_h: 0.01501\n",
      "hsv_s: 0.84848\n",
      "hsv_v: 0.34353\n",
      "degrees: 0.0\n",
      "translate: 0.0787\n",
      "scale: 0.42381\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.40764\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 8.0\n",
      "\n",
      "yolo12l tuning complete. Best hyperparameters saved to runs/detect/20260111_172635_yolo12l_tune/best_hyperparameters.yaml\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=9.00772, cache=False, cfg=None, classes=None, close_mosaic=8, cls=0.5008, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=2.05195, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=200, erasing=0.4, exist_ok=False, fliplr=0.40764, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01501, hsv_s=0.84848, hsv_v=0.34353, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00874, lrf=0.00798, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo12l.pt, momentum=0.97378, mosaic=1.0, multi_scale=False, name=20260111_172635_yolo12l, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/20260111_172635_yolo12l, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.42381, seed=64, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.0787, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.49708, warmup_momentum=0.6871, weight_decay=0.00051, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 4, True, 1.2]\n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 1, True, 1.2]\n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  2   2102784  ultralytics.nn.modules.block.A2C2f           [1024, 512, 2, False, -1, True, 1.2]\n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  2    592640  ultralytics.nn.modules.block.A2C2f           [1024, 256, 2, False, -1, True, 1.2]\n",
      " 15                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  2   2037248  ultralytics.nn.modules.block.A2C2f           [768, 512, 2, False, -1, True, 1.2]\n",
      " 18                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 21        [14, 17, 20]  1   1411795  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "YOLOv12l summary: 488 layers, 26,389,875 parameters, 26,389,859 gradients, 89.4 GFLOPs\n",
      "\n",
      "Transferred 1239/1245 items from pretrained weights\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5310.6Â±1058.4 MB/s, size: 152.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 2.0Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1541.9Â±221.6 MB/s, size: 142.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 189.6Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.00874' and 'momentum=0.97378' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 205 weight(decay=0.0), 214 weight(decay=0.00051), 211 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/20260111_172635_yolo12l\u001b[0m\n",
      "Starting training for 200 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/200      2.41G      4.735      2.794      2.528        470        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 12.6it/s 1.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 23.6it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/200      2.88G      2.804       1.29      1.575        744        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.8it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 23.8it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/200      2.98G      2.651      1.289      1.516        558        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.0it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 23.3it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/200      3.07G      2.616      1.212      1.513        493        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 23.0it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/200      3.17G        2.6      1.219      1.478        519        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.4it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 23.1it/s 0.1s\n",
      "                   all         93       2846          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/200      3.17G      2.611      1.221      1.476        505        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.1it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 17.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.099      0.104     0.0267    0.00863\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/200      3.17G      2.636      1.264      1.491        426        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.8it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.6it/s 0.2s.3s\n",
      "                   all         93       2846      0.166      0.218     0.0747     0.0109\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/200      3.17G      2.581       1.26      1.459        501        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846       0.18      0.204     0.0681    0.00879\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/200      3.17G      2.469      1.222      1.429        403        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.8it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.195      0.199     0.0755     0.0102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/200      3.17G      2.596      1.217      1.458        409        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.8it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846     0.0608     0.0738     0.0124    0.00279\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/200      3.26G      2.413      1.212      1.407        619        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.036     0.0682    0.00984     0.0016\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/200      3.26G      2.545       1.19      1.455        464        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.8it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 15.0it/s 0.2s.2s\n",
      "                   all         93       2846     0.0415     0.0137    0.00787    0.00345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/200      3.26G      2.525      1.244      1.447        497        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.0it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.122      0.238     0.0563       0.01\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/200      3.26G      2.503      1.224       1.42        519        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.4it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.397      0.623       0.34     0.0806\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/200      3.26G      2.497      1.228      1.418        598        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.0it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.252      0.219      0.133     0.0259\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/200      3.26G      2.417      1.217      1.406        382        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.8it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846      0.319      0.234      0.128     0.0215\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/200      3.26G      2.356      1.175      1.386        464        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846       0.55      0.481      0.398     0.0795\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/200      3.26G      2.421      1.179        1.4        415        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.7it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.116      0.109     0.0381    0.00929\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/200      3.26G      2.334      1.184      1.377        409        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.0it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.389      0.475       0.25     0.0444\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/200      3.26G      2.293      1.205      1.376        571        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.0it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846       0.13      0.129      0.035    0.00511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/200      3.26G      2.295      1.182      1.372        464        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.7it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846     0.0266     0.0485    0.00881    0.00157\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/200      3.26G      2.279      1.143      1.368        587        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 13.8it/s 1.5s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.573      0.549      0.419     0.0853\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/200      3.26G      2.254      1.154      1.366        370        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.3it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.679      0.627      0.543       0.18\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/200      3.26G      2.301      1.174      1.366        569        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.1it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.2it/s 0.2s.2s\n",
      "                   all         93       2846      0.628      0.593      0.493      0.133\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/200      3.26G      2.264      1.122       1.36        542        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.1it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.528      0.443      0.349     0.0654\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/200      3.26G      2.256      1.135      1.348        462        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.5it/s 0.2s.2s\n",
      "                   all         93       2846      0.112      0.105     0.0249    0.00366\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     27/200      3.26G      2.301      1.162      1.361        485        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.0it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.9it/s 0.2s.3s\n",
      "                   all         93       2846      0.335       0.29      0.151     0.0281\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     28/200      3.26G      2.262       1.14      1.371        511        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.1it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.707      0.634      0.581      0.223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     29/200      3.26G      2.387      1.153      1.374        573        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.7it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.367      0.378      0.197     0.0316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     30/200      3.26G      2.257       1.14      1.361        462        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.3it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.3it/s 0.2s.2s\n",
      "                   all         93       2846       0.66      0.564        0.5      0.139\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     31/200      3.26G      2.344      1.156      1.374        539        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.6it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.7it/s 0.2s.3s\n",
      "                   all         93       2846       0.44       0.42      0.262     0.0437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     32/200      3.26G      2.251      1.148      1.348        549        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.5it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.6it/s 0.2s.2s\n",
      "                   all         93       2846     0.0513     0.0647     0.0163      0.003\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     33/200      3.26G      2.249      1.103      1.346        518        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.0it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.7it/s 0.2s.3s\n",
      "                   all         93       2846      0.536      0.519      0.376     0.0691\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     34/200      3.26G      2.224      1.117      1.345        382        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.0it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.535       0.49      0.363      0.084\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     35/200      3.26G      2.197      1.098      1.344        546        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.2it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.3it/s 0.2s.2s\n",
      "                   all         93       2846      0.652      0.588      0.511      0.137\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     36/200      3.26G        2.2      1.117      1.346        574        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.8it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.278      0.246      0.119     0.0164\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     37/200      3.26G      2.198      1.125      1.344        429        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 15.1it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.8it/s 0.2s.2s\n",
      "                   all         93       2846      0.662      0.606       0.53      0.169\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     38/200      3.26G      2.263      1.147      1.353        629        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.7it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.2it/s 0.2s.2s\n",
      "                   all         93       2846       0.68      0.649      0.581      0.223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     39/200      3.26G       2.29      1.162      1.362        431        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.8it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.258      0.265      0.104     0.0143\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     40/200      3.26G      2.224      1.153      1.333        509        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.7it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.7it/s 0.2s.2s\n",
      "                   all         93       2846      0.608      0.536      0.424     0.0874\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     41/200      3.26G      2.212      1.153      1.342        603        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.2it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.0it/s 0.2s.2s\n",
      "                   all         93       2846      0.581      0.508      0.396     0.0831\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     42/200      3.26G      2.153        1.1      1.326        529        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.7it/s 1.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.523      0.459      0.328     0.0559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     43/200      3.26G      2.142       1.09      1.311        586        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 14.9it/s 1.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 14.1it/s 0.2s.2s\n",
      "                   all         93       2846       0.36      0.331      0.177     0.0263\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 15 epochs. Best results observed at epoch 28, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=15) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "43 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/20260111_172635_yolo12l/weights/last.pt, 53.5MB\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/20260111_172635_yolo12l/weights/best.pt, 53.5MB\n",
      "\n",
      "Validating /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/20260111_172635_yolo12l/weights/best.pt...\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "YOLOv12l summary (fused): 283 layers, 26,339,843 parameters, 0 gradients, 88.5 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 16.6it/s 0.2s.2s\n",
      "                   all         93       2846      0.707      0.635      0.581      0.224\n",
      "Speed: 0.0ms preprocess, 0.9ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "YOLOv12l summary (fused): 283 layers, 26,339,843 parameters, 0 gradients, 88.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5525.0Â±968.0 MB/s, size: 153.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 464.9Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 6/6 4.0it/s 1.5s1.2s\n",
      "                   all         93       2846       0.71      0.634      0.582      0.223\n",
      "Speed: 0.2ms preprocess, 13.4ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/val35\u001b[0m\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 4198.2Â±1353.3 MB/s, size: 131.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/test.cache... 45 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 107.4Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.4it/s 0.9s0.8s\n",
      "                   all         45       1150      0.746       0.67       0.65      0.239\n",
      "Speed: 0.3ms preprocess, 13.1ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Results saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/val36\u001b[0m\n",
      "yolo12l: val_f1=0.6699, test_f1=0.7057, test_map50=0.6505\n",
      "\n",
      "Tuning rtdetr-l for 10 iterations\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mInitialized Tuner instance with 'tune_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune'\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mğŸ’¡ Learn about tuning at https://docs.ultralytics.com/guides/hyperparameter-tuning\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 1/10 with hyperparameters: {'lr0': 0.01, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'box': 7.5, 'cls': 0.5, 'dfl': 1.5, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 10}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=rtdetr-l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "WARNING âš ï¸ no model scale passed. Assuming scale='l'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n",
      "  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n",
      "  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
      "  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n",
      "  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n",
      "  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n",
      "  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n",
      "  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n",
      " 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n",
      " 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
      " 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n",
      " 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n",
      " 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 28        [21, 24, 27]  1   7303907  ultralytics.nn.modules.head.RTDETRDecoder    [1, [256, 256, 256]]          \n",
      "rt-detr-l summary: 465 layers, 32,808,131 parameters, 32,808,131 gradients, 108.0 GFLOPs\n",
      "\n",
      "Transferred 926/941 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 4842.0Â±1037.5 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 16.0Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2375.7Â±1644.7 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.8Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.0005), 226 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       1/20       8.7G       1.72      0.463     0.5695        496        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.7it/s 5.5s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.5it/s 1.2s3.3s\n",
      "                   all         93       2846      0.105      0.432     0.0921      0.026\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       2/20      4.78G      1.389      0.402     0.3533        507        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       2/20      6.03G      1.128     0.4941     0.2364        790        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.0it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.614      0.563      0.524      0.193\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       3/20      6.03G      0.989     0.4926     0.2111        458        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       3/20      7.02G     0.9534     0.4791     0.1893        570        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.0it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.5it/s 0.2s.3s\n",
      "                   all         93       2846      0.542      0.469      0.391     0.0874\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       4/20      7.02G     0.9181     0.4562     0.1867        539        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       4/20      7.02G     0.9107     0.4716     0.1779        514        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.2it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.5it/s 0.2s.3s\n",
      "                   all         93       2846      0.589      0.534       0.44     0.0922\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       5/20      7.02G     0.8877     0.4608     0.1661        586        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       5/20      7.02G     0.8706     0.4714     0.1643        531        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.1it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.5it/s 0.2s.3s\n",
      "                   all         93       2846      0.469      0.448      0.293     0.0561\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       6/20      7.02G     0.8284     0.4688     0.1577        589        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       6/20      8.05G     0.8352     0.4744     0.1443        529        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.1it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846      0.605      0.519      0.443     0.0958\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       7/20      7.56G      0.847     0.4861     0.1531        433        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.2it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.649      0.636      0.572      0.195\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       8/20      7.56G     0.8187     0.5054     0.1595        481        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       8/20      7.56G     0.8525     0.4888     0.1565        532        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.1it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.649      0.588      0.516      0.124\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       9/20      7.56G       0.79     0.4931     0.1375        573        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       9/20      7.56G     0.8138     0.4805     0.1421        410        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.2it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.711      0.629       0.59      0.179\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      10/20      7.56G     0.8074     0.4792     0.1394        420        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.1it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.9it/s 0.3s.3s\n",
      "                   all         93       2846      0.665      0.614      0.552      0.137\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      11/20      7.56G     0.7305     0.5827     0.1242        278        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      11/20      7.56G     0.7106      0.532     0.1314        416        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.6it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846       0.71       0.66      0.609      0.178\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      12/20      7.56G      0.857     0.4651     0.2059        406        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      12/20      7.56G     0.7024     0.5149     0.1304        355        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846      0.746      0.688      0.652      0.275\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      13/20      7.56G     0.6817      0.493     0.1149        388        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      13/20      7.56G     0.6774     0.5127     0.1256        251        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.717      0.636      0.585      0.156\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      14/20      7.56G     0.6912     0.5239     0.1319        384        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      14/20      7.56G     0.7067     0.5117     0.1391        219        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.758      0.707      0.673       0.31\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      15/20      7.56G     0.7178     0.5125     0.1246        342        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      15/20      7.56G     0.6658     0.5136     0.1217        283        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.741      0.682      0.642      0.232\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      16/20      7.56G     0.7284      0.507     0.1384        340        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      16/20      7.56G     0.6747     0.5122     0.1198        270        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.756      0.691      0.665      0.278\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      17/20      7.56G     0.7011     0.5171     0.1024        270        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      17/20      7.56G     0.6525      0.521      0.116        467        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.761      0.691      0.669      0.291\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      18/20      7.56G     0.6937     0.5141     0.1194        264        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      18/20      7.56G     0.6492     0.5141     0.1113        275        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.6it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.755      0.699      0.667      0.282\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      19/20      7.56G      0.633     0.5561     0.1189        298        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      19/20      7.56G      0.654     0.5065     0.1086        369        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 2.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.3s.3s\n",
      "                   all         93       2846      0.763       0.71      0.679       0.31\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      20/20      7.56G     0.6522     0.4834     0.1097        416        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      20/20      7.56G     0.6445     0.5108     0.1091        315        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 2.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.9it/s 0.3s.3s\n",
      "                   all         93       2846      0.766       0.71      0.682      0.307\n",
      "\n",
      "20 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 66.1MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m1/10 iterations complete âœ… (80.14s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.30735 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.76647, 'metrics/recall(B)': 0.71038, 'metrics/mAP50(B)': 0.68153, 'metrics/mAP50-95(B)': 0.30735, 'val/giou_loss': 0.70614, 'val/cls_loss': 0.49636, 'val/l1_loss': 0.12347, 'fitness': 0.30735}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 2/10 with hyperparameters: {'lr0': 0.01269, 'lrf': 0.0078, 'momentum': 0.92025, 'weight_decay': 0.00069, 'warmup_epochs': 3.0, 'warmup_momentum': 0.92932, 'box': 7.5, 'cls': 0.49026, 'dfl': 1.5, 'hsv_h': 0.01602, 'hsv_s': 0.7751, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.11878, 'scale': 0.37544, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.4032, 'bgr': 0.0, 'mosaic': 0.73123, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 10}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.49026, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.4032, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01602, hsv_s=0.7751, hsv_v=0.4, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01269, lrf=0.0078, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=rtdetr-l.pt, momentum=0.92025, mosaic=0.73123, multi_scale=False, name=train47, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train47, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.37544, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.11878, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.92932, weight_decay=0.00069, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "WARNING âš ï¸ no model scale passed. Assuming scale='l'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n",
      "  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n",
      "  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
      "  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n",
      "  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n",
      "  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n",
      "  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n",
      "  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n",
      " 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n",
      " 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
      " 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n",
      " 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n",
      " 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 28        [21, 24, 27]  1   7303907  ultralytics.nn.modules.head.RTDETRDecoder    [1, [256, 256, 256]]          \n",
      "rt-detr-l summary: 465 layers, 32,808,131 parameters, 32,808,131 gradients, 108.0 GFLOPs\n",
      "\n",
      "Transferred 926/941 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 4894.3Â±1061.8 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 14.6Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2638.4Â±1902.6 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.8Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01269' and 'momentum=0.92025' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.00069), 226 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train47\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       1/20      7.38G      1.656     0.5271     0.5485        366        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.8it/s 5.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.5it/s 1.2s3.3s\n",
      "                   all         93       2846      0.063       0.59     0.0703     0.0211\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       2/20      4.38G      1.289     0.5077     0.3412        269        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       2/20       6.2G      1.048     0.5644     0.2462        356        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.5it/s 0.2s.3s\n",
      "                   all         93       2846      0.432      0.476       0.33      0.084\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       3/20      6.87G     0.9554     0.5629     0.2035        351        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       3/20      6.87G      0.911     0.5102     0.1946        351        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846       0.47       0.42      0.312     0.0559\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       4/20      6.87G     0.8401      0.507     0.1852        321        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       4/20      7.43G     0.8584     0.5044     0.1835        524        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.285       0.29      0.145     0.0215\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       5/20      7.43G     0.8795     0.4944     0.1732        349        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       5/20      7.43G      0.882     0.4853     0.1836        394        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.6it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.7it/s 0.2s.3s\n",
      "                   all         93       2846      0.496      0.416      0.331     0.0857\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       6/20      7.43G     0.8836     0.4749     0.1781        501        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       6/20      7.43G     0.8176     0.4883     0.1578        233        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.7it/s 0.2s.3s\n",
      "                   all         93       2846      0.462      0.333      0.254     0.0509\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       7/20      7.43G     0.8113     0.4888     0.1678        347        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       7/20      7.43G     0.8028     0.4936     0.1535        393        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846     0.0862     0.0819      0.028    0.00791\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       8/20      7.43G     0.7638     0.5072     0.1413        384        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       8/20      7.43G     0.7989     0.4935     0.1532        439        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846      0.363       0.33      0.169     0.0239\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       9/20      7.43G     0.8026     0.5017     0.1434        450        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       9/20      7.43G     0.7683     0.5073      0.141        390        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.693      0.635      0.568       0.15\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      10/20      7.43G     0.7586     0.4732     0.1357        399        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      10/20      7.43G     0.7566     0.4909      0.134        457        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846      0.562      0.504      0.397     0.0613\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      11/20      7.43G     0.7915     0.5299     0.1559        301        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      11/20      7.43G     0.6935     0.5156       0.13        437        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.6it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.6it/s 0.3s.3s\n",
      "                   all         93       2846      0.724      0.674      0.617      0.212\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      12/20      7.43G     0.6783     0.5161     0.1267        369        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.653      0.584      0.504      0.102\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      13/20      7.43G     0.6755     0.5158     0.1282        254        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.741      0.697      0.648      0.281\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      14/20      7.43G     0.6593     0.5161     0.1267        223        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.6it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.9it/s 0.3s.3s\n",
      "                   all         93       2846      0.763      0.709      0.674      0.311\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      15/20      7.43G     0.6531      0.512      0.118        290        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.739      0.684      0.632      0.231\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      16/20      7.43G     0.6489      0.517     0.1122        272        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.756      0.689      0.652      0.286\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      17/20      7.43G     0.6332     0.5228     0.1123        475        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 2.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.752      0.703      0.658      0.288\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      18/20      7.43G     0.6436      0.511     0.1102        284        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.755       0.71      0.663      0.293\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      19/20      7.43G     0.6355     0.5088      0.107        368        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.6it/s 0.3s.3s\n",
      "                   all         93       2846      0.766      0.708      0.671      0.316\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      20/20      7.43G     0.6292     0.5134     0.1115        324        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.766      0.701      0.669      0.305\n",
      "\n",
      "20 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train47/weights/last.pt, 66.2MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m2/10 iterations complete âœ… (158.33s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.30735 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.76647, 'metrics/recall(B)': 0.71038, 'metrics/mAP50(B)': 0.68153, 'metrics/mAP50-95(B)': 0.30735, 'val/giou_loss': 0.70614, 'val/cls_loss': 0.49636, 'val/l1_loss': 0.12347, 'fitness': 0.30735}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 3/10 with hyperparameters: {'lr0': 0.01, 'lrf': 0.01141, 'momentum': 0.937, 'weight_decay': 0.00061, 'warmup_epochs': 3.0853, 'warmup_momentum': 0.8, 'box': 6.58224, 'cls': 0.5, 'dfl': 1.56201, 'hsv_h': 0.015, 'hsv_s': 0.70341, 'hsv_v': 0.47406, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.52047, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 10}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=6.58224, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.56201, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.70341, hsv_v=0.47406, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01141, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=rtdetr-l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.52047, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0853, warmup_momentum=0.8, weight_decay=0.00061, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "WARNING âš ï¸ no model scale passed. Assuming scale='l'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n",
      "  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n",
      "  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
      "  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n",
      "  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n",
      "  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n",
      "  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n",
      "  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n",
      " 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n",
      " 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
      " 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n",
      " 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n",
      " 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 28        [21, 24, 27]  1   7303907  ultralytics.nn.modules.head.RTDETRDecoder    [1, [256, 256, 256]]          \n",
      "rt-detr-l summary: 465 layers, 32,808,131 parameters, 32,808,131 gradients, 108.0 GFLOPs\n",
      "\n",
      "Transferred 926/941 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5477.8Â±1571.4 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 16.0Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2397.0Â±1786.8 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.4Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.00061), 226 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       1/20      8.09G      1.732     0.4604      0.553        496        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.6it/s 5.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.5it/s 1.2s3.4s\n",
      "                   all         93       2846     0.0463      0.301     0.0331    0.00686\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       2/20      4.86G      1.379     0.4339     0.3702        514        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       2/20      6.66G      1.113     0.5025     0.2317        802        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.0it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.607       0.53       0.49      0.168\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       3/20      6.66G     0.9817     0.4737     0.1829        462        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       3/20      7.68G     0.9578     0.4795     0.1849        571        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.0it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.5it/s 0.2s.3s\n",
      "                   all         93       2846      0.456      0.384       0.29     0.0576\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       4/20      7.68G       0.91     0.4545      0.164        543        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       4/20      7.68G     0.9249     0.4657     0.1859        525        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.2it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846      0.566      0.499      0.415     0.0869\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       5/20      7.68G     0.9011     0.4546     0.1645        598        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       5/20      7.68G     0.8812     0.4709      0.158        536        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.1it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.496      0.396      0.299     0.0524\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       6/20      7.68G     0.8511     0.5031     0.1616        596        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       6/20      8.73G     0.8677     0.4826     0.1561        543        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.0it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.3it/s 0.3s.3s\n",
      "                   all         93       2846      0.628      0.561       0.48      0.109\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       7/20      7.51G     0.8719     0.4724     0.1523        443        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.1it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.9it/s 0.3s.3s\n",
      "                   all         93       2846      0.683      0.633      0.577      0.226\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       8/20      7.51G     0.8018     0.4674     0.1447        483        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       8/20      7.51G     0.8412      0.474     0.1474        528        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.1it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846      0.594      0.537      0.449     0.0996\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       9/20      7.51G     0.7798     0.4966     0.1388        575        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       9/20      7.51G     0.8413     0.4788     0.1519        410        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.2it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.5it/s 0.2s.3s\n",
      "                   all         93       2846      0.532      0.478       0.36     0.0576\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      10/20      7.51G     0.8232     0.4757     0.1426        419        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.0it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.759      0.676       0.65      0.275\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      11/20      7.51G     0.7084     0.5293     0.1288        411        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.6it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.7it/s 0.3s.3s\n",
      "                   all         93       2846      0.684      0.639      0.572      0.168\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      12/20      7.51G     0.7076     0.5225     0.1266        352        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.9it/s 0.3s.3s\n",
      "                   all         93       2846      0.738      0.685      0.642      0.274\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      13/20      7.51G     0.6858     0.5158     0.1255        250        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.664      0.627      0.544      0.117\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      14/20      7.51G     0.6936     0.5223     0.1338        214        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.8it/s 0.3s.3s\n",
      "                   all         93       2846      0.756      0.694      0.656      0.283\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      15/20      7.51G     0.6675     0.5186     0.1187        283        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.9it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.748      0.705       0.66      0.293\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      16/20      7.51G     0.6711     0.5166      0.114        269        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.7it/s 0.3s.3s\n",
      "                   all         93       2846      0.751      0.687      0.657      0.281\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      17/20      7.51G     0.6542     0.5223     0.1156        467        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.6it/s 0.3s.3s\n",
      "                   all         93       2846      0.758      0.693      0.663      0.296\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      18/20      7.51G     0.6608     0.5118     0.1105        271        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.757      0.699      0.663      0.294\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      19/20      7.51G     0.6435      0.512     0.1046        367        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.8it/s 0.3s.3s\n",
      "                   all         93       2846      0.765      0.702      0.668      0.301\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      20/20      7.51G     0.6483     0.5105     0.1085        313        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 2.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.763        0.7      0.667      0.294\n",
      "\n",
      "20 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 66.1MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m3/10 iterations complete âœ… (238.72s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.30735 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.76647, 'metrics/recall(B)': 0.71038, 'metrics/mAP50(B)': 0.68153, 'metrics/mAP50-95(B)': 0.30735, 'val/giou_loss': 0.70614, 'val/cls_loss': 0.49636, 'val/l1_loss': 0.12347, 'fitness': 0.30735}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 4/10 with hyperparameters: {'lr0': 0.01078, 'lrf': 0.01202, 'momentum': 0.937, 'weight_decay': 0.00053, 'warmup_epochs': 2.93311, 'warmup_momentum': 0.94091, 'box': 7.02406, 'cls': 0.34585, 'dfl': 1.76075, 'hsv_h': 0.015, 'hsv_s': 0.62808, 'hsv_v': 0.58896, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.50687, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 10}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.02406, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.34585, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.76075, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.50687, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.62808, hsv_v=0.58896, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01078, lrf=0.01202, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=rtdetr-l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=2.93311, warmup_momentum=0.94091, weight_decay=0.00053, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "WARNING âš ï¸ no model scale passed. Assuming scale='l'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n",
      "  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n",
      "  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
      "  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n",
      "  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n",
      "  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n",
      "  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n",
      "  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n",
      " 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n",
      " 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
      " 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n",
      " 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n",
      " 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 28        [21, 24, 27]  1   7303907  ultralytics.nn.modules.head.RTDETRDecoder    [1, [256, 256, 256]]          \n",
      "rt-detr-l summary: 465 layers, 32,808,131 parameters, 32,808,131 gradients, 108.0 GFLOPs\n",
      "\n",
      "Transferred 926/941 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3787.2Â±1771.9 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 14.6Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1473.5Â±925.2 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.1Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01078' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.00053), 226 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       1/20       8.7G      1.723     0.4602     0.5742        496        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.7it/s 5.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.5it/s 1.2s3.4s\n",
      "                   all         93       2846     0.0613      0.565     0.0597     0.0187\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       2/20      4.78G       1.41     0.4171     0.3851        507        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       2/20      6.03G      1.158     0.5055     0.2484        790        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.1it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.511      0.509      0.444      0.164\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       3/20      6.03G     0.9971     0.5131     0.2088        458        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       3/20      7.02G     0.9691     0.4932     0.1973        570        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.1it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.634       0.47       0.46      0.181\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       4/20      7.02G     0.9306     0.4566     0.1778        539        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       4/20      7.02G     0.9262      0.472     0.1842        514        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.2it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.343      0.281      0.169     0.0252\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       5/20      7.02G      0.932     0.4615      0.188        586        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       5/20      7.02G     0.8922     0.4711     0.1691        531        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.0it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846      0.528      0.484      0.377      0.084\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       6/20      7.02G     0.8545     0.4639     0.1692        589        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       6/20      8.05G     0.8758     0.4645     0.1614        529        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.1it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.5it/s 0.2s.3s\n",
      "                   all         93       2846      0.162      0.143     0.0536    0.00828\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       7/20      7.56G     0.8686     0.4726     0.1654        433        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.1it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.659      0.574      0.504      0.124\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       8/20      7.56G     0.8428     0.4675     0.1533        481        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       8/20      7.56G     0.8372     0.4775      0.143        532        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.1it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.629      0.556      0.479     0.0993\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       9/20      7.56G     0.7852     0.4892     0.1391        573        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       9/20      7.56G     0.8356     0.4721     0.1499        410        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.2it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.9it/s 0.3s.3s\n",
      "                   all         93       2846      0.752      0.676      0.644      0.279\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      10/20      7.56G     0.8315      0.473     0.1495        420        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.1it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.712      0.652      0.597      0.201\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      11/20      7.56G     0.7325     0.5321     0.1237        278        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      11/20      7.56G     0.7093     0.5175     0.1287        416        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.6it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.7it/s 0.3s.3s\n",
      "                   all         93       2846      0.699      0.638      0.572      0.164\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      12/20      7.56G     0.7113       0.52     0.1346        355        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.707      0.648      0.584      0.187\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      13/20      7.56G      0.699     0.5162     0.1284        251        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.725      0.658      0.606       0.21\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      14/20      7.56G     0.6721     0.5228     0.1231        219        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.744       0.67      0.637      0.268\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      15/20      7.56G     0.6655     0.5303     0.1189        283        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846       0.72      0.665      0.609      0.215\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      16/20      7.56G     0.6716     0.5251     0.1182        270        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.3s.3s\n",
      "                   all         93       2846      0.738      0.689      0.645      0.279\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      17/20      7.56G     0.6603      0.524     0.1185        467        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.3s.3s\n",
      "                   all         93       2846       0.75      0.696      0.657      0.299\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      18/20      7.56G     0.6592     0.5157     0.1125        275        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.751      0.704      0.657      0.293\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      19/20      7.56G     0.6431     0.5143     0.1067        369        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 2.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846       0.76      0.703      0.661      0.303\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      20/20      7.56G     0.6495     0.5114     0.1091        315        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 2.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.757      0.702      0.657      0.293\n",
      "\n",
      "20 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 66.1MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m4/10 iterations complete âœ… (318.92s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.30735 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.76647, 'metrics/recall(B)': 0.71038, 'metrics/mAP50(B)': 0.68153, 'metrics/mAP50-95(B)': 0.30735, 'val/giou_loss': 0.70614, 'val/cls_loss': 0.49636, 'val/l1_loss': 0.12347, 'fitness': 0.30735}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 5/10 with hyperparameters: {'lr0': 0.01512, 'lrf': 0.00855, 'momentum': 0.88399, 'weight_decay': 0.00055, 'warmup_epochs': 2.47036, 'warmup_momentum': 0.95, 'box': 7.5, 'cls': 0.49394, 'dfl': 1.34101, 'hsv_h': 0.01733, 'hsv_s': 0.76562, 'hsv_v': 0.41659, 'degrees': 0.0, 'translate': 0.09727, 'scale': 0.47772, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.56527, 'bgr': 0.0, 'mosaic': 0.59112, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 10}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.49394, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.34101, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.56527, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01733, hsv_s=0.76562, hsv_v=0.41659, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01512, lrf=0.00855, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=rtdetr-l.pt, momentum=0.88399, mosaic=0.59112, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.47772, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.09727, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=2.47036, warmup_momentum=0.95, weight_decay=0.00055, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "WARNING âš ï¸ no model scale passed. Assuming scale='l'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n",
      "  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n",
      "  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
      "  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n",
      "  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n",
      "  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n",
      "  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n",
      "  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n",
      " 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n",
      " 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
      " 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n",
      " 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n",
      " 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 28        [21, 24, 27]  1   7303907  ultralytics.nn.modules.head.RTDETRDecoder    [1, [256, 256, 256]]          \n",
      "rt-detr-l summary: 465 layers, 32,808,131 parameters, 32,808,131 gradients, 108.0 GFLOPs\n",
      "\n",
      "Transferred 926/941 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 4317.2Â±1442.4 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 13.7Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1726.8Â±1220.5 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.8Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01512' and 'momentum=0.88399' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.00055), 226 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       1/20      8.32G      1.672     0.5151     0.5318        370        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.7it/s 5.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.5it/s 1.2s3.4s\n",
      "                   all         93       2846     0.0775      0.513     0.0722     0.0221\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       2/20       4.3G       1.46     0.4279     0.3982        357        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       2/20      7.08G      1.068     0.5383     0.2467        285        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.3it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.8it/s 0.3s.3s\n",
      "                   all         93       2846      0.482      0.514      0.399      0.131\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       3/20      7.08G     0.9379     0.4944     0.2018        346        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.3it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.5it/s 0.3s.3s\n",
      "                   all         93       2846       0.31      0.256      0.154     0.0239\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       4/20      7.08G     0.8763     0.4829     0.1764        439        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.6it/s 0.2s.3s\n",
      "                   all         93       2846     0.0212     0.0327    0.00552    0.00147\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       5/20      7.08G     0.8346     0.4914     0.1594        629        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.615      0.538       0.45     0.0973\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       6/20      7.08G     0.8297     0.4989     0.1554        321        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.6it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.4it/s 0.3s.3s\n",
      "                   all         93       2846      0.695      0.637      0.586      0.232\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       7/20      7.08G      0.802     0.4944     0.1639        413        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.566      0.469      0.387     0.0835\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       8/20      7.08G     0.7878     0.4998     0.1462        570        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.696      0.614      0.562       0.17\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       9/20      7.08G     0.7654     0.5014     0.1359        394        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.6it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.601      0.539      0.452     0.0888\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      10/20      7.08G     0.7671     0.4979     0.1393        368        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.743      0.687      0.643      0.263\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      11/20      7.08G     0.7544      0.531     0.1418        281        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      11/20      7.08G     0.6936     0.5251     0.1274        419        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.6it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.727      0.685      0.634      0.255\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      12/20      7.08G     0.7955     0.4767     0.1695        408        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      12/20      7.08G     0.6763     0.5262     0.1206        359        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.6it/s 0.3s.3s\n",
      "                   all         93       2846      0.731      0.668      0.625      0.226\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      13/20      7.08G     0.6735     0.5085     0.1088        390        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      13/20      7.08G     0.6751     0.5209     0.1283        252        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.6it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.9it/s 0.3s.3s\n",
      "                   all         93       2846      0.718      0.682      0.624      0.222\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      14/20      7.08G     0.6504     0.5353     0.1153        386        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      14/20      7.08G     0.6615     0.5227      0.122        220        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.6it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.9it/s 0.3s.3s\n",
      "                   all         93       2846      0.757      0.695      0.662      0.297\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      15/20      7.08G     0.7327     0.5032     0.1266        344        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      15/20      7.08G     0.6516     0.5183     0.1155        285        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.725      0.682      0.625      0.228\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      16/20      7.08G     0.6929     0.5126      0.126        342        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      16/20      7.08G     0.6578      0.519     0.1103        270        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.754      0.687      0.647      0.264\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      17/20      7.08G     0.7129     0.5018     0.1067        270        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      17/20      7.08G      0.651     0.5205     0.1173        467        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.9it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.764      0.702      0.667      0.309\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      18/20      7.08G      0.695     0.5097     0.1261        265        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      18/20      7.08G     0.6434     0.5131     0.1078        279        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.9it/s 0.3s.3s\n",
      "                   all         93       2846      0.735      0.692      0.639      0.246\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      19/20      7.08G     0.6366     0.5321     0.1161        300        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      19/20      7.08G     0.6454     0.5117     0.1092        370        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 2.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.761      0.706      0.668      0.312\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      20/20      7.08G     0.6737     0.4835     0.1286        417        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      20/20      7.08G     0.6459     0.5116      0.114        319        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.9it/s 0.3s.3s\n",
      "                   all         93       2846      0.758      0.699      0.663      0.293\n",
      "\n",
      "20 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 66.1MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m5/10 iterations complete âœ… (397.46s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.30735 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.76647, 'metrics/recall(B)': 0.71038, 'metrics/mAP50(B)': 0.68153, 'metrics/mAP50-95(B)': 0.30735, 'val/giou_loss': 0.70614, 'val/cls_loss': 0.49636, 'val/l1_loss': 0.12347, 'fitness': 0.30735}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 6/10 with hyperparameters: {'lr0': 0.01062, 'lrf': 0.00837, 'momentum': 0.9176, 'weight_decay': 0.00053, 'warmup_epochs': 3.43732, 'warmup_momentum': 0.74914, 'box': 7.5, 'cls': 0.5507, 'dfl': 1.5, 'hsv_h': 0.01542, 'hsv_s': 0.80823, 'hsv_v': 0.53574, 'degrees': 0.0, 'translate': 0.12619, 'scale': 0.38303, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.37121, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 10}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5507, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.37121, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01542, hsv_s=0.80823, hsv_v=0.53574, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01062, lrf=0.00837, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=rtdetr-l.pt, momentum=0.9176, mosaic=1.0, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.38303, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.12619, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.43732, warmup_momentum=0.74914, weight_decay=0.00053, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "WARNING âš ï¸ no model scale passed. Assuming scale='l'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n",
      "  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n",
      "  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
      "  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n",
      "  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n",
      "  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n",
      "  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n",
      "  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n",
      " 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n",
      " 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
      " 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n",
      " 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n",
      " 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 28        [21, 24, 27]  1   7303907  ultralytics.nn.modules.head.RTDETRDecoder    [1, [256, 256, 256]]          \n",
      "rt-detr-l summary: 465 layers, 32,808,131 parameters, 32,808,131 gradients, 108.0 GFLOPs\n",
      "\n",
      "Transferred 926/941 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5110.5Â±1271.0 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 15.3Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2406.1Â±1783.6 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.6Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01062' and 'momentum=0.9176' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.00053), 226 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       1/20      7.93G      1.698     0.4822     0.5821        456        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.8it/s 5.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.5it/s 1.2s3.3s\n",
      "                   all         93       2846     0.0796      0.421     0.0657     0.0186\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       2/20      4.42G      1.362      0.427     0.3523        451        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       2/20      5.46G      1.117     0.5293     0.2575        716        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.3it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.513      0.513       0.45      0.178\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       3/20      5.46G     0.9287      0.557     0.2005        435        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       3/20      6.36G     0.9079     0.5057     0.1852        546        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.2it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846      0.333      0.285      0.166     0.0237\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       4/20      6.36G       0.85     0.4837     0.1641        502        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       4/20      6.36G     0.8926     0.4705      0.183        484        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846      0.364      0.323      0.176     0.0247\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       5/20      6.36G       0.89     0.4576     0.1712        537        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       5/20      6.36G     0.8427     0.4757     0.1626        515        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.2it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.122      0.125     0.0315    0.00488\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       6/20      6.36G     0.8197     0.4818     0.1599        560        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       6/20      6.91G     0.8173     0.4766     0.1521        497        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.5it/s 0.2s.3s\n",
      "                   all         93       2846      0.459       0.41      0.281      0.047\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       7/20      6.91G     0.7862     0.5136     0.1595        400        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       7/20         8G      0.808     0.4886     0.1568        426        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.604      0.562      0.469     0.0909\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       8/20      6.49G     0.7924     0.4804      0.144        488        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.3it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.5it/s 0.2s.3s\n",
      "                   all         93       2846      0.435      0.407      0.259     0.0397\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       9/20      7.35G     0.7751     0.4868     0.1409        400        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.717      0.669      0.614      0.208\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      10/20      8.23G     0.7802     0.4776     0.1423        396        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.3it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.8it/s 0.3s.3s\n",
      "                   all         93       2846      0.562      0.517      0.386     0.0571\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      11/20      4.16G     0.7614     0.5254     0.1468        296        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      11/20       6.2G     0.7044     0.5044     0.1352        435        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.6it/s 0.3s.3s\n",
      "                   all         93       2846      0.724      0.656      0.602      0.199\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      12/20       6.2G     0.7668     0.4954     0.1611        416        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      12/20       6.2G     0.6866     0.5093     0.1219        366        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.3s.3s\n",
      "                   all         93       2846      0.746      0.683       0.64      0.247\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      13/20       6.2G     0.6727     0.4938     0.1132        381        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      13/20       6.2G     0.6692     0.5116     0.1209        252        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846      0.583       0.53      0.413     0.0669\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      14/20       6.2G     0.6905     0.5176     0.1306        398        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      14/20       6.2G      0.677     0.5188     0.1306        220        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.766      0.706      0.675      0.313\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      15/20       6.2G      0.703     0.5236     0.1195        352        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      15/20       6.2G     0.6563     0.5138     0.1187        289        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.3s.3s\n",
      "                   all         93       2846      0.737      0.695      0.649      0.263\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      16/20       6.2G     0.7316     0.5011     0.1395        356        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      16/20       6.2G     0.6594     0.5103     0.1159        271        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.9it/s 0.3s.3s\n",
      "                   all         93       2846      0.755      0.701      0.669      0.308\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      17/20       6.2G     0.6798     0.5106     0.1095        275        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      17/20       6.2G     0.6436      0.517     0.1149        474        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.3s.3s\n",
      "                   all         93       2846      0.758      0.695      0.662      0.293\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      18/20       6.2G     0.6867     0.4981     0.1148        272        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      18/20       6.2G     0.6448     0.5145     0.1158        281        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.748      0.705       0.66      0.279\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      19/20       6.2G     0.6047       0.57     0.1107        305        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      19/20       6.2G     0.6396     0.5108     0.1091        366        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.762      0.707      0.674      0.312\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      20/20       6.2G     0.6605      0.491     0.1291        421        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      20/20       6.2G     0.6342     0.5112     0.1144        324        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.9it/s 0.3s.3s\n",
      "                   all         93       2846      0.758      0.704      0.664      0.286\n",
      "\n",
      "20 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 66.1MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m6/10 iterations complete âœ… (477.07s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.30735 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.76647, 'metrics/recall(B)': 0.71038, 'metrics/mAP50(B)': 0.68153, 'metrics/mAP50-95(B)': 0.30735, 'val/giou_loss': 0.70614, 'val/cls_loss': 0.49636, 'val/l1_loss': 0.12347, 'fitness': 0.30735}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 7/10 with hyperparameters: {'lr0': 0.01105, 'lrf': 0.00916, 'momentum': 0.98, 'weight_decay': 0.00079, 'warmup_epochs': 4.05419, 'warmup_momentum': 0.8942, 'box': 7.5, 'cls': 0.45843, 'dfl': 1.5, 'hsv_h': 0.01563, 'hsv_s': 0.78243, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.10278, 'scale': 0.49039, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.34377, 'bgr': 0.0, 'mosaic': 0.78051, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 10}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.45843, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.34377, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01563, hsv_s=0.78243, hsv_v=0.4, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01105, lrf=0.00916, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=rtdetr-l.pt, momentum=0.98, mosaic=0.78051, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.49039, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.10278, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=4.05419, warmup_momentum=0.8942, weight_decay=0.00079, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "WARNING âš ï¸ no model scale passed. Assuming scale='l'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n",
      "  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n",
      "  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
      "  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n",
      "  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n",
      "  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n",
      "  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n",
      "  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n",
      " 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n",
      " 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
      " 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n",
      " 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n",
      " 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 28        [21, 24, 27]  1   7303907  ultralytics.nn.modules.head.RTDETRDecoder    [1, [256, 256, 256]]          \n",
      "rt-detr-l summary: 465 layers, 32,808,131 parameters, 32,808,131 gradients, 108.0 GFLOPs\n",
      "\n",
      "Transferred 926/941 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5064.2Â±1383.4 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 14.7Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2788.8Â±1947.4 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.7Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01105' and 'momentum=0.98' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.00079), 226 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       1/20      7.18G      1.684     0.5002     0.5668        400        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.8it/s 5.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.5it/s 1.2s3.3s\n",
      "                   all         93       2846     0.0661      0.565      0.082     0.0219\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       2/20      4.39G      1.317     0.5261     0.3633        348        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       2/20      10.3G      1.075     0.5404     0.2358        599        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.0it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.5it/s 0.3s.3s\n",
      "                   all         93       2846      0.642      0.579      0.536      0.216\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       3/20      6.87G     0.9596     0.4755     0.2023        354        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.2it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.249      0.219      0.114     0.0159\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       4/20      7.78G     0.9115     0.4738     0.1769        484        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.3it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.304      0.319      0.179     0.0315\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       5/20      8.87G     0.8666      0.482     0.1596        584        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.1it/s 3.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.5it/s 0.3s.3s\n",
      "                   all         93       2846      0.707      0.647      0.614      0.251\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       6/20      5.41G     0.8253     0.4896     0.1527        519        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.3it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.493      0.409      0.321     0.0708\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       7/20      6.28G     0.8043     0.4841      0.143        487        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.3it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.737       0.66      0.621      0.245\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       8/20      6.28G     0.7734     0.4928     0.1444        421        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.747      0.673      0.643      0.284\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       9/20      6.28G     0.7939     0.4974     0.1479        465        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.3it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.661      0.619      0.539       0.15\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      10/20      8.29G     0.7781     0.4766     0.1328        562        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.7it/s 0.2s.3s\n",
      "                   all         93       2846      0.725      0.664      0.607      0.215\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      11/20      6.21G     0.7074     0.5147     0.1291        419        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.9it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.6it/s 0.2s.3s\n",
      "                   all         93       2846      0.744      0.674      0.625      0.225\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      12/20      6.21G     0.6921     0.5179     0.1284        357        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 7.2it/s 2.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.6it/s 0.2s.3s\n",
      "                   all         93       2846      0.742      0.673      0.633       0.23\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      13/20      6.21G     0.6736     0.5199     0.1217        252        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 7.1it/s 2.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.9it/s 0.2s.3s\n",
      "                   all         93       2846      0.718      0.683       0.62      0.204\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      14/20      6.21G     0.6545     0.5293     0.1196        385        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      14/20      6.21G     0.6619     0.5155      0.123        220        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 7.1it/s 2.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.6it/s 0.2s.3s\n",
      "                   all         93       2846      0.764      0.694      0.661      0.298\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      15/20      6.21G     0.7275     0.5086     0.1216        344        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      15/20      6.21G     0.6511     0.5153     0.1141        283        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 7.3it/s 2.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.7it/s 0.2s.3s\n",
      "                   all         93       2846      0.757      0.695      0.654      0.272\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      16/20      6.21G        0.7     0.5266     0.1372        341        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      16/20      6.21G     0.6604     0.5174     0.1131        270        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 7.1it/s 2.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.7it/s 0.2s.3s\n",
      "                   all         93       2846      0.756      0.691      0.657      0.269\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      17/20      6.21G     0.6997     0.5298     0.1062        270        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      17/20      6.21G     0.6477     0.5208      0.112        468        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 7.2it/s 2.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.774      0.715      0.682      0.316\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      18/20      6.21G     0.6791     0.4992     0.1182        264        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      18/20      6.21G     0.6424     0.5157     0.1087        277        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 7.1it/s 2.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.5it/s 0.2s.3s\n",
      "                   all         93       2846      0.768      0.717      0.677      0.319\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      19/20      6.21G     0.6227     0.5316     0.1088        300        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      19/20      6.21G     0.6325     0.5113     0.1025        369        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 7.2it/s 2.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.7it/s 0.2s.3s\n",
      "                   all         93       2846      0.767       0.71      0.674      0.316\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      20/20      6.21G     0.6288     0.4942     0.1043        415        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      20/20      6.21G     0.6377     0.5127     0.1058        317        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 7.2it/s 2.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.6it/s 0.2s.3s\n",
      "                   all         93       2846      0.767      0.707       0.67      0.303\n",
      "\n",
      "20 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 66.1MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m7/10 iterations complete âœ… (554.93s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.30735 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.76647, 'metrics/recall(B)': 0.71038, 'metrics/mAP50(B)': 0.68153, 'metrics/mAP50-95(B)': 0.30735, 'val/giou_loss': 0.70614, 'val/cls_loss': 0.49636, 'val/l1_loss': 0.12347, 'fitness': 0.30735}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 8/10 with hyperparameters: {'lr0': 0.01305, 'lrf': 0.00719, 'momentum': 0.95472, 'weight_decay': 0.00042, 'warmup_epochs': 4.65495, 'warmup_momentum': 0.95, 'box': 7.46226, 'cls': 0.48257, 'dfl': 1.31438, 'hsv_h': 0.01605, 'hsv_s': 0.81308, 'hsv_v': 0.40783, 'degrees': 0.0, 'translate': 0.14105, 'scale': 0.39892, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.41209, 'bgr': 0.0, 'mosaic': 0.95045, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 8}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.46226, cache=False, cfg=None, classes=None, close_mosaic=8, cls=0.48257, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.31438, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.41209, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01605, hsv_s=0.81308, hsv_v=0.40783, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01305, lrf=0.00719, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=rtdetr-l.pt, momentum=0.95472, mosaic=0.95045, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.39892, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.14105, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=4.65495, warmup_momentum=0.95, weight_decay=0.00042, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "WARNING âš ï¸ no model scale passed. Assuming scale='l'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n",
      "  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n",
      "  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
      "  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n",
      "  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n",
      "  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n",
      "  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n",
      "  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n",
      " 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n",
      " 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
      " 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n",
      " 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n",
      " 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 28        [21, 24, 27]  1   7303907  ultralytics.nn.modules.head.RTDETRDecoder    [1, [256, 256, 256]]          \n",
      "rt-detr-l summary: 465 layers, 32,808,131 parameters, 32,808,131 gradients, 108.0 GFLOPs\n",
      "\n",
      "Transferred 926/941 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5189.7Â±1381.6 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 15.8Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1123.8Â±112.3 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.0Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01305' and 'momentum=0.95472' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.00042), 226 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       1/20      8.71G      1.702     0.4654     0.5558        402        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.9it/s 5.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.6it/s 1.2s3.3s\n",
      "                   all         93       2846     0.0647      0.468     0.0709     0.0167\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       2/20      4.58G      1.266     0.4969     0.3032        488        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       2/20      6.08G      1.111     0.5048     0.2706        591        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846      0.578      0.522      0.473      0.163\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       3/20      6.08G     0.9088     0.5161     0.1794        459        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       3/20      6.08G     0.9405     0.4937     0.1901        559        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.457      0.443      0.332      0.063\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       4/20      6.08G      0.833     0.4861     0.1611        524        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       4/20      6.08G     0.8905     0.4749      0.181        562        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.9it/s 0.2s.3s\n",
      "                   all         93       2846      0.623      0.597      0.526      0.186\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       5/20      6.08G     0.9122     0.4533     0.2123        582        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       5/20      6.08G       0.85     0.4785     0.1725        546        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.9it/s 0.2s.3s\n",
      "                   all         93       2846      0.483      0.545      0.398      0.083\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       6/20      6.08G     0.8986     0.4716     0.1755        477        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       6/20      6.08G     0.8261     0.4977     0.1562        463        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.9it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.9it/s 0.2s.3s\n",
      "                   all         93       2846      0.626      0.607      0.509       0.14\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       7/20      6.08G     0.7862     0.4887     0.1368        387        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       7/20      6.08G     0.8084     0.4794     0.1512        486        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.581      0.512      0.417      0.075\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       8/20      6.08G     0.7827     0.4664     0.1497        460        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       8/20      6.08G     0.7952     0.4777     0.1451        567        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.8it/s 0.2s.3s\n",
      "                   all         93       2846      0.751      0.687      0.651      0.282\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       9/20      6.08G     0.7712     0.4679     0.1502        484        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       9/20      6.08G     0.7595      0.479     0.1363        522        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.8it/s 0.2s.3s\n",
      "                   all         93       2846      0.681      0.637      0.566      0.155\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      10/20      6.08G     0.7121     0.4601     0.1232        554        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      10/20      6.08G     0.7645     0.4823     0.1348        316        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.9it/s 0.2s.3s\n",
      "                   all         93       2846      0.574      0.536       0.43     0.0798\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      11/20      6.08G     0.7481      0.512     0.1496        347        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      11/20       7.1G     0.7503     0.4828     0.1353        519        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 2.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.8it/s 0.2s.3s\n",
      "                   all         93       2846      0.717      0.656      0.604      0.183\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      12/20       7.1G     0.7244     0.4689     0.1409        457        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      12/20       7.1G     0.7436     0.4839     0.1287        423        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.9it/s 0.2s.3s\n",
      "                   all         93       2846      0.676      0.633      0.563      0.146\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      13/20       7.1G     0.6682     0.4946     0.1205        360        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      13/20       7.1G     0.6699     0.5152     0.1283        260        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.7it/s 0.2s.3s\n",
      "                   all         93       2846       0.74      0.701       0.65       0.26\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      14/20       7.1G     0.6171     0.5385     0.1139        367        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      14/20       7.1G     0.6655      0.514     0.1234        224        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 7.0it/s 2.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.7it/s 0.2s.3s\n",
      "                   all         93       2846      0.733      0.699      0.641      0.246\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      15/20       7.1G     0.6657     0.5326     0.1225        316        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      15/20       7.1G     0.6641     0.5144     0.1205        242        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 7.2it/s 2.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.6it/s 0.2s.3s\n",
      "                   all         93       2846      0.722      0.685      0.626      0.227\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      16/20       7.1G     0.7155     0.4895     0.1121        386        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      16/20       7.1G     0.6562     0.5108     0.1147        222        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 7.3it/s 2.7s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.5it/s 0.2s.3s\n",
      "                   all         93       2846       0.75      0.699       0.66      0.286\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      17/20       7.1G     0.7028     0.4912     0.1113        293        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      17/20       7.1G     0.6372      0.516     0.1116        432        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 7.1it/s 2.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.6it/s 0.2s.3s\n",
      "                   all         93       2846      0.752      0.697      0.662      0.274\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      18/20       7.1G     0.7148     0.5014     0.1226        282        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      18/20       7.1G     0.6349     0.5114     0.1042        269        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 7.1it/s 2.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.5it/s 0.2s.3s\n",
      "                   all         93       2846      0.752      0.702      0.665       0.29\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      19/20       7.1G     0.6134     0.5202    0.09849        316        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      19/20       7.1G     0.6282     0.5187     0.1098        360        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 7.2it/s 2.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.7it/s 0.2s.3s\n",
      "                   all         93       2846      0.756      0.702      0.668      0.298\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      20/20       7.1G      0.645     0.4904     0.1074        426        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      20/20       7.1G     0.6266     0.5104     0.1075        330        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 7.1it/s 2.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.5it/s 0.2s.3s\n",
      "                   all         93       2846      0.754      0.706      0.671      0.297\n",
      "\n",
      "20 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 66.1MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m8/10 iterations complete âœ… (630.10s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.30735 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.76647, 'metrics/recall(B)': 0.71038, 'metrics/mAP50(B)': 0.68153, 'metrics/mAP50-95(B)': 0.30735, 'val/giou_loss': 0.70614, 'val/cls_loss': 0.49636, 'val/l1_loss': 0.12347, 'fitness': 0.30735}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 9/10 with hyperparameters: {'lr0': 0.01443, 'lrf': 0.00787, 'momentum': 0.93057, 'weight_decay': 0.00073, 'warmup_epochs': 4.16866, 'warmup_momentum': 0.84983, 'box': 7.25117, 'cls': 0.4425, 'dfl': 1.4557, 'hsv_h': 0.01542, 'hsv_s': 0.8858, 'hsv_v': 0.44381, 'degrees': 0.0, 'translate': 0.10644, 'scale': 0.2487, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.39482, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 10}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.25117, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.4425, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.4557, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.39482, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01542, hsv_s=0.8858, hsv_v=0.44381, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01443, lrf=0.00787, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=rtdetr-l.pt, momentum=0.93057, mosaic=1.0, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.2487, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.10644, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=4.16866, warmup_momentum=0.84983, weight_decay=0.00073, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "WARNING âš ï¸ no model scale passed. Assuming scale='l'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n",
      "  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n",
      "  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
      "  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n",
      "  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n",
      "  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n",
      "  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n",
      "  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n",
      " 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n",
      " 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
      " 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n",
      " 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n",
      " 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 28        [21, 24, 27]  1   7303907  ultralytics.nn.modules.head.RTDETRDecoder    [1, [256, 256, 256]]          \n",
      "rt-detr-l summary: 465 layers, 32,808,131 parameters, 32,808,131 gradients, 108.0 GFLOPs\n",
      "\n",
      "Transferred 926/941 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5195.8Â±1617.6 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 15.6Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2462.3Â±1818.8 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.7Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01443' and 'momentum=0.93057' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.00073), 226 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       1/20         8G      1.656     0.5023     0.5639        434        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.0it/s 5.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.6it/s 1.2s3.2s\n",
      "                   all         93       2846     0.0676      0.423     0.0553     0.0144\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       2/20      4.27G      1.306     0.4712     0.3937        406        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       2/20      5.29G      1.065     0.5395     0.2513        630        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.9it/s 0.2s.3s\n",
      "                   all         93       2846      0.545      0.573      0.492      0.199\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       3/20      5.29G     0.9176     0.4972     0.2135        410        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       3/20      5.93G     0.8712     0.4967     0.1795        519        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.7it/s 0.2s.3s\n",
      "                   all         93       2846      0.629      0.567      0.509      0.127\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       4/20      5.93G     0.7871     0.4826     0.1509        477        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       4/20      5.93G     0.8363     0.4802     0.1671        449        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.9it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.294      0.226       0.13     0.0174\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       5/20      5.93G     0.8166     0.4812     0.1634        481        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       5/20      5.93G      0.793     0.4845     0.1509        493        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.9it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.176      0.158     0.0718     0.0127\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       6/20      5.93G     0.7804     0.4851     0.1434        548        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       6/20       6.3G     0.7695     0.4905     0.1424        449        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 7.0it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.8it/s 0.2s.3s\n",
      "                   all         93       2846      0.703      0.646      0.581      0.182\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       7/20       6.3G     0.7851     0.4763     0.1589        394        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       7/20      7.17G     0.7675      0.493     0.1482        425        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.9it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.8it/s 0.2s.3s\n",
      "                   all         93       2846      0.726      0.674      0.625       0.23\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       8/20      7.17G     0.7453     0.4859     0.1368        453        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       8/20      7.17G     0.7737     0.4846     0.1439        447        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 7.0it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 13.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.685      0.606      0.537      0.109\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       9/20      7.17G     0.6992     0.5095     0.1157        501        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       9/20      7.17G     0.7375      0.498     0.1375        386        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 7.0it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.8it/s 0.2s.3s\n",
      "                   all         93       2846      0.694      0.626       0.56      0.135\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      10/20      7.17G     0.6419     0.5246     0.1108        725        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      10/20      7.17G     0.7188     0.4971     0.1285        395        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.9it/s 0.3s.3s\n",
      "                   all         93       2846      0.655      0.584      0.499     0.0852\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      11/20      7.17G     0.7039     0.5512     0.1326        317        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      11/20      7.17G     0.6523     0.5176     0.1165        446        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.691      0.639      0.571      0.137\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      12/20      7.17G     0.7483      0.501     0.1539        437        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      12/20      7.17G     0.6509     0.5138     0.1192        384        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.7it/s 0.3s.3s\n",
      "                   all         93       2846      0.727      0.681       0.63      0.244\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      13/20      7.17G     0.6342     0.5178     0.1136        276        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.711       0.66      0.602      0.159\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      14/20      7.17G     0.6435      0.518     0.1191        228        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.768      0.708      0.676      0.314\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      15/20      7.17G     0.6233      0.514     0.1089        299        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.8it/s 0.3s.3s\n",
      "                   all         93       2846      0.755      0.704      0.662      0.281\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      16/20      7.17G     0.6255       0.52     0.1069        277        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.4it/s 0.3s.3s\n",
      "                   all         93       2846      0.751       0.72      0.671      0.309\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      17/20      7.17G     0.6175     0.5142     0.1097        489        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.9it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.9it/s 0.3s.3s\n",
      "                   all         93       2846      0.776      0.713      0.684      0.323\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      18/20      7.17G     0.6198     0.5136     0.1064        289        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.9it/s 0.3s.3s\n",
      "                   all         93       2846      0.769      0.708      0.673      0.312\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      19/20      7.17G     0.6098     0.5096     0.1011        375        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.9it/s 2.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.756      0.712      0.668      0.301\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      20/20      7.17G     0.6057     0.5089     0.1027        336        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.8it/s 0.3s.3s\n",
      "                   all         93       2846      0.759      0.719       0.67      0.307\n",
      "\n",
      "20 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 66.1MB\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m9/10 iterations complete âœ… (706.02s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.30735 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.76647, 'metrics/recall(B)': 0.71038, 'metrics/mAP50(B)': 0.68153, 'metrics/mAP50-95(B)': 0.30735, 'val/giou_loss': 0.70614, 'val/cls_loss': 0.49636, 'val/l1_loss': 0.12347, 'fitness': 0.30735}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 10.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 10/10 with hyperparameters: {'lr0': 0.00757, 'lrf': 0.00811, 'momentum': 0.86981, 'weight_decay': 0.00072, 'warmup_epochs': 2.47394, 'warmup_momentum': 0.85635, 'box': 8.12694, 'cls': 0.51098, 'dfl': 1.66769, 'hsv_h': 0.02119, 'hsv_s': 0.69414, 'hsv_v': 0.57914, 'degrees': 0.0, 'translate': 0.11036, 'scale': 0.38954, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.39863, 'bgr': 0.0, 'mosaic': 0.72505, 'mixup': 0.0, 'cutmix': 0.0, 'copy_paste': 0.0, 'close_mosaic': 9}\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=8.12694, cache=False, cfg=None, classes=None, close_mosaic=9, cls=0.51098, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.66769, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.39863, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.02119, hsv_s=0.69414, hsv_v=0.57914, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00757, lrf=0.00811, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=rtdetr-l.pt, momentum=0.86981, mosaic=0.72505, multi_scale=False, name=train42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.38954, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.11036, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=2.47394, warmup_momentum=0.85635, weight_decay=0.00072, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "WARNING âš ï¸ no model scale passed. Assuming scale='l'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n",
      "  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n",
      "  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
      "  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n",
      "  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n",
      "  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n",
      "  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n",
      "  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n",
      " 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n",
      " 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
      " 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n",
      " 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n",
      " 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 28        [21, 24, 27]  1   7303907  ultralytics.nn.modules.head.RTDETRDecoder    [1, [256, 256, 256]]          \n",
      "rt-detr-l summary: 465 layers, 32,808,131 parameters, 32,808,131 gradients, 108.0 GFLOPs\n",
      "\n",
      "Transferred 926/941 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5058.9Â±1280.3 MB/s, size: 113.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 14.0Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2482.9Â±1761.0 MB/s, size: 161.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 1.7Mit/s 0.0ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.00757' and 'momentum=0.86981' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.00072), 226 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       1/20       7.4G      1.673     0.5169     0.5649        364        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.8it/s 5.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.5it/s 1.2s3.4s\n",
      "                   all         93       2846     0.0615      0.554     0.0742     0.0199\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       2/20      4.38G      1.274      0.498     0.3631        271        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       2/20      6.92G      1.025     0.5587     0.2321        352        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.3it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.612      0.546      0.526      0.208\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       3/20      7.59G     0.9563     0.5298     0.2087        353        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       3/20      7.59G     0.9062     0.5031      0.194        353        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.634      0.549      0.511      0.142\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       4/20      7.59G     0.8176     0.5119     0.1586        416        256: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/20  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       4/20      8.15G     0.8504      0.496     0.1782        530        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.501      0.448      0.313     0.0567\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       5/20      5.81G     0.8624       0.49     0.1732        393        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.6it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.549      0.505      0.385     0.0774\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       6/20      5.81G     0.8084     0.5056     0.1532        233        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.678      0.622       0.54      0.156\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       7/20      7.09G     0.7993     0.4971     0.1449        394        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.427      0.398      0.256     0.0402\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       8/20      7.09G     0.7898     0.4882     0.1456        442        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846      0.541      0.483      0.356     0.0516\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       9/20      7.09G     0.7668     0.4863     0.1413        395        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.6it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.683       0.63      0.552      0.129\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      10/20      7.09G     0.7607     0.4864      0.133        466        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.3s.3s\n",
      "                   all         93       2846      0.741      0.677      0.634      0.262\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      11/20      7.09G     0.7243     0.4902     0.1252        460        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.8it/s 0.3s.3s\n",
      "                   all         93       2846      0.534      0.505      0.368     0.0589\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      12/20      7.09G     0.6728     0.5165     0.1257        389        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.6it/s 3.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.3s.3s\n",
      "                   all         93       2846      0.734       0.68      0.632      0.244\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      13/20      7.09G     0.6666      0.517     0.1209        276        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.6it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.749      0.692       0.65      0.283\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      14/20      7.09G     0.6589     0.5211     0.1206        219        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.3it/s 0.3s.3s\n",
      "                   all         93       2846       0.75      0.697      0.651      0.278\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      15/20      7.09G     0.6387     0.5219     0.1135        287        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.5it/s 0.3s.3s\n",
      "                   all         93       2846      0.753      0.697      0.656      0.288\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      16/20      7.09G     0.6477     0.5205     0.1133        267        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.8it/s 2.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.7it/s 0.3s.3s\n",
      "                   all         93       2846      0.734      0.694       0.64      0.262\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      17/20      7.09G     0.6343     0.5247     0.1094        460        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.8it/s 0.3s.3s\n",
      "                   all         93       2846      0.748        0.7      0.656      0.283\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      18/20      7.09G     0.6382      0.515     0.1063        278        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.6it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.5it/s 0.3s.3s\n",
      "                   all         93       2846       0.75      0.706      0.662      0.303\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      19/20      7.09G     0.6394     0.5114     0.1148        349        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.9it/s 0.3s.3s\n",
      "                   all         93       2846      0.749      0.709       0.66      0.292\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      20/20      7.09G     0.6237       0.51     0.1065        305        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.7it/s 3.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.7it/s 0.3s.3s\n",
      "                   all         93       2846      0.755      0.712      0.665      0.307\n",
      "\n",
      "20 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/last.pt, 66.1MB\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/best.pt, 66.1MB\n",
      "\n",
      "Validating /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42/weights/best.pt...\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "rt-detr-l summary: 310 layers, 31,985,795 parameters, 0 gradients, 103.4 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 17.4it/s 0.2s.2s\n",
      "                   all         93       2846      0.754      0.711      0.663      0.307\n",
      "Speed: 0.0ms preprocess, 1.1ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/tune_scatter_plots.png\n",
      "Saved /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m10/10 iterations complete âœ… (787.05s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.30745 observed at iteration 10\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.75502, 'metrics/recall(B)': 0.71188, 'metrics/mAP50(B)': 0.66501, 'metrics/mAP50-95(B)': 0.30745, 'val/giou_loss': 0.70791, 'val/cls_loss': 0.50033, 'val/l1_loss': 0.12705, 'fitness': 0.30745}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/train42\n",
      "Printing '\u001b[1m\u001b[30m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/20260111_172635_rtdetr-l_tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00757\n",
      "lrf: 0.00811\n",
      "momentum: 0.86981\n",
      "weight_decay: 0.00072\n",
      "warmup_epochs: 2.47394\n",
      "warmup_momentum: 0.85635\n",
      "box: 8.12694\n",
      "cls: 0.51098\n",
      "dfl: 1.66769\n",
      "hsv_h: 0.02119\n",
      "hsv_s: 0.69414\n",
      "hsv_v: 0.57914\n",
      "degrees: 0.0\n",
      "translate: 0.11036\n",
      "scale: 0.38954\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.39863\n",
      "bgr: 0.0\n",
      "mosaic: 0.72505\n",
      "mixup: 0.0\n",
      "cutmix: 0.0\n",
      "copy_paste: 0.0\n",
      "close_mosaic: 9.0\n",
      "\n",
      "rtdetr-l tuning complete. Best hyperparameters saved to runs/detect/20260111_172635_rtdetr-l_tune/best_hyperparameters.yaml\n",
      "New https://pypi.org/project/ultralytics/8.3.252 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=8.12694, cache=False, cfg=None, classes=None, close_mosaic=9, cls=0.51098, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../data/yolo/config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.66769, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=200, erasing=0.4, exist_ok=False, fliplr=0.39863, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.02119, hsv_s=0.69414, hsv_v=0.57914, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.00757, lrf=0.00811, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=rtdetr-l.pt, momentum=0.86981, mosaic=0.72505, multi_scale=False, name=20260111_172635_rtdetr-l, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/20260111_172635_rtdetr-l, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.38954, seed=64, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.11036, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=2.47394, warmup_momentum=0.85635, weight_decay=0.00072, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "WARNING âš ï¸ no model scale passed. Assuming scale='l'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n",
      "  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n",
      "  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
      "  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n",
      "  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n",
      "  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n",
      "  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n",
      "  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n",
      " 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n",
      " 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
      " 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n",
      " 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n",
      " 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 28        [21, 24, 27]  1   7303907  ultralytics.nn.modules.head.RTDETRDecoder    [1, [256, 256, 256]]          \n",
      "rt-detr-l summary: 465 layers, 32,808,131 parameters, 32,808,131 gradients, 108.0 GFLOPs\n",
      "\n",
      "Transferred 926/941 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 4800.0Â±681.6 MB/s, size: 152.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train.cache... 320 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 320/320 1.1Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6774-293573-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/train/OAM-6783-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 817.3Â±161.3 MB/s, size: 142.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 192.2Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.00757' and 'momentum=0.86981' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.00072), 226 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/20260111_172635_rtdetr-l\u001b[0m\n",
      "Starting training for 200 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      1/200      4.58G      2.026     0.9988     0.8559        489        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 1.8it/s 0.4s<10.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      1/200       7.3G      1.761     0.5437     0.6536        364        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 5.8it/s 3.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.4it/s 0.3s.3s\n",
      "                   all         93       2846     0.0516      0.432      0.039     0.0105\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      2/200      4.38G       1.36      0.499     0.3106        359        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.1it/s 0.3s<8.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      2/200      6.93G      1.125     0.5336     0.2734        352        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.2it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846      0.128      0.156     0.0579     0.0106\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      3/200      7.68G     0.9556     0.5271     0.2109        435        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.1it/s 0.3s<9.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      3/200      7.68G     0.9415     0.5144     0.1984        353        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.8it/s 0.3s.3s\n",
      "                   all         93       2846      0.632      0.586      0.532      0.209\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      4/200      8.33G     0.8952     0.5238     0.1812        531        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 1.7it/s 0.3s<11.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      4/200      8.33G     0.9058     0.5053     0.1952        530        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846       0.58      0.497      0.414      0.082\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      5/200      4.55G      0.864     0.4846     0.1729        350        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.1it/s 0.3s<9.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      5/200      5.99G     0.8819     0.4846     0.1778        393        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.472      0.394      0.287     0.0508\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      6/200      6.08G     0.8722     0.4887     0.1814        488        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.0it/s 0.3s<9.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      6/200      6.08G     0.8367      0.501     0.1614        233        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846      0.677      0.573      0.526      0.149\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      7/200      6.08G     0.8561     0.4826     0.1764        460        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.0it/s 0.3s<9.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      7/200      7.37G      0.842     0.4833     0.1615        394        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.5it/s 0.2s.3s\n",
      "                   all         93       2846      0.319      0.274      0.158     0.0268\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      8/200      7.46G     0.7897     0.4782     0.1459        453        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.0it/s 0.3s<9.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      8/200      7.46G     0.7993      0.494     0.1525        442        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.134      0.133     0.0349    0.00475\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      9/200      7.54G     0.8023     0.4998      0.145        457        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.1it/s 0.3s<9.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      9/200      7.54G     0.7705     0.5066     0.1417        395        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.636      0.557      0.462     0.0898\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     10/200      7.54G     0.7986     0.4725     0.1465        375        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 1.9it/s 0.3s<10.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     10/200      7.54G     0.7804      0.478     0.1434        466        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.3it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.701      0.652      0.583      0.178\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     11/200      7.54G     0.7695     0.4948     0.1398        306        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.1it/s 0.3s<8.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     11/200      7.54G     0.7467     0.4925     0.1378        460        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.3it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846       0.12      0.125     0.0311    0.00481\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     12/200      7.54G     0.7583     0.5058     0.1333        454        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 1.9it/s 0.3s<9.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     12/200      7.54G      0.757     0.5051      0.134        485        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.3s.3s\n",
      "                   all         93       2846      0.559      0.508      0.377     0.0573\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     13/200      7.54G     0.7794     0.5026     0.1488        370        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.2it/s 0.3s<8.8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     13/200      7.54G     0.7365     0.5054     0.1304        467        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.694       0.63      0.577      0.182\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     14/200      7.54G     0.7224     0.5119     0.1317        303        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.1it/s 0.3s<8.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     14/200      7.54G     0.7375     0.5027     0.1394        244        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.714      0.648      0.585      0.178\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     15/200      7.54G     0.7958     0.5243     0.1472        339        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.1it/s 0.3s<9.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     15/200      7.54G     0.7369     0.5143     0.1409        517        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.737      0.676      0.627      0.234\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     16/200      7.54G     0.7664     0.4851     0.1428        486        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 1.9it/s 0.3s<10.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     16/200      7.54G     0.7293     0.5112     0.1312        485        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.3it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.678      0.632      0.551      0.138\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     17/200      7.54G     0.8075     0.4971     0.1372        428        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 1.9it/s 0.3s<9.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     17/200      7.54G     0.7339     0.5127     0.1313        406        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.3it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846      0.565       0.61      0.484      0.131\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     18/200      7.54G     0.7255     0.4916     0.1319        532        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.0it/s 0.3s<9.7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     18/200      7.54G     0.7206     0.5033     0.1302        540        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.3it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.6it/s 0.2s.3s\n",
      "                   all         93       2846      0.211      0.204      0.078     0.0161\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     19/200      7.54G      0.722     0.4865     0.1272        542        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 1.9it/s 0.3s<10.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     19/200      7.54G     0.7215     0.5098     0.1285        395        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.2it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.755      0.693      0.661      0.294\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     20/200      7.54G        0.7     0.5102     0.1313        441        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.1it/s 0.3s<9.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     20/200      7.54G     0.7085     0.4984      0.129        252        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846      0.321      0.292      0.159     0.0262\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     21/200      7.54G     0.7478     0.4728     0.1551        550        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.0it/s 0.3s<9.7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     21/200      7.54G     0.7465     0.4934     0.1438        450        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.767      0.711      0.679      0.309\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     22/200      7.54G     0.6531     0.5133      0.124        393        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.1it/s 0.3s<9.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     22/200      7.54G     0.7118     0.5051       0.13        394        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.752      0.694      0.651       0.27\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     23/200      7.54G     0.7252     0.5078     0.1365        443        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 1.9it/s 0.3s<9.8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     23/200      7.54G     0.6993     0.4967     0.1282        454        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.754      0.706      0.665      0.297\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     24/200      7.54G     0.7107      0.519     0.1299        540        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.0it/s 0.3s<9.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     24/200      7.54G     0.7339     0.5173     0.1377        363        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846      0.748       0.69      0.651      0.297\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     25/200      7.54G     0.7053     0.5139      0.124        335        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.1it/s 0.3s<9.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     25/200      7.54G     0.7063     0.4989     0.1267        372        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.5it/s 0.2s.3s\n",
      "                   all         93       2846      0.559      0.522        0.4     0.0661\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     26/200      7.54G     0.7141     0.5127      0.121        419        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.1it/s 0.3s<9.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     26/200      7.54G     0.7224     0.4905      0.127        412        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.745      0.701      0.651      0.272\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     27/200      7.54G     0.6686     0.4935     0.1152        343        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.2it/s 0.3s<8.8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     27/200      7.54G     0.6994     0.5021      0.123        361        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846      0.718      0.664      0.611      0.215\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     28/200      7.54G     0.6819     0.5018     0.1254        489        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 1.9it/s 0.3s<10.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     28/200      7.54G     0.6974     0.5062     0.1189        357        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.746      0.691      0.653      0.273\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     29/200      7.54G      0.676     0.5112     0.1106        577        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 1.7it/s 0.3s<11.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     29/200      7.54G     0.6809     0.5067     0.1183        308        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.2it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.739        0.7      0.651      0.276\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     30/200      7.54G     0.7014     0.5009      0.123        430        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.0it/s 0.3s<9.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     30/200      7.54G     0.6957     0.5008     0.1223        536        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.2it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.4it/s 0.2s.3s\n",
      "                   all         93       2846      0.256      0.253      0.109     0.0152\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     31/200      7.54G     0.7177     0.4936     0.1255        419        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.0it/s 0.3s<9.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     31/200      7.54G     0.6956     0.4898     0.1202        590        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.2it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.8it/s 0.3s.3s\n",
      "                   all         93       2846      0.763      0.713      0.673      0.318\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     32/200      7.54G     0.6779     0.4828     0.1309        389        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.1it/s 0.3s<9.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     32/200      7.54G      0.707     0.5108     0.1349        561        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.3it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.676      0.648       0.56      0.154\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     33/200      7.54G     0.6941     0.5217     0.1252        341        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.0it/s 0.3s<9.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     33/200      7.54G     0.6966     0.5057     0.1286        447        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.8it/s 0.3s.3s\n",
      "                   all         93       2846      0.743      0.692       0.64      0.252\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     34/200      7.54G     0.7725     0.4998      0.128        583        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 1.9it/s 0.3s<10.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     34/200      7.54G     0.7053     0.4846     0.1203        513        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.2it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.1it/s 0.2s.3s\n",
      "                   all         93       2846      0.751      0.711      0.659      0.293\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     35/200      7.54G     0.6991     0.5173     0.1241        328        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.1it/s 0.3s<9.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     35/200      7.54G     0.6969     0.5056     0.1254        469        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.2s.3s\n",
      "                   all         93       2846      0.756      0.697      0.653      0.288\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     36/200      7.54G     0.7071     0.5043     0.1287        416        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.0it/s 0.3s<9.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     36/200      7.54G     0.6868     0.4988     0.1208        416        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.745      0.698      0.649      0.281\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     37/200      7.54G     0.6944     0.4987     0.1161        486        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 1.9it/s 0.3s<9.8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     37/200      7.54G     0.6842     0.4897     0.1133        391        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.3it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.9it/s 0.3s.3s\n",
      "                   all         93       2846      0.725      0.708      0.641      0.267\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     38/200      7.54G     0.6464     0.4912     0.1053        406        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.1it/s 0.3s<9.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     38/200      7.54G     0.6765     0.4982     0.1198        376        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.747      0.716      0.657      0.292\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     39/200      7.54G     0.6472     0.4899     0.1128        437        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.1it/s 0.3s<9.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     39/200      7.54G     0.6821     0.5007     0.1189        334        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.752      0.687      0.648      0.262\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     40/200      7.54G     0.6891     0.4855     0.1268        569        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 1.8it/s 0.3s<10.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     40/200      7.54G     0.6697     0.4968     0.1173        350        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.752      0.676      0.644      0.271\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     41/200      7.54G     0.6436     0.5435     0.1184        360        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.0it/s 0.3s<9.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     41/200      7.54G     0.6725     0.5061     0.1174        513        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846       0.75       0.69      0.631      0.241\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     42/200      7.54G     0.6587     0.5148     0.1147        487        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.0it/s 0.3s<9.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     42/200      7.54G     0.6691      0.495     0.1132        449        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.5it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.5it/s 0.3s.3s\n",
      "                   all         93       2846      0.751      0.714       0.66      0.306\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     43/200      7.54G     0.6842      0.492     0.1167        520        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 1.9it/s 0.3s<10.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     43/200      7.54G     0.6814     0.4983     0.1121        424        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.0it/s 0.3s.3s\n",
      "                   all         93       2846      0.753      0.709      0.649       0.28\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     44/200      7.54G     0.6795     0.4849     0.1204        408        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 1.9it/s 0.3s<10.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     44/200      7.54G     0.6945      0.496     0.1195        632        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.3it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 11.8it/s 0.3s.3s\n",
      "                   all         93       2846      0.749      0.697      0.635      0.252\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     45/200      7.63G     0.7053     0.5095      0.125        274        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.2it/s 0.3s<8.8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     45/200      7.63G     0.6723     0.4998     0.1134        459        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.4it/s 3.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.3it/s 0.2s.3s\n",
      "                   all         93       2846      0.719      0.675      0.601      0.172\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K     46/200      7.63G     0.6485     0.4951    0.09933        379        256: 5% â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/20 2.1it/s 0.3s<9.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:841: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:148.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     46/200      7.63G     0.6583      0.496     0.1113        326        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 6.3it/s 3.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 12.2it/s 0.2s.3s\n",
      "                   all         93       2846      0.748      0.702      0.638      0.264\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 15 epochs. Best results observed at epoch 31, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=15) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "46 epochs completed in 0.049 hours.\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/20260111_172635_rtdetr-l/weights/last.pt, 66.2MB\n",
      "Optimizer stripped from /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/20260111_172635_rtdetr-l/weights/best.pt, 66.2MB\n",
      "\n",
      "Validating /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/20260111_172635_rtdetr-l/weights/best.pt...\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "rt-detr-l summary: 310 layers, 31,985,795 parameters, 0 gradients, 103.4 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 17.1it/s 0.2s.2s\n",
      "                   all         93       2846      0.763      0.714      0.673      0.319\n",
      "Speed: 0.0ms preprocess, 1.1ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "rt-detr-l summary: 310 layers, 31,985,795 parameters, 0 gradients, 103.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5501.7Â±805.8 MB/s, size: 153.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val.cache... 93 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 93/93 341.3Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/val/OAM-6782-293582-19.png: 1 duplicate labels removed\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 6/6 3.9it/s 1.5s1.2s\n",
      "                   all         93       2846      0.763      0.711      0.671      0.317\n",
      "Speed: 0.3ms preprocess, 14.3ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/val37\u001b[0m\n",
      "Ultralytics 8.3.250 ğŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "rt-detr-l summary: 310 layers, 31,985,795 parameters, 0 gradients, 103.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3405.6Â±891.8 MB/s, size: 131.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/test.cache... 45 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 161.5Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.4it/s 0.9s0.8s\n",
      "                   all         45       1150      0.777      0.766      0.719      0.334\n",
      "Speed: 0.2ms preprocess, 17.1ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1m/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/notebooks/runs/detect/val38\u001b[0m\n",
      "rtdetr-l: val_f1=0.7362, test_f1=0.7717, test_map50=0.7187\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = []\n",
    "\n",
    "for model_cfg in MODELS:\n",
    "    name = model_cfg['name']\n",
    "\n",
    "    model = RTDETR(model_cfg['weights']) if 'rtdetr' in name.lower() else YOLO(model_cfg['weights'])\n",
    "    \n",
    "    \n",
    "    if TUNE_MODELS:\n",
    "        tuning_name = f\"{exp_id}_{name}_tune\"\n",
    "            \n",
    "        print(f\"\\nTuning {name} for {TUNE_ITERATIONS} iterations\")\n",
    "        model.tune(\n",
    "            data=str(YOLO_DIR / \"config.yaml\"),\n",
    "            name = tuning_name,\n",
    "            epochs=TUNE_EPOCHS,\n",
    "            iterations=TUNE_ITERATIONS,\n",
    "            imgsz=IMG_SIZE,\n",
    "            plots=False,\n",
    "            save=False,\n",
    "            val=True\n",
    "        )\n",
    "\n",
    "        print(f\"{name} tuning complete. Best hyperparameters saved to runs/detect/{tuning_name}/best_hyperparameters.yaml\")\n",
    "    \n",
    "\n",
    "    tuned_params = {}\n",
    "    best_cfg_path = Path(f\"runs/detect/{exp_id}_{name}_tune/best_hyperparameters.yaml\")\n",
    "\n",
    "    if best_cfg_path.exists():\n",
    "        with open(best_cfg_path, 'r') as f:\n",
    "            tuned_params = yaml.safe_load(f)\n",
    "        # Fix the float error: force to int\n",
    "        if 'close_mosaic' in tuned_params:\n",
    "            tuned_params['close_mosaic'] = int(tuned_params['close_mosaic'])\n",
    "\n",
    "\n",
    "    # train the model  \n",
    "\n",
    "    model.train(\n",
    "        data=str(YOLO_DIR / \"config.yaml\"),\n",
    "        epochs=EPOCHS,\n",
    "        imgsz=IMG_SIZE,\n",
    "        patience=PATIENCE,\n",
    "        batch=BATCH,\n",
    "        seed=SEED,\n",
    "        name=f\"{exp_id}_{name}\",\n",
    "        project=\"runs\",\n",
    "        plots=False,\n",
    "        verbose=False,\n",
    "        **tuned_params\n",
    "    )\n",
    "    \n",
    "    val_metrics = model.val(split='val', verbose=False)\n",
    "    test_metrics = model.val(split='test', verbose=False)\n",
    "    \n",
    "    val_p, val_r = float(val_metrics.box.mp), float(val_metrics.box.mr)\n",
    "    test_p, test_r = float(test_metrics.box.mp), float(test_metrics.box.mr)\n",
    "    \n",
    "    val_f1 = 2 * (val_p * val_r) / (val_p + val_r + 1e-6)\n",
    "    test_f1 = 2 * (test_p * test_r) / (test_p + test_r + 1e-6)\n",
    "    \n",
    "    results.append({\n",
    "        'model': name,\n",
    "        'tuned': TUNE_MODELS,\n",
    "        'val_precision': val_p,\n",
    "        'val_recall': val_r,\n",
    "        'val_f1': val_f1,\n",
    "        'val_map50': float(val_metrics.box.map50),\n",
    "        'test_precision': test_p,\n",
    "        'test_recall': test_r,\n",
    "        'test_f1': test_f1,\n",
    "        'test_map50': float(test_metrics.box.map50),\n",
    "    })\n",
    "    \n",
    "    print(f\"{name}: val_f1={val_f1:.4f}, test_f1={test_f1:.4f}, test_map50={results[-1]['test_map50']:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results\n",
      "   model   val_f1  val_map50  test_f1  test_map50\n",
      " yolov8l 0.680170   0.596053 0.723645    0.648653\n",
      " yolo12l 0.669856   0.581507 0.705671    0.650465\n",
      "rtdetr-l 0.736169   0.670961 0.771689    0.718725\n",
      "\n",
      "Best: rtdetr-l (test_map50=0.7187)\n",
      "Saved: results/20260111_172635.json\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "summary = {\n",
    "    'exp_id': exp_id,\n",
    "    'seed': SEED,\n",
    "    'epochs': EPOCHS,\n",
    "    'img_size': IMG_SIZE,\n",
    "    'batch': BATCH,\n",
    "    'patience': PATIENCE,\n",
    "    'models': [m['name'] for m in MODELS],\n",
    "    'results': results,\n",
    "    'best_model': results[df['test_map50'].idxmax()]['model'] if len(results) > 0 else None,\n",
    "    'best_test_map50': float(df['test_map50'].max()) if len(results) > 0 else 0.0\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / f\"{exp_id}.json\", 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"\\nResults\")\n",
    "print(df[['model', 'val_f1', 'val_map50', 'test_f1', 'test_map50']].to_string(index=False))\n",
    "print(f\"\\nBest: {summary['best_model']} (test_map50={summary['best_test_map50']:.4f})\")\n",
    "print(f\"Saved: results/{exp_id}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for model_cfg in MODELS:\n",
    "    name = model_cfg['name']\n",
    "    csv_file = Path(f\"runs/{exp_id}_{name}/results.csv\")\n",
    "    \n",
    "    if csv_file.exists():\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df.columns = df.columns.str.strip()\n",
    "        \n",
    "        p = df['metrics/precision(B)']\n",
    "        r = df['metrics/recall(B)']\n",
    "        f1 = 2 * (p * r) / (p + r + 1e-6)\n",
    "        \n",
    "        axes[0].plot(f1, label=name, linewidth=2)\n",
    "        axes[1].plot(df['metrics/mAP50(B)'], label=name, linewidth=2)\n",
    "\n",
    "axes[0].set_title('F1 Score')\n",
    "axes[0].set_ylabel('F1')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].set_title('mAP50')\n",
    "axes[1].set_ylabel('mAP50')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / f\"curves_{exp_id}.png\", dpi=150)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4cv-object-detection-on-aerial-imagery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
