{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection Pipeline - Hyperparameter Tuning & Model Training\n",
    "\n",
    "Hyperparameter tuning with Ray Tune on validation set, followed by final training on train+val and evaluation on test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kshitijrajsharma/dl4cv-oda/blob/master/notebooks/experiment.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install dl4cv_oda ray[tune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from dl4cv_oda import (clean_osm_data, clip_labels_to_tiles, convert_to_yolo_format,\n",
    "                       create_train_val_split, create_yolo_config, download_tiles)\n",
    "from ultralytics import YOLO, RTDETR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../data\")\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "CHIPS_DIR = DATA_DIR / \"chips\"\n",
    "LABELS_DIR = DATA_DIR / \"labels\"\n",
    "YOLO_DIR = DATA_DIR / \"yolo\"\n",
    "\n",
    "OSM_FILE = RAW_DIR / \"kolovai-trees.geojson\"\n",
    "CLEANED_FILE = RAW_DIR / \"cleaned.geojson\"\n",
    "TREES_BOX_FILE = DATA_DIR / \"trees_box.geojson\"\n",
    "TILES_FILE = DATA_DIR / \"tiles.geojson\"\n",
    "\n",
    "IMG_SIZE = 256\n",
    "EPOCHS = 200\n",
    "PATIENCE = 10\n",
    "\n",
    "TUNE_EPOCHS = 30\n",
    "TUNE_ITERATIONS = 3\n",
    "GPU_PER_TRIAL = 1\n",
    "\n",
    "MODELS_TO_TRAIN = {\n",
    "    \"yolov8l\": \"yolov8l.pt\",\n",
    "    \"yolo12l\": \"yolo12l.pt\",\n",
    "    \"rtdetr-l\": \"rtdetr-l.pt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSM data ready\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "if not OSM_FILE.exists():\n",
    "    OSM_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    OSM_FILE.write_bytes(requests.get(\"https://github.com/kshitijrajsharma/dl4cv-oda/blob/master/data/raw/kolovai-trees.geojson?raw=true\", allow_redirects=True).content)\n",
    "    print(f\"Downloaded {OSM_FILE}\")\n",
    "else:\n",
    "    print(\"OSM data ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Clean OSM Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data ready\n"
     ]
    }
   ],
   "source": [
    "if not CLEANED_FILE.exists():\n",
    "    count = clean_osm_data(str(OSM_FILE), str(CLEANED_FILE), str(TREES_BOX_FILE))\n",
    "    print(f\"Processed {count} trees\")\n",
    "else:\n",
    "    print(\"Cleaned data ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TILES_FILE.exists():\n",
    "    data = gpd.read_file(TREES_BOX_FILE)\n",
    "    data.to_crs(epsg=4326, inplace=True)\n",
    "    bbox = list(data.total_bounds)\n",
    "    await download_tiles(bbox, 19, \"https://tiles.openaerialmap.org/5a28639331eff4000c380690/0/5b1b6fb2-5024-4681-a175-9b667174f48c/{z}/{x}/{y}.png\", DATA_DIR, 'OAM')\n",
    "    print(\"Tiles downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip Labels & Convert to YOLO Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO format data ready\n"
     ]
    }
   ],
   "source": [
    "if TILES_FILE.exists() and not (YOLO_DIR / \"train\").exists():\n",
    "    stats = clip_labels_to_tiles(str(TREES_BOX_FILE), str(TILES_FILE), str(LABELS_DIR))\n",
    "    print(f\"{stats['processed']} tiles, {stats['total_trees']} trees\")\n",
    "    class_mapping = convert_to_yolo_format(str(TREES_BOX_FILE), str(CHIPS_DIR), str(LABELS_DIR), str(YOLO_DIR), target_species=\"Coconut\")\n",
    "    print(f\"Class mapping: {class_mapping}\")\n",
    "else:\n",
    "    print(\"YOLO format data ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train/Val/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test split ready\n",
      "Config: /home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/config.yaml\n"
     ]
    }
   ],
   "source": [
    "if not (YOLO_DIR / \"train\").exists():\n",
    "    train_count, val_count, test_count = create_train_val_split(str(LABELS_DIR), str(CHIPS_DIR), str(YOLO_DIR), train_ratio=0.7, val_ratio=0.2, test_ratio=0.1)\n",
    "    print(f\"Train: {train_count} | Val: {val_count} | Test: {test_count}\")\n",
    "else:\n",
    "    print(\"Train/Val/Test split ready\")\n",
    "\n",
    "config_file = create_yolo_config(str(YOLO_DIR), {\"Coconut\": 0})\n",
    "config_file_abs = os.path.abspath(config_file)\n",
    "print(f\"Config: {config_file_abs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with Ray Tune\n",
    "\n",
    "Tune all models with consistent parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2026-01-11 01:07:14</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:00.12        </td></tr>\n",
       "<tr><td>Memory:      </td><td>17.3/62.5 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 30.000: None | Iter 10.000: None<br>Logical resource usage: 8.0/32 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">     bgr</th><th style=\"text-align: right;\">      box</th><th style=\"text-align: right;\">    cls</th><th style=\"text-align: right;\">  copy_paste</th><th style=\"text-align: right;\">   cutmix</th><th style=\"text-align: right;\">  degrees</th><th style=\"text-align: right;\">  fliplr</th><th style=\"text-align: right;\">   flipud</th><th style=\"text-align: right;\">    hsv_h</th><th style=\"text-align: right;\">    hsv_s</th><th style=\"text-align: right;\">   hsv_v</th><th style=\"text-align: right;\">      lr0</th><th style=\"text-align: right;\">      lrf</th><th style=\"text-align: right;\">   mixup</th><th style=\"text-align: right;\">  momentum</th><th style=\"text-align: right;\">   mosaic</th><th style=\"text-align: right;\">  perspective</th><th style=\"text-align: right;\">   scale</th><th style=\"text-align: right;\">  shear</th><th style=\"text-align: right;\">  translate</th><th style=\"text-align: right;\">  warmup_epochs</th><th style=\"text-align: right;\">  warmup_momentum</th><th style=\"text-align: right;\">  weight_decay</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>_tune_7bb73_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.907854</td><td style=\"text-align: right;\">0.0796307</td><td style=\"text-align: right;\">3.58553</td><td style=\"text-align: right;\">   0.0988905</td><td style=\"text-align: right;\">0.0569382</td><td style=\"text-align: right;\">  13.7758</td><td style=\"text-align: right;\">0.670354</td><td style=\"text-align: right;\">0.0420122</td><td style=\"text-align: right;\">0.0522778</td><td style=\"text-align: right;\">0.664216 </td><td style=\"text-align: right;\">0.239032</td><td style=\"text-align: right;\">0.0235204</td><td style=\"text-align: right;\">0.0588072</td><td style=\"text-align: right;\">0.777525</td><td style=\"text-align: right;\">  0.604125</td><td style=\"text-align: right;\">0.486435 </td><td style=\"text-align: right;\">  0.000151422</td><td style=\"text-align: right;\">0.161405</td><td style=\"text-align: right;\">6.62615</td><td style=\"text-align: right;\">   0.597882</td><td style=\"text-align: right;\">      3.38397  </td><td style=\"text-align: right;\">        0.744189 </td><td style=\"text-align: right;\">   2.01515e-06</td></tr>\n",
       "<tr><td>_tune_7bb73_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.823878</td><td style=\"text-align: right;\">0.0356839</td><td style=\"text-align: right;\">3.11894</td><td style=\"text-align: right;\">   0.336589 </td><td style=\"text-align: right;\">0.283678 </td><td style=\"text-align: right;\">  11.101 </td><td style=\"text-align: right;\">0.136259</td><td style=\"text-align: right;\">0.815132 </td><td style=\"text-align: right;\">0.0808653</td><td style=\"text-align: right;\">0.0508149</td><td style=\"text-align: right;\">0.263521</td><td style=\"text-align: right;\">0.0883875</td><td style=\"text-align: right;\">0.763884 </td><td style=\"text-align: right;\">0.95676 </td><td style=\"text-align: right;\">  0.943843</td><td style=\"text-align: right;\">0.65639  </td><td style=\"text-align: right;\">  0.000459537</td><td style=\"text-align: right;\">0.204948</td><td style=\"text-align: right;\">0.52553</td><td style=\"text-align: right;\">   0.456485</td><td style=\"text-align: right;\">      0.0495785</td><td style=\"text-align: right;\">        0.946266 </td><td style=\"text-align: right;\">   0.00060137 </td></tr>\n",
       "<tr><td>_tune_7bb73_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.779135</td><td style=\"text-align: right;\">0.0338327</td><td style=\"text-align: right;\">3.20488</td><td style=\"text-align: right;\">   0.843383 </td><td style=\"text-align: right;\">0.928586 </td><td style=\"text-align: right;\">  39.0042</td><td style=\"text-align: right;\">0.216124</td><td style=\"text-align: right;\">0.0130427</td><td style=\"text-align: right;\">0.0381761</td><td style=\"text-align: right;\">0.85973  </td><td style=\"text-align: right;\">0.477259</td><td style=\"text-align: right;\">0.0660049</td><td style=\"text-align: right;\">0.12079  </td><td style=\"text-align: right;\">0.805766</td><td style=\"text-align: right;\">  0.673489</td><td style=\"text-align: right;\">0.0632038</td><td style=\"text-align: right;\">  0.000758183</td><td style=\"text-align: right;\">0.347336</td><td style=\"text-align: right;\">7.09766</td><td style=\"text-align: right;\">   0.224045</td><td style=\"text-align: right;\">      2.71455  </td><td style=\"text-align: right;\">        0.0951832</td><td style=\"text-align: right;\">   0.000111936</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=3475307)\u001b[0m New https://pypi.org/project/ultralytics/8.3.252 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m Ultralytics 8.3.250 ðŸš€ Python-3.13.7 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090 Laptop GPU, 15944MiB)\n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m \u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.907854238249426, box=0.07963073825918983, cache=False, cfg=None, classes=None, close_mosaic=10, cls=3.5855302095415205, compile=False, conf=None, copy_paste=0.09889050143185318, copy_paste_mode=flip, cos_lr=False, cutmix=0.05693824651467838, data=/home/krschap/academia/dl4cv-object-detection-on-aerial-imagery/data/yolo/config.yaml, degrees=13.775788821871268, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.6703543885383698, flipud=0.04201215309291839, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.052277842725976846, hsv_s=0.6642156250023235, hsv_v=0.23903249523295025, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.023520413211327352, lrf=0.05880722085518508, mask_ratio=4, max_det=300, mixup=0.77752503904651, mode=train, model=yolo12l.pt, momentum=0.6041248349658435, mosaic=0.4864353835744891, multi_scale=False, name=tune, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.00015142151823380602, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/tmp/ray/session_2026-01-11_01-07-12_753703_3452286/artifacts/2026-01-11_01-07-14/tune15/working_dirs/_tune_7bb73_00000/runs/detect/tune, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.16140453271361385, seed=0, shear=6.626151253697606, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.597881609682153, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.3839719021958574, warmup_momentum=0.7441886550453403, weight_decay=2.015151387323999e-06, workers=8, workspace=None\n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m Overriding model.yaml nc=80 with nc=1\n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m \n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m                    from  n    params  module                                       arguments                     \n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m   0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m   1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m   2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m   3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m   4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m   5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m   6                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 4, True, 1.2]\n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m   7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m   8                  -1  4   4272944  ultralytics.nn.modules.block.A2C2f           [512, 512, 4, True, 1, True, 1.2]\n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m   9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m  10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m  11                  -1  2   2102784  ultralytics.nn.modules.block.A2C2f           [1024, 512, 2, False, -1, True, 1.2]\n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m  12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m  13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m  14                  -1  2    592640  ultralytics.nn.modules.block.A2C2f           [1024, 256, 2, False, -1, True, 1.2]\n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m  15                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m  16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m  17                  -1  2   2037248  ultralytics.nn.modules.block.A2C2f           [768, 512, 2, False, -1, True, 1.2]\n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m  18                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m  19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m  20                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m  21        [14, 17, 20]  1   1411795  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m YOLOv12l summary: 488 layers, 26,389,875 parameters, 26,389,859 gradients, 89.4 GFLOPs\n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m \n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m Transferred 1239/1245 items from pretrained weights\n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m Freezing layer 'model.21.dfl.conv.weight'\n",
      "\u001b[36m(_tune pid=3475307)\u001b[0m \u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n"
     ]
    }
   ],
   "source": [
    "tune_results = {}\n",
    "for model_name, model_weights in MODELS_TO_TRAIN.items():\n",
    "    print(f\"Tuning {model_name}...\")\n",
    "    model = RTDETR(model_weights) if \"rtdetr\" in model_name.lower() else YOLO(model_weights)\n",
    "    result_grid = model.tune(data=config_file_abs, epochs=TUNE_EPOCHS, imgsz=IMG_SIZE, \n",
    "                            patience=PATIENCE, iterations=TUNE_ITERATIONS, \n",
    "                            gpu_per_trial=GPU_PER_TRIAL, use_ray=True)\n",
    "    tune_results[model_name] = result_grid\n",
    "    print(f\"{model_name} tuning complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results & Extract Best Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_and_save_results(result_grid, model_name):\n",
    "    results_list = []\n",
    "    for i, result in enumerate(result_grid):\n",
    "        df = result.metrics_dataframe\n",
    "        p = df['metrics/precision(B)'].iloc[-1] if 'metrics/precision(B)' in df else 0\n",
    "        r = df['metrics/recall(B)'].iloc[-1] if 'metrics/recall(B)' in df else 0\n",
    "        m = df['metrics/mAP50(B)'].iloc[-1] if 'metrics/mAP50(B)' in df else 0\n",
    "        f1 = 2 * (p * r) / (p + r + 1e-6) if (p + r) > 0 else 0\n",
    "        results_list.append({'trial': i, 'config': result.config, 'precision': p, 'recall': r, 'mAP50': m, 'f1': f1})\n",
    "    \n",
    "    results_df = pd.DataFrame(results_list).sort_values('f1', ascending=False)\n",
    "    best = results_df.iloc[0]\n",
    "    best_config = best['config']\n",
    "    \n",
    "    with open(YOLO_DIR / f\"best_config_{model_name}.yaml\", 'w') as f:\n",
    "        yaml.dump(best_config, f, default_flow_style=False)\n",
    "    \n",
    "    print(f\"{model_name:12s} F1: {best['f1']:.4f} | P: {best['precision']:.4f} | R: {best['recall']:.4f} | mAP50: {best['mAP50']:.4f}\")\n",
    "    return results_df, best_config\n",
    "\n",
    "best_configs = {}\n",
    "for model_name, result_grid in tune_results.items():\n",
    "    _, best_configs[model_name] = analyze_and_save_results(result_grid, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Train+Val for Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_dir = YOLO_DIR / \"trainval\"\n",
    "trainval_config = YOLO_DIR / \"data_trainval.yaml\"\n",
    "\n",
    "if not trainval_dir.exists():\n",
    "    trainval_dir.mkdir(exist_ok=True)\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        for f in (YOLO_DIR / split).glob(\"*\"):\n",
    "            shutil.copy(f, trainval_dir / f.name)\n",
    "    with open(config_file, 'r') as f:\n",
    "        trainval_config.write_text(f.read().replace(\"train: train\", \"train: trainval\"))\n",
    "    print(f\"Merged train+val into {trainval_dir}\")\n",
    "else:\n",
    "    print(\"Train+val merge ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Training with Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models = {}\n",
    "for model_name, model_weights in MODELS_TO_TRAIN.items():\n",
    "    print(f\"\\nTraining {model_name} on train+val...\")\n",
    "    model = RTDETR(model_weights) if \"rtdetr\" in model_weights.lower() else YOLO(model_weights)\n",
    "    cfg = best_configs[model_name].copy()\n",
    "    cfg.update({'data': str(trainval_config), 'epochs': EPOCHS, 'imgsz': IMG_SIZE, \n",
    "                'patience': PATIENCE, 'name': f\"final_{model_name}\", 'plots': True})\n",
    "    model.train(**cfg)\n",
    "    trained_models[model_name] = model\n",
    "    print(f\"{model_name} complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "for name, model in trained_models.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    m = model.val(split='test')\n",
    "    p, r = m.box.mp, m.box.mr\n",
    "    test_results[name] = {\"precision\": p, \"recall\": r, \"f1\": 2 * (p * r) / (p + r + 1e-6),\n",
    "                         \"mAP50\": m.box.map50, \"mAP50-95\": m.box.map}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(test_results).T.sort_values('f1', ascending=False)\n",
    "print(\"Test Set Results:\")\n",
    "print(results_df.to_string())\n",
    "print(f\"\\nBest: {results_df.index[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score per Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(MODELS_TO_TRAIN)\n",
    "cols = min(3, n)\n",
    "rows = (n + cols - 1) // cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(6*cols, 5*rows))\n",
    "axes = axes.flatten() if n > 1 else [axes]\n",
    "\n",
    "for idx, model_name in enumerate(MODELS_TO_TRAIN.keys()):\n",
    "    csv = Path(f\"runs/detect/final_{model_name}/results.csv\")\n",
    "    if csv.exists():\n",
    "        df = pd.read_csv(csv)\n",
    "        df.columns = df.columns.str.strip()\n",
    "        p, r = df['metrics/precision(B)'], df['metrics/recall(B)']\n",
    "        f1 = 2 * (p * r) / (p + r + 1e-6)\n",
    "        axes[idx].plot(f1, label='F1', linewidth=2, color='#2E86AB')\n",
    "        axes[idx].plot(p, label='Precision', alpha=0.7, color='#A23B72')\n",
    "        axes[idx].plot(r, label='Recall', alpha=0.7, color='#F18F01')\n",
    "        axes[idx].set_title(model_name.upper(), fontsize=11, fontweight='bold')\n",
    "        axes[idx].set_xlabel('Epoch')\n",
    "        axes[idx].set_ylabel('Score')\n",
    "        axes[idx].legend()\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "for idx in range(n, len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('f1_scores_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4cv-object-detection-on-aerial-imagery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
